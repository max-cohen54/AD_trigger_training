{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c66c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e534d4b-7c71-41e4-9bb4-cbbae169f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20999b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('/eos/home-w/wsherman/AD_Work/n_tuples/40MHZ_data/background_for_training.h5','r')\n",
    "Dataset=np.array(f[\"Particles\"])\n",
    "\n",
    "#for i, batch in enumerate(Dataset):\n",
    "#  pt_sum=0\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    if particle[3]!=0:\n",
    "#      pt_sum+=particle[0]\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    particle[0]=particle[0]/pt_sum\n",
    "    \n",
    "    \n",
    "Data_Train=Dataset[0:2000000,:,0:3]\n",
    "Data_Test=Dataset[2000001:3600000,:,0:3]\n",
    "Data_Validate=Dataset[3600001:4000000,:,0:3]\n",
    "\n",
    "Data_Train_Flat=np.reshape(Data_Train,(-1,57))\n",
    "Data_Val_Flat=np.reshape(Data_Validate,(-1,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def make_encoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(input_dim))\n",
    "    #x=layers.BatchNormalization()(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(inputs)\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(x)\n",
    "    z_mean=layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_logvar=layers.Dense(latent_dim, name='z_log_var',kernel_initializer=keras.initializers.Zeros())(x)\n",
    "    z=Sampling()([z_mean,z_logvar])\n",
    "    encoder=keras.Model(inputs,[z_mean,z_logvar,z],name='encoder')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_decoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(latent_dim))\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(x)\n",
    "    z=layers.Dense(input_dim)(x)\n",
    "    decoder=keras.Model(inputs,z,name='decoder')\n",
    "    return decoder\n",
    "\n",
    "class VAE_Model(keras.Model):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta=1\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def set_beta(self,beta):\n",
    "        self.beta=beta\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            #making a masked loss function\n",
    "            mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "            reconstruction_loss *=(1-self.beta)\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *=self.beta\n",
    "\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reco_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        \n",
    "        reconstruction = self.decoder(z)\n",
    "        mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "        \n",
    "        reconstruction_loss*=(1-self.beta)\n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        \n",
    "        #KL loss changed abck to sum as in paper\n",
    "        kl_loss = tf.reduce_sum(kl_loss)\n",
    "        \n",
    "        kl_loss *=self.beta\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reco_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean,z_log_var,x = self.encoder(data)\n",
    "        reconstruction = self.decoder(x)\n",
    "        return {\n",
    "            \"z_mean\": z_mean,\n",
    "            \"z_log_var\": z_log_var,\n",
    "            \"reconstruction\": reconstruction\n",
    "        }\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f8c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 14s 5ms/step - loss: 548856.5820 - reco_loss: 543152.2282 - kl_loss: 1781.9402 - val_loss: 718408.8125 - val_reco_loss: 346.2984 - val_kl_loss: 718062.5000 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 362.6258 - reco_loss: 267.8953 - kl_loss: 80.0966 - val_loss: 360631.7188 - val_reco_loss: 187.7482 - val_kl_loss: 360443.9688 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 241.0576 - reco_loss: 191.9410 - kl_loss: 43.3885 - val_loss: 215295.0469 - val_reco_loss: 160.7582 - val_kl_loss: 215134.2812 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 194.3176 - reco_loss: 164.0121 - kl_loss: 27.7391 - val_loss: 150949.7812 - val_reco_loss: 141.2512 - val_kl_loss: 150808.5312 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 161.3955 - reco_loss: 139.7764 - kl_loss: 20.2286 - val_loss: 114599.5000 - val_reco_loss: 129.3740 - val_kl_loss: 114470.1250 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 139.3198 - reco_loss: 122.2807 - kl_loss: 16.1635 - val_loss: 93227.9375 - val_reco_loss: 125.4946 - val_kl_loss: 93102.4453 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 137.6787 - reco_loss: 123.4354 - kl_loss: 13.6853 - val_loss: 79494.3281 - val_reco_loss: 104.8312 - val_kl_loss: 79389.5000 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 102.6816 - reco_loss: 90.4843 - kl_loss: 11.8344 - val_loss: 70167.8750 - val_reco_loss: 97.2025 - val_kl_loss: 70070.6719 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 79.9134 - reco_loss: 69.2504 - kl_loss: 10.3260 - val_loss: 62439.3672 - val_reco_loss: 76.1376 - val_kl_loss: 62363.2305 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 73.4493 - reco_loss: 63.8653 - kl_loss: 9.2763 - val_loss: 54291.6367 - val_reco_loss: 73.8083 - val_kl_loss: 54217.8281 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 68.7341 - reco_loss: 60.3527 - kl_loss: 8.1947 - val_loss: 49428.5156 - val_reco_loss: 82.2327 - val_kl_loss: 49346.2812 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 64.0122 - reco_loss: 56.4345 - kl_loss: 7.3946 - val_loss: 44101.5156 - val_reco_loss: 71.3797 - val_kl_loss: 44030.1367 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 62.9849 - reco_loss: 56.0811 - kl_loss: 6.8057 - val_loss: 41254.3828 - val_reco_loss: 90.8196 - val_kl_loss: 41163.5625 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 64.2201 - reco_loss: 57.7202 - kl_loss: 6.5379 - val_loss: 41949.5117 - val_reco_loss: 68.1406 - val_kl_loss: 41881.3711 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.8702 - reco_loss: 53.3704 - kl_loss: 6.3898 - val_loss: 39400.7461 - val_reco_loss: 65.6374 - val_kl_loss: 39335.1094 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.3129 - reco_loss: 51.1970 - kl_loss: 6.0374 - val_loss: 36776.0508 - val_reco_loss: 71.7762 - val_kl_loss: 36704.2734 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.9655 - reco_loss: 52.2016 - kl_loss: 5.7699 - val_loss: 35754.9023 - val_reco_loss: 64.1979 - val_kl_loss: 35690.7031 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.4353 - reco_loss: 51.7844 - kl_loss: 5.7083 - val_loss: 51179.1719 - val_reco_loss: 155.0023 - val_kl_loss: 51024.1680 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 81.7338 - reco_loss: 74.0613 - kl_loss: 7.2819 - val_loss: 41635.4414 - val_reco_loss: 70.6260 - val_kl_loss: 41564.8164 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.3660 - reco_loss: 52.0329 - kl_loss: 6.1116 - val_loss: 36145.1367 - val_reco_loss: 68.3780 - val_kl_loss: 36076.7578 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 54.1202 - reco_loss: 48.5204 - kl_loss: 5.5382 - val_loss: 33966.4180 - val_reco_loss: 63.6747 - val_kl_loss: 33902.7422 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.6299 - reco_loss: 52.2407 - kl_loss: 5.3860 - val_loss: 33596.3359 - val_reco_loss: 62.5508 - val_kl_loss: 33533.7852 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 54.3160 - reco_loss: 48.9957 - kl_loss: 5.2572 - val_loss: 32389.3145 - val_reco_loss: 64.4405 - val_kl_loss: 32324.8730 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 54.1398 - reco_loss: 49.0087 - kl_loss: 5.0977 - val_loss: 31501.4004 - val_reco_loss: 68.7808 - val_kl_loss: 31432.6191 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.4756 - reco_loss: 48.4625 - kl_loss: 4.9668 - val_loss: 30527.9844 - val_reco_loss: 69.1243 - val_kl_loss: 30458.8594 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.4494 - reco_loss: 48.5869 - kl_loss: 4.8287 - val_loss: 29399.5469 - val_reco_loss: 70.3482 - val_kl_loss: 29329.1992 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.0712 - reco_loss: 47.4263 - kl_loss: 4.6088 - val_loss: 28351.9824 - val_reco_loss: 63.7245 - val_kl_loss: 28288.2578 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 185407364189.4479 - reco_loss: 185163549305.4350 - kl_loss: 2845669632.0000 - val_loss: 148139.5938 - val_reco_loss: 2636.4033 - val_kl_loss: 145503.1875 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 1457.8505 - reco_loss: 1433.6611 - kl_loss: 25.1278 - val_loss: 171897.8438 - val_reco_loss: 638.5152 - val_kl_loss: 171259.3281 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 465.9311 - reco_loss: 439.3833 - kl_loss: 26.3788 - val_loss: 165743.4375 - val_reco_loss: 394.9528 - val_kl_loss: 165348.4844 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1798/1800 [============================>.] - ETA: 0s - loss: 280.4256 - reco_loss: 255.9274 - kl_loss: 23.9409\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 280.3933 - reco_loss: 255.8960 - kl_loss: 23.9392 - val_loss: 151266.5938 - val_reco_loss: 262.8169 - val_kl_loss: 151003.7812 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 228.1419 - reco_loss: 205.0058 - kl_loss: 23.0269 - val_loss: 149153.1719 - val_reco_loss: 242.9484 - val_kl_loss: 148910.2188 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 219.1254 - reco_loss: 196.2685 - kl_loss: 22.6813 - val_loss: 145781.9062 - val_reco_loss: 232.0838 - val_kl_loss: 145549.8281 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 214.2159 - reco_loss: 192.0360 - kl_loss: 22.1280 - val_loss: 142007.0312 - val_reco_loss: 221.9692 - val_kl_loss: 141785.0625 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - ETA: 0s - loss: 209.3084 - reco_loss: 187.6448 - kl_loss: 21.4490\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 209.3057 - reco_loss: 187.6422 - kl_loss: 21.4490 - val_loss: 136962.3594 - val_reco_loss: 214.1181 - val_kl_loss: 136748.2344 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 6070.2412 - reco_loss: 5943.7258 - kl_loss: 100.7190 - val_loss: 311367.6875 - val_reco_loss: 161.8085 - val_kl_loss: 311205.8750 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 192.7280 - reco_loss: 153.8846 - kl_loss: 32.7220 - val_loss: 151464.5156 - val_reco_loss: 102.7278 - val_kl_loss: 151361.7812 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 107.7080 - reco_loss: 86.3961 - kl_loss: 18.9964 - val_loss: 98031.5781 - val_reco_loss: 84.1025 - val_kl_loss: 97947.4766 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 84.2215 - reco_loss: 70.0172 - kl_loss: 13.1404 - val_loss: 71688.3203 - val_reco_loss: 78.5817 - val_kl_loss: 71609.7422 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 75.4862 - reco_loss: 64.7089 - kl_loss: 10.3081 - val_loss: 61097.8906 - val_reco_loss: 118.6318 - val_kl_loss: 60979.2578 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 68.5014 - reco_loss: 59.2536 - kl_loss: 8.8751 - val_loss: 52780.8750 - val_reco_loss: 66.0816 - val_kl_loss: 52714.7930 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 65.5639 - reco_loss: 57.5674 - kl_loss: 7.7103 - val_loss: 45947.4414 - val_reco_loss: 71.4727 - val_kl_loss: 45875.9688 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 62.9394 - reco_loss: 55.8573 - kl_loss: 6.9543 - val_loss: 42394.6445 - val_reco_loss: 63.6427 - val_kl_loss: 42331.0000 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 61.2309 - reco_loss: 54.6744 - kl_loss: 6.4483 - val_loss: 39283.0117 - val_reco_loss: 56.4613 - val_kl_loss: 39226.5508 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.9269 - reco_loss: 52.7789 - kl_loss: 6.0623 - val_loss: 37362.8945 - val_reco_loss: 61.4429 - val_kl_loss: 37301.4531 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.4525 - reco_loss: 52.5994 - kl_loss: 5.7707 - val_loss: 36189.1289 - val_reco_loss: 68.8161 - val_kl_loss: 36120.3125 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.7813 - reco_loss: 54.0857 - kl_loss: 5.5980 - val_loss: 34233.4453 - val_reco_loss: 61.6163 - val_kl_loss: 34171.8281 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 55.6384 - reco_loss: 50.2717 - kl_loss: 5.3355 - val_loss: 32893.6250 - val_reco_loss: 61.3171 - val_kl_loss: 32832.3086 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 55.1945 - reco_loss: 50.0088 - kl_loss: 5.1472 - val_loss: 31862.9980 - val_reco_loss: 52.7165 - val_kl_loss: 31810.2812 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.4907 - reco_loss: 48.4664 - kl_loss: 4.9936 - val_loss: 30985.4883 - val_reco_loss: 58.0833 - val_kl_loss: 30927.4043 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.3317 - reco_loss: 51.4092 - kl_loss: 4.9637 - val_loss: 30808.1777 - val_reco_loss: 56.0914 - val_kl_loss: 30752.0859 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.4859 - reco_loss: 47.6093 - kl_loss: 4.8325 - val_loss: 29643.5137 - val_reco_loss: 52.1808 - val_kl_loss: 29591.3320 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.8853 - reco_loss: 53.0926 - kl_loss: 4.8133 - val_loss: 29791.7168 - val_reco_loss: 59.5261 - val_kl_loss: 29732.1914 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.8198 - reco_loss: 48.0843 - kl_loss: 4.7035 - val_loss: 28974.4844 - val_reco_loss: 61.2999 - val_kl_loss: 28913.1836 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.5562 - reco_loss: 48.9435 - kl_loss: 4.6107 - val_loss: 28520.2383 - val_reco_loss: 60.6790 - val_kl_loss: 28459.5586 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.1702 - reco_loss: 47.6252 - kl_loss: 4.5168 - val_loss: 27819.6191 - val_reco_loss: 50.6733 - val_kl_loss: 27768.9453 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.4463 - reco_loss: 47.0006 - kl_loss: 4.4094 - val_loss: 27158.2246 - val_reco_loss: 54.7104 - val_kl_loss: 27103.5137 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.2950 - reco_loss: 46.9724 - kl_loss: 4.3082 - val_loss: 26548.3711 - val_reco_loss: 50.6103 - val_kl_loss: 26497.7617 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.1900 - reco_loss: 46.9322 - kl_loss: 4.2614 - val_loss: 26482.3574 - val_reco_loss: 52.2666 - val_kl_loss: 26430.0898 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.7139 - reco_loss: 44.4898 - kl_loss: 4.2174 - val_loss: 25926.7168 - val_reco_loss: 51.7564 - val_kl_loss: 25874.9609 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.7567 - reco_loss: 46.6043 - kl_loss: 4.1581 - val_loss: 25873.1934 - val_reco_loss: 51.7910 - val_kl_loss: 25821.4023 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.9375 - reco_loss: 44.7846 - kl_loss: 4.1283 - val_loss: 25461.9902 - val_reco_loss: 49.7244 - val_kl_loss: 25412.2656 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.7559 - reco_loss: 45.6758 - kl_loss: 4.0526 - val_loss: 24937.4883 - val_reco_loss: 51.2789 - val_kl_loss: 24886.2090 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.2132 - reco_loss: 44.2259 - kl_loss: 3.9894 - val_loss: 24531.2207 - val_reco_loss: 52.6314 - val_kl_loss: 24478.5898 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.8447 - reco_loss: 44.8922 - kl_loss: 3.9437 - val_loss: 24291.7930 - val_reco_loss: 47.6046 - val_kl_loss: 24244.1875 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.1083 - reco_loss: 45.1972 - kl_loss: 3.8849 - val_loss: 23959.6855 - val_reco_loss: 58.8377 - val_kl_loss: 23900.8477 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.3502 - reco_loss: 45.4986 - kl_loss: 3.8617 - val_loss: 24014.9238 - val_reco_loss: 48.1868 - val_kl_loss: 23966.7363 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.9442 - reco_loss: 45.1034 - kl_loss: 3.8342 - val_loss: 23862.3281 - val_reco_loss: 54.3566 - val_kl_loss: 23807.9707 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.3763 - reco_loss: 44.5691 - kl_loss: 3.7879 - val_loss: 23292.8145 - val_reco_loss: 50.2763 - val_kl_loss: 23242.5391 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.8461 - reco_loss: 45.0987 - kl_loss: 3.7440 - val_loss: 23054.2422 - val_reco_loss: 52.2997 - val_kl_loss: 23001.9434 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.2689 - reco_loss: 43.5611 - kl_loss: 3.6970 - val_loss: 22792.0137 - val_reco_loss: 46.7170 - val_kl_loss: 22745.2969 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.5661 - reco_loss: 45.8679 - kl_loss: 3.6722 - val_loss: 22558.7598 - val_reco_loss: 48.6930 - val_kl_loss: 22510.0664 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.2962 - reco_loss: 44.6331 - kl_loss: 3.6624 - val_loss: 22706.6289 - val_reco_loss: 60.5174 - val_kl_loss: 22646.1113 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.6648 - reco_loss: 45.0009 - kl_loss: 3.6452 - val_loss: 22510.6973 - val_reco_loss: 51.2344 - val_kl_loss: 22459.4629 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.6586 - reco_loss: 43.0738 - kl_loss: 3.5812 - val_loss: 22166.5547 - val_reco_loss: 50.2186 - val_kl_loss: 22116.3359 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.3845 - reco_loss: 44.8267 - kl_loss: 3.5620 - val_loss: 22028.5996 - val_reco_loss: 51.1884 - val_kl_loss: 21977.4121 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.9569 - reco_loss: 43.4190 - kl_loss: 3.5412 - val_loss: 21932.3750 - val_reco_loss: 49.4858 - val_kl_loss: 21882.8887 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.1968 - reco_loss: 42.6762 - kl_loss: 3.5148 - val_loss: 21584.8613 - val_reco_loss: 51.4422 - val_kl_loss: 21533.4199 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.7202 - reco_loss: 43.2415 - kl_loss: 3.4855 - val_loss: 21511.7051 - val_reco_loss: 49.6463 - val_kl_loss: 21462.0586 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.9484 - reco_loss: 43.4791 - kl_loss: 3.4601 - val_loss: 21291.0273 - val_reco_loss: 52.6003 - val_kl_loss: 21238.4277 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.7479 - reco_loss: 43.3179 - kl_loss: 3.4172 - val_loss: 21038.8926 - val_reco_loss: 52.3180 - val_kl_loss: 20986.5742 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.3580 - reco_loss: 42.9643 - kl_loss: 3.3851 - val_loss: 20868.0703 - val_reco_loss: 46.7044 - val_kl_loss: 20821.3652 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.2412 - reco_loss: 42.8798 - kl_loss: 3.3603 - val_loss: 20722.7539 - val_reco_loss: 49.4300 - val_kl_loss: 20673.3242 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.5894 - reco_loss: 43.2437 - kl_loss: 3.3446 - val_loss: 20455.1699 - val_reco_loss: 49.4803 - val_kl_loss: 20405.6895 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.0848 - reco_loss: 44.7538 - kl_loss: 3.3268 - val_loss: 20455.2090 - val_reco_loss: 50.8564 - val_kl_loss: 20404.3535 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.6975 - reco_loss: 43.3788 - kl_loss: 3.3138 - val_loss: 20278.5020 - val_reco_loss: 48.3168 - val_kl_loss: 20230.1855 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.6102 - reco_loss: 45.2943 - kl_loss: 3.3020 - val_loss: 20190.6953 - val_reco_loss: 46.8936 - val_kl_loss: 20143.8008 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.8359 - reco_loss: 43.5529 - kl_loss: 3.3006 - val_loss: 20397.5781 - val_reco_loss: 51.3875 - val_kl_loss: 20346.1914 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.1051 - reco_loss: 43.8100 - kl_loss: 3.2847 - val_loss: 20118.8398 - val_reco_loss: 48.1261 - val_kl_loss: 20070.7129 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.1594 - reco_loss: 42.8964 - kl_loss: 3.2554 - val_loss: 19900.3184 - val_reco_loss: 46.9371 - val_kl_loss: 19853.3809 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.2341 - reco_loss: 44.9841 - kl_loss: 3.2507 - val_loss: 19957.0605 - val_reco_loss: 48.2082 - val_kl_loss: 19908.8516 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.6101 - reco_loss: 42.3845 - kl_loss: 3.2175 - val_loss: 19696.5371 - val_reco_loss: 49.2647 - val_kl_loss: 19647.2715 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.6547 - reco_loss: 42.4585 - kl_loss: 3.1925 - val_loss: 19638.0195 - val_reco_loss: 49.0900 - val_kl_loss: 19588.9297 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.8668 - reco_loss: 42.6972 - kl_loss: 3.1683 - val_loss: 19578.2969 - val_reco_loss: 50.1360 - val_kl_loss: 19528.1602 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.3525 - reco_loss: 43.1900 - kl_loss: 3.1500 - val_loss: 19345.6055 - val_reco_loss: 51.5059 - val_kl_loss: 19294.0996 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.2285 - reco_loss: 43.0926 - kl_loss: 3.1364 - val_loss: 19370.8672 - val_reco_loss: 49.3117 - val_kl_loss: 19321.5547 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.7032 - reco_loss: 42.5745 - kl_loss: 3.1241 - val_loss: 19193.2676 - val_reco_loss: 49.9160 - val_kl_loss: 19143.3516 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.2463 - reco_loss: 47.0897 - kl_loss: 3.1504 - val_loss: 19238.5508 - val_reco_loss: 45.9575 - val_kl_loss: 19192.5938 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.8233 - reco_loss: 42.6945 - kl_loss: 3.1314 - val_loss: 19292.1426 - val_reco_loss: 47.4990 - val_kl_loss: 19244.6445 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.2382 - reco_loss: 41.1238 - kl_loss: 3.1125 - val_loss: 18984.1074 - val_reco_loss: 47.5840 - val_kl_loss: 18936.5234 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.7893 - reco_loss: 42.6954 - kl_loss: 3.0855 - val_loss: 18907.1738 - val_reco_loss: 47.0174 - val_kl_loss: 18860.1562 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.7819 - reco_loss: 42.7056 - kl_loss: 3.0763 - val_loss: 18866.0684 - val_reco_loss: 51.3844 - val_kl_loss: 18814.6836 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.0008 - reco_loss: 42.9304 - kl_loss: 3.0703 - val_loss: 18855.7227 - val_reco_loss: 50.1444 - val_kl_loss: 18805.5781 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.8593 - reco_loss: 41.8033 - kl_loss: 3.0511 - val_loss: 18571.1602 - val_reco_loss: 49.1406 - val_kl_loss: 18522.0195 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.9181 - reco_loss: 42.8795 - kl_loss: 3.0312 - val_loss: 18527.7773 - val_reco_loss: 53.2145 - val_kl_loss: 18474.5625 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.2484 - reco_loss: 42.2311 - kl_loss: 3.0194 - val_loss: 18519.4688 - val_reco_loss: 47.3497 - val_kl_loss: 18472.1191 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.8733 - reco_loss: 40.8646 - kl_loss: 3.0102 - val_loss: 18483.7891 - val_reco_loss: 47.5866 - val_kl_loss: 18436.2031 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.8534 - reco_loss: 41.8515 - kl_loss: 2.9994 - val_loss: 18567.5098 - val_reco_loss: 47.7175 - val_kl_loss: 18519.7930 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.7529 - reco_loss: 41.7538 - kl_loss: 2.9969 - val_loss: 18297.2129 - val_reco_loss: 48.5558 - val_kl_loss: 18248.6562 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.9810 - reco_loss: 40.9914 - kl_loss: 2.9811 - val_loss: 18175.2871 - val_reco_loss: 48.9749 - val_kl_loss: 18126.3125 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.6790 - reco_loss: 41.7027 - kl_loss: 2.9735 - val_loss: 18133.0918 - val_reco_loss: 50.5763 - val_kl_loss: 18082.5156 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.0454 - reco_loss: 41.0833 - kl_loss: 2.9617 - val_loss: 18185.4785 - val_reco_loss: 49.8231 - val_kl_loss: 18135.6562 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.8279 - reco_loss: 41.8716 - kl_loss: 2.9571 - val_loss: 18043.5234 - val_reco_loss: 48.6480 - val_kl_loss: 17994.8750 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.7428 - reco_loss: 44.7890 - kl_loss: 2.9542 - val_loss: 18157.6719 - val_reco_loss: 50.5416 - val_kl_loss: 18107.1309 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.3682 - reco_loss: 41.4210 - kl_loss: 2.9431 - val_loss: 17972.2012 - val_reco_loss: 46.6964 - val_kl_loss: 17925.5039 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.0834 - reco_loss: 42.1423 - kl_loss: 2.9382 - val_loss: 17950.8672 - val_reco_loss: 46.0204 - val_kl_loss: 17904.8477 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.0928 - reco_loss: 42.1443 - kl_loss: 2.9421 - val_loss: 18122.0508 - val_reco_loss: 47.4455 - val_kl_loss: 18074.6055 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.1999 - reco_loss: 41.2693 - kl_loss: 2.9217 - val_loss: 17800.4531 - val_reco_loss: 53.0244 - val_kl_loss: 17747.4297 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.6803 - reco_loss: 42.7677 - kl_loss: 2.9072 - val_loss: 17857.9062 - val_reco_loss: 53.2861 - val_kl_loss: 17804.6211 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.1947 - reco_loss: 41.2891 - kl_loss: 2.9034 - val_loss: 17824.2852 - val_reco_loss: 52.3142 - val_kl_loss: 17771.9707 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.8305 - reco_loss: 41.9188 - kl_loss: 2.9014 - val_loss: 17732.6719 - val_reco_loss: 51.0205 - val_kl_loss: 17681.6523 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.8047 - reco_loss: 42.9073 - kl_loss: 2.8940 - val_loss: 17665.9648 - val_reco_loss: 48.5450 - val_kl_loss: 17617.4199 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.5467 - reco_loss: 41.6526 - kl_loss: 2.8879 - val_loss: 17557.7051 - val_reco_loss: 50.5841 - val_kl_loss: 17507.1211 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.4835 - reco_loss: 41.6009 - kl_loss: 2.8815 - val_loss: 17531.1191 - val_reco_loss: 45.9046 - val_kl_loss: 17485.2148 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.5528 - reco_loss: 40.6743 - kl_loss: 2.8796 - val_loss: 17505.5820 - val_reco_loss: 48.3910 - val_kl_loss: 17457.1914 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.0414 - reco_loss: 41.1654 - kl_loss: 2.8740 - val_loss: 17492.9316 - val_reco_loss: 48.2698 - val_kl_loss: 17444.6621 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.9049 - reco_loss: 41.0286 - kl_loss: 2.8675 - val_loss: 17753.8516 - val_reco_loss: 48.5063 - val_kl_loss: 17705.3457 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.8678 - reco_loss: 40.9812 - kl_loss: 2.8758 - val_loss: 17508.0137 - val_reco_loss: 48.7050 - val_kl_loss: 17459.3086 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.5639 - reco_loss: 40.7058 - kl_loss: 2.8581 - val_loss: 17428.3945 - val_reco_loss: 50.4490 - val_kl_loss: 17377.9453 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.3403 - reco_loss: 40.4833 - kl_loss: 2.8560 - val_loss: 17329.1055 - val_reco_loss: 47.4407 - val_kl_loss: 17281.6641 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.4340 - reco_loss: 40.5835 - kl_loss: 2.8486 - val_loss: 17346.8164 - val_reco_loss: 47.3043 - val_kl_loss: 17299.5117 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.5167 - reco_loss: 40.6666 - kl_loss: 2.8515 - val_loss: 17378.5723 - val_reco_loss: 45.9709 - val_kl_loss: 17332.6016 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.8454 - reco_loss: 40.9967 - kl_loss: 2.8490 - val_loss: 17575.6367 - val_reco_loss: 45.5862 - val_kl_loss: 17530.0508 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 42.9018 - reco_loss: 40.0601 - kl_loss: 2.8412 - val_loss: 17254.4414 - val_reco_loss: 46.7348 - val_kl_loss: 17207.7070 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.2574 - reco_loss: 40.4256 - kl_loss: 2.8355 - val_loss: 17274.7676 - val_reco_loss: 45.3611 - val_kl_loss: 17229.4062 - lr: 0.0010\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 4270.2739 - reco_loss: 4160.3887 - kl_loss: 87.3407 - val_loss: 268322.3750 - val_reco_loss: 355.0905 - val_kl_loss: 267967.2812 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 277.4446 - reco_loss: 239.7107 - kl_loss: 37.3492 - val_loss: 203257.7188 - val_reco_loss: 285.7412 - val_kl_loss: 202971.9844 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 167.7511 - reco_loss: 138.7133 - kl_loss: 26.1228 - val_loss: 135570.5781 - val_reco_loss: 219.8597 - val_kl_loss: 135350.7188 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 129.0841 - reco_loss: 108.9172 - kl_loss: 18.8813 - val_loss: 105312.0312 - val_reco_loss: 93.7883 - val_kl_loss: 105218.2422 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 95.0985 - reco_loss: 79.0964 - kl_loss: 15.1335 - val_loss: 84433.7969 - val_reco_loss: 69.4349 - val_kl_loss: 84364.3594 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 78.7654 - reco_loss: 65.9938 - kl_loss: 12.1413 - val_loss: 69339.2734 - val_reco_loss: 68.7892 - val_kl_loss: 69270.4844 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 72.9806 - reco_loss: 62.3494 - kl_loss: 10.3606 - val_loss: 60134.6016 - val_reco_loss: 68.6796 - val_kl_loss: 60065.9219 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 68.1528 - reco_loss: 58.8048 - kl_loss: 9.1560 - val_loss: 54388.7266 - val_reco_loss: 63.4121 - val_kl_loss: 54325.3125 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 77.1948 - reco_loss: 68.7387 - kl_loss: 8.8917 - val_loss: 96001.6484 - val_reco_loss: 386.5063 - val_kl_loss: 95615.1406 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1796/1800 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1791/1800 [============================>.] - ETA: 0s - loss: nan - reco_loss: nan - kl_loss: nan\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: nan - reco_loss: nan - kl_loss: nan - val_loss: nan - val_reco_loss: nan - val_kl_loss: nan - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 21190.0548 - reco_loss: 20561.2982 - kl_loss: 246.1029 - val_loss: 363250.1250 - val_reco_loss: 398.8809 - val_kl_loss: 362851.2500 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 272.3816 - reco_loss: 223.4232 - kl_loss: 42.7015 - val_loss: 206215.8125 - val_reco_loss: 170.9429 - val_kl_loss: 206044.8750 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 158.7140 - reco_loss: 129.8505 - kl_loss: 26.0849 - val_loss: 134500.4219 - val_reco_loss: 105.4465 - val_kl_loss: 134394.9688 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 107.6271 - reco_loss: 88.3592 - kl_loss: 17.7394 - val_loss: 95159.1094 - val_reco_loss: 82.8613 - val_kl_loss: 95076.2500 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 87.6626 - reco_loss: 73.6036 - kl_loss: 13.1925 - val_loss: 75167.8125 - val_reco_loss: 81.4657 - val_kl_loss: 75086.3438 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 76.3218 - reco_loss: 65.1481 - kl_loss: 10.6622 - val_loss: 61583.3516 - val_reco_loss: 69.1946 - val_kl_loss: 61514.1562 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 71.4887 - reco_loss: 62.0097 - kl_loss: 9.1458 - val_loss: 53589.7695 - val_reco_loss: 66.6507 - val_kl_loss: 53523.1172 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 68.1145 - reco_loss: 59.8698 - kl_loss: 8.0321 - val_loss: 47311.9492 - val_reco_loss: 69.5017 - val_kl_loss: 47242.4492 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 65.3712 - reco_loss: 57.9769 - kl_loss: 7.2269 - val_loss: 43534.4648 - val_reco_loss: 66.8457 - val_kl_loss: 43467.6172 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 68.8467 - reco_loss: 61.9030 - kl_loss: 6.9746 - val_loss: 42170.5547 - val_reco_loss: 60.5149 - val_kl_loss: 42110.0391 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 62.7039 - reco_loss: 56.0693 - kl_loss: 6.4994 - val_loss: 39208.9102 - val_reco_loss: 61.2339 - val_kl_loss: 39147.6758 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 61.3767 - reco_loss: 55.2161 - kl_loss: 6.0772 - val_loss: 36903.3164 - val_reco_loss: 67.4121 - val_kl_loss: 36835.9062 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.3560 - reco_loss: 53.5146 - kl_loss: 5.7511 - val_loss: 34824.2578 - val_reco_loss: 60.6170 - val_kl_loss: 34763.6406 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.1938 - reco_loss: 53.6308 - kl_loss: 5.4789 - val_loss: 32791.8984 - val_reco_loss: 65.6956 - val_kl_loss: 32726.2012 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.0270 - reco_loss: 53.7995 - kl_loss: 5.1947 - val_loss: 31510.7715 - val_reco_loss: 61.2019 - val_kl_loss: 31449.5703 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.4307 - reco_loss: 53.3607 - kl_loss: 5.0066 - val_loss: 30491.8359 - val_reco_loss: 60.8030 - val_kl_loss: 30431.0332 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.8076 - reco_loss: 51.9237 - kl_loss: 4.8946 - val_loss: 30539.6816 - val_reco_loss: 64.3783 - val_kl_loss: 30475.3027 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.2411 - reco_loss: 51.4239 - kl_loss: 4.7311 - val_loss: 28412.2852 - val_reco_loss: 73.6773 - val_kl_loss: 28338.6074 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.6766 - reco_loss: 53.0731 - kl_loss: 4.6260 - val_loss: 29391.5918 - val_reco_loss: 65.9531 - val_kl_loss: 29325.6387 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.1848 - reco_loss: 51.5120 - kl_loss: 4.5888 - val_loss: 27347.1133 - val_reco_loss: 66.4988 - val_kl_loss: 27280.6152 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 54.9395 - reco_loss: 50.5088 - kl_loss: 4.4117 - val_loss: 26806.3613 - val_reco_loss: 60.4864 - val_kl_loss: 26745.8750 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 55.1346 - reco_loss: 50.7887 - kl_loss: 4.3188 - val_loss: 26032.0957 - val_reco_loss: 67.8229 - val_kl_loss: 25964.2734 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.1454 - reco_loss: 54.7273 - kl_loss: 4.5630 - val_loss: 28467.5469 - val_reco_loss: 67.4967 - val_kl_loss: 28400.0508 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 55.7075 - reco_loss: 51.2077 - kl_loss: 4.4257 - val_loss: 26733.8066 - val_reco_loss: 64.6637 - val_kl_loss: 26669.1426 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.3529 - reco_loss: 49.0586 - kl_loss: 4.2532 - val_loss: 25837.4043 - val_reco_loss: 71.2071 - val_kl_loss: 25766.1973 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.5502 - reco_loss: 48.4251 - kl_loss: 4.0849 - val_loss: 25087.5762 - val_reco_loss: 69.5051 - val_kl_loss: 25018.0703 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.2977 - reco_loss: 49.2810 - kl_loss: 3.9977 - val_loss: 24550.9238 - val_reco_loss: 59.2986 - val_kl_loss: 24491.6250 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.1854 - reco_loss: 47.2295 - kl_loss: 3.9600 - val_loss: 24241.3008 - val_reco_loss: 59.4769 - val_kl_loss: 24181.8242 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.7994 - reco_loss: 46.8960 - kl_loss: 3.8840 - val_loss: 23638.9570 - val_reco_loss: 59.8663 - val_kl_loss: 23579.0898 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.8260 - reco_loss: 47.9789 - kl_loss: 3.8438 - val_loss: 23602.6250 - val_reco_loss: 65.0450 - val_kl_loss: 23537.5801 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.9862 - reco_loss: 48.0970 - kl_loss: 3.9113 - val_loss: 24040.2363 - val_reco_loss: 60.5513 - val_kl_loss: 23979.6855 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.2967 - reco_loss: 46.4479 - kl_loss: 3.8139 - val_loss: 23145.0020 - val_reco_loss: 56.9308 - val_kl_loss: 23088.0703 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.7682 - reco_loss: 52.9671 - kl_loss: 3.8324 - val_loss: 23716.2285 - val_reco_loss: 64.9542 - val_kl_loss: 23651.2734 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.4584 - reco_loss: 48.6473 - kl_loss: 3.7968 - val_loss: 23035.5957 - val_reco_loss: 93.1322 - val_kl_loss: 22942.4629 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.3059 - reco_loss: 48.5530 - kl_loss: 3.7472 - val_loss: 23097.7695 - val_reco_loss: 66.7073 - val_kl_loss: 23031.0625 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.9802 - reco_loss: 47.2622 - kl_loss: 3.7232 - val_loss: 22763.7715 - val_reco_loss: 74.4250 - val_kl_loss: 22689.3457 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.5004 - reco_loss: 46.8258 - kl_loss: 3.6674 - val_loss: 22553.4258 - val_reco_loss: 57.4891 - val_kl_loss: 22495.9375 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.4873 - reco_loss: 47.8397 - kl_loss: 3.6378 - val_loss: 22271.3379 - val_reco_loss: 62.6623 - val_kl_loss: 22208.6758 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.1630 - reco_loss: 47.5609 - kl_loss: 3.6017 - val_loss: 22096.8418 - val_reco_loss: 66.6189 - val_kl_loss: 22030.2227 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.0344 - reco_loss: 48.4485 - kl_loss: 3.5686 - val_loss: 21691.2773 - val_reco_loss: 65.7809 - val_kl_loss: 21625.4961 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.4369 - reco_loss: 55.8381 - kl_loss: 3.5803 - val_loss: 21893.1387 - val_reco_loss: 60.1071 - val_kl_loss: 21833.0312 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.9780 - reco_loss: 46.4331 - kl_loss: 3.5264 - val_loss: 21598.7676 - val_reco_loss: 61.6429 - val_kl_loss: 21537.1250 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.7059 - reco_loss: 45.2016 - kl_loss: 3.4884 - val_loss: 21037.8867 - val_reco_loss: 61.1899 - val_kl_loss: 20976.6973 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.9971 - reco_loss: 45.5429 - kl_loss: 3.4570 - val_loss: 21038.9199 - val_reco_loss: 59.8378 - val_kl_loss: 20979.0820 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.5715 - reco_loss: 44.1419 - kl_loss: 3.4294 - val_loss: 20741.3926 - val_reco_loss: 63.9346 - val_kl_loss: 20677.4570 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.8880 - reco_loss: 44.4781 - kl_loss: 3.4095 - val_loss: 20842.9531 - val_reco_loss: 63.8135 - val_kl_loss: 20779.1406 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.8242 - reco_loss: 45.4369 - kl_loss: 3.3889 - val_loss: 20652.3145 - val_reco_loss: 64.0181 - val_kl_loss: 20588.2969 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.8758 - reco_loss: 44.4868 - kl_loss: 3.4412 - val_loss: 21677.6367 - val_reco_loss: 62.0031 - val_kl_loss: 21615.6328 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.2784 - reco_loss: 43.8019 - kl_loss: 3.4503 - val_loss: 20674.6074 - val_reco_loss: 62.2294 - val_kl_loss: 20612.3789 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.8695 - reco_loss: 43.5162 - kl_loss: 3.3450 - val_loss: 20465.6191 - val_reco_loss: 69.2402 - val_kl_loss: 20396.3789 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.6506 - reco_loss: 44.3119 - kl_loss: 3.3282 - val_loss: 20158.7773 - val_reco_loss: 65.9358 - val_kl_loss: 20092.8418 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.7780 - reco_loss: 43.4801 - kl_loss: 3.3010 - val_loss: 20212.3633 - val_reco_loss: 64.3272 - val_kl_loss: 20148.0352 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.8193 - reco_loss: 44.4820 - kl_loss: 3.3533 - val_loss: 20459.0293 - val_reco_loss: 66.5806 - val_kl_loss: 20392.4492 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.8745 - reco_loss: 44.5375 - kl_loss: 3.3329 - val_loss: 20449.4668 - val_reco_loss: 60.8396 - val_kl_loss: 20388.6270 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.3334 - reco_loss: 44.0288 - kl_loss: 3.2794 - val_loss: 19936.2070 - val_reco_loss: 73.2829 - val_kl_loss: 19862.9238 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.9727 - reco_loss: 43.7192 - kl_loss: 3.2489 - val_loss: 19892.8965 - val_reco_loss: 79.4081 - val_kl_loss: 19813.4883 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.9267 - reco_loss: 42.6964 - kl_loss: 3.2337 - val_loss: 19827.2188 - val_reco_loss: 56.1600 - val_kl_loss: 19771.0586 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.3800 - reco_loss: 43.1490 - kl_loss: 3.2238 - val_loss: 19624.0117 - val_reco_loss: 64.5992 - val_kl_loss: 19559.4121 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.2201 - reco_loss: 43.0008 - kl_loss: 3.2158 - val_loss: 19597.2695 - val_reco_loss: 62.5203 - val_kl_loss: 19534.7500 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.1883 - reco_loss: 43.9737 - kl_loss: 3.2128 - val_loss: 19718.3184 - val_reco_loss: 61.6238 - val_kl_loss: 19656.6953 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.4594 - reco_loss: 42.2711 - kl_loss: 3.1885 - val_loss: 19426.2012 - val_reco_loss: 60.8492 - val_kl_loss: 19365.3516 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.5728 - reco_loss: 44.3904 - kl_loss: 3.1853 - val_loss: 19336.6719 - val_reco_loss: 61.4390 - val_kl_loss: 19275.2324 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.6326 - reco_loss: 42.4674 - kl_loss: 3.1659 - val_loss: 19309.5625 - val_reco_loss: 65.1341 - val_kl_loss: 19244.4277 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.8194 - reco_loss: 43.6648 - kl_loss: 3.1571 - val_loss: 19633.3457 - val_reco_loss: 65.6191 - val_kl_loss: 19567.7266 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.5287 - reco_loss: 42.3365 - kl_loss: 3.1796 - val_loss: 19588.4785 - val_reco_loss: 59.4572 - val_kl_loss: 19529.0215 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.8189 - reco_loss: 55.5883 - kl_loss: 3.2847 - val_loss: 20201.8379 - val_reco_loss: 66.5333 - val_kl_loss: 20135.3047 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "1789/1800 [============================>.] - ETA: 0s - loss: 46.3255 - reco_loss: 43.0267 - kl_loss: 3.2904\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.3348 - reco_loss: 43.0361 - kl_loss: 3.2901 - val_loss: 19761.0391 - val_reco_loss: 64.9604 - val_kl_loss: 19696.0781 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.7070 - reco_loss: 40.4629 - kl_loss: 3.2475 - val_loss: 19805.3320 - val_reco_loss: 61.9639 - val_kl_loss: 19743.3672 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.9018 - reco_loss: 40.6558 - kl_loss: 3.2455 - val_loss: 19806.7207 - val_reco_loss: 61.4438 - val_kl_loss: 19745.2773 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.9616 - reco_loss: 40.7236 - kl_loss: 3.2361 - val_loss: 19723.4805 - val_reco_loss: 61.3932 - val_kl_loss: 19662.0879 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1797/1800 [============================>.] - ETA: 0s - loss: 44.1349 - reco_loss: 40.9120 - kl_loss: 3.2177\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.1338 - reco_loss: 40.9109 - kl_loss: 3.2176 - val_loss: 19550.2344 - val_reco_loss: 63.2106 - val_kl_loss: 19487.0234 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 13s 5ms/step - loss: 6222.1512 - reco_loss: 6117.5355 - kl_loss: 88.6344 - val_loss: 292179.4375 - val_reco_loss: 143.9607 - val_kl_loss: 292035.4688 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 150.4126 - reco_loss: 113.2144 - kl_loss: 31.2193 - val_loss: 140619.0312 - val_reco_loss: 97.4396 - val_kl_loss: 140521.5938 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 100.4708 - reco_loss: 81.1088 - kl_loss: 17.3557 - val_loss: 88531.3672 - val_reco_loss: 79.9940 - val_kl_loss: 88451.3750 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 88.4540 - reco_loss: 75.5110 - kl_loss: 12.5112 - val_loss: 71551.1641 - val_reco_loss: 72.5416 - val_kl_loss: 71478.6250 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 74.4723 - reco_loss: 63.8281 - kl_loss: 10.0444 - val_loss: 56807.8945 - val_reco_loss: 66.0153 - val_kl_loss: 56741.8789 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 70.0124 - reco_loss: 61.3496 - kl_loss: 8.2850 - val_loss: 47576.8086 - val_reco_loss: 94.2426 - val_kl_loss: 47482.5664 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 69.9661 - reco_loss: 62.5448 - kl_loss: 7.2480 - val_loss: 43559.7734 - val_reco_loss: 65.1465 - val_kl_loss: 43494.6250 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 65.0975 - reco_loss: 58.3486 - kl_loss: 6.6703 - val_loss: 40523.7266 - val_reco_loss: 64.7664 - val_kl_loss: 40458.9609 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46317186.1685 - reco_loss: 45501621.2821 - kl_loss: 1448267.5000 - val_loss: 212051.4844 - val_reco_loss: 239.4524 - val_kl_loss: 211812.0312 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 253.0047 - reco_loss: 222.8863 - kl_loss: 28.1859 - val_loss: 159712.4375 - val_reco_loss: 151.4622 - val_kl_loss: 159560.9688 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 156.9499 - reco_loss: 134.4612 - kl_loss: 21.3490 - val_loss: 129143.0859 - val_reco_loss: 110.8985 - val_kl_loss: 129032.1875 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1798/1800 [============================>.] - ETA: 0s - loss: 119.6427 - reco_loss: 100.7620 - kl_loss: 18.1098\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 119.6346 - reco_loss: 100.7552 - kl_loss: 18.1062 - val_loss: 107480.3047 - val_reco_loss: 100.8284 - val_kl_loss: 107379.4766 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 106.2112 - reco_loss: 89.7129 - kl_loss: 16.4093 - val_loss: 105702.5859 - val_reco_loss: 94.6616 - val_kl_loss: 105607.9219 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 102.7131 - reco_loss: 86.5328 - kl_loss: 16.1118 - val_loss: 103330.4375 - val_reco_loss: 92.9374 - val_kl_loss: 103237.5000 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 101.3556 - reco_loss: 85.5324 - kl_loss: 15.7474 - val_loss: 100832.9453 - val_reco_loss: 91.9298 - val_kl_loss: 100741.0156 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1795/1800 [============================>.] - ETA: 0s - loss: 100.9212 - reco_loss: 85.3579 - kl_loss: 15.3409\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 100.9143 - reco_loss: 85.3518 - kl_loss: 15.3409 - val_loss: 97888.7344 - val_reco_loss: 89.5601 - val_kl_loss: 97799.1719 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 4141.5303 - reco_loss: 3999.7549 - kl_loss: 105.8512 - val_loss: 289901.3125 - val_reco_loss: 170.4878 - val_kl_loss: 289730.8125 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 179.8011 - reco_loss: 143.9800 - kl_loss: 29.6948 - val_loss: 135811.8750 - val_reco_loss: 92.0401 - val_kl_loss: 135719.8281 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 95.4776 - reco_loss: 76.7421 - kl_loss: 16.5509 - val_loss: 83079.3750 - val_reco_loss: 86.8720 - val_kl_loss: 82992.5000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 80.0857 - reco_loss: 67.9684 - kl_loss: 11.2275 - val_loss: 61286.7539 - val_reco_loss: 75.6217 - val_kl_loss: 61211.1328 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 73.8027 - reco_loss: 64.5878 - kl_loss: 8.7079 - val_loss: 49198.8242 - val_reco_loss: 90.8804 - val_kl_loss: 49107.9453 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 83.8524 - reco_loss: 75.9428 - kl_loss: 7.6930 - val_loss: 44500.6016 - val_reco_loss: 73.2871 - val_kl_loss: 44427.3125 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.1398 - reco_loss: 46.4218 - kl_loss: 4.7033 - val_loss: 28354.9082 - val_reco_loss: 53.9627 - val_kl_loss: 28300.9453 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 67.0285 - reco_loss: 62.4165 - kl_loss: 4.8643 - val_loss: 35243.7773 - val_reco_loss: 107.2658 - val_kl_loss: 35136.5117 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 100.1078 - reco_loss: 94.4584 - kl_loss: 5.5920 - val_loss: 33326.8672 - val_reco_loss: 65.7433 - val_kl_loss: 33261.1250 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 5567.7678 - reco_loss: 5543.7576 - kl_loss: 30.6250 - val_loss: 44057.4766 - val_reco_loss: 146.6938 - val_kl_loss: 43910.7812 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1795/1800 [============================>.] - ETA: 0s - loss: 109.7512 - reco_loss: 102.7501 - kl_loss: 6.8732\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 109.7078 - reco_loss: 102.7071 - kl_loss: 6.8724 - val_loss: 40851.9297 - val_reco_loss: 96.2188 - val_kl_loss: 40755.7109 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 75.7728 - reco_loss: 69.1720 - kl_loss: 6.5930 - val_loss: 40482.3828 - val_reco_loss: 90.0858 - val_kl_loss: 40392.2969 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 73.0610 - reco_loss: 66.5300 - kl_loss: 6.5106 - val_loss: 39844.4141 - val_reco_loss: 85.1034 - val_kl_loss: 39759.3125 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 69.5922 - reco_loss: 63.1889 - kl_loss: 6.3918 - val_loss: 39093.2148 - val_reco_loss: 83.3936 - val_kl_loss: 39009.8203 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1799/1800 [============================>.] - ETA: 0s - loss: 66.4020 - reco_loss: 60.0994 - kl_loss: 6.2827\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 66.4026 - reco_loss: 60.1000 - kl_loss: 6.2826 - val_loss: 38568.0117 - val_reco_loss: 80.7282 - val_kl_loss: 38487.2852 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 5235.0164 - reco_loss: 5099.7456 - kl_loss: 101.8091 - val_loss: 332141.2188 - val_reco_loss: 182.6819 - val_kl_loss: 331958.5312 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 152.4540 - reco_loss: 116.2396 - kl_loss: 30.0252 - val_loss: 155521.1562 - val_reco_loss: 90.4390 - val_kl_loss: 155430.7188 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 88.6571 - reco_loss: 70.3813 - kl_loss: 16.3463 - val_loss: 98582.7656 - val_reco_loss: 80.2274 - val_kl_loss: 98502.5391 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 69.5001 - reco_loss: 57.2246 - kl_loss: 11.4453 - val_loss: 73923.0078 - val_reco_loss: 61.6528 - val_kl_loss: 73861.3516 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 64.9551 - reco_loss: 55.3942 - kl_loss: 9.0627 - val_loss: 60327.4453 - val_reco_loss: 66.2950 - val_kl_loss: 60261.1484 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.3265 - reco_loss: 48.4113 - kl_loss: 7.6911 - val_loss: 52962.7812 - val_reco_loss: 56.4454 - val_kl_loss: 52906.3359 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.7742 - reco_loss: 44.7428 - kl_loss: 6.8731 - val_loss: 47488.9141 - val_reco_loss: 49.3372 - val_kl_loss: 47439.5781 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.2850 - reco_loss: 40.9389 - kl_loss: 6.2480 - val_loss: 43318.6055 - val_reco_loss: 46.4249 - val_kl_loss: 43272.1797 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 162.9020 - reco_loss: 152.9699 - kl_loss: 9.1035 - val_loss: 58173.2461 - val_reco_loss: 106.2452 - val_kl_loss: 58067.0000 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 88.6700 - reco_loss: 81.0983 - kl_loss: 7.1234 - val_loss: 44766.8789 - val_reco_loss: 77.6296 - val_kl_loss: 44689.2500 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1791/1800 [============================>.] - ETA: 0s - loss: 59.5827 - reco_loss: 53.6253 - kl_loss: 5.7403\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 59.5783 - reco_loss: 53.6220 - kl_loss: 5.7383 - val_loss: 38343.6445 - val_reco_loss: 61.7475 - val_kl_loss: 38281.8984 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 53.0685 - reco_loss: 47.7231 - kl_loss: 5.3387 - val_loss: 38163.8984 - val_reco_loss: 54.2424 - val_kl_loss: 38109.6562 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.2951 - reco_loss: 46.9763 - kl_loss: 5.2962 - val_loss: 37755.6562 - val_reco_loss: 52.5656 - val_kl_loss: 37703.0898 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.5732 - reco_loss: 45.3287 - kl_loss: 5.2341 - val_loss: 37341.5742 - val_reco_loss: 51.6293 - val_kl_loss: 37289.9453 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1796/1800 [============================>.] - ETA: 0s - loss: 50.2419 - reco_loss: 45.0533 - kl_loss: 5.1627\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 50.2398 - reco_loss: 45.0513 - kl_loss: 5.1631 - val_loss: 36771.4766 - val_reco_loss: 52.7650 - val_kl_loss: 36718.7109 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 7513.3679 - reco_loss: 7375.9406 - kl_loss: 104.4794 - val_loss: 311463.7188 - val_reco_loss: 128.9952 - val_kl_loss: 311334.7188 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 152.1235 - reco_loss: 118.1546 - kl_loss: 28.7909 - val_loss: 154088.8750 - val_reco_loss: 77.1211 - val_kl_loss: 154011.7500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 93.4722 - reco_loss: 75.1042 - kl_loss: 16.4342 - val_loss: 98701.9062 - val_reco_loss: 81.7025 - val_kl_loss: 98620.2031 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 77.3986 - reco_loss: 64.9537 - kl_loss: 11.5774 - val_loss: 74765.7891 - val_reco_loss: 65.5244 - val_kl_loss: 74700.2656 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 67.3896 - reco_loss: 57.8041 - kl_loss: 9.2079 - val_loss: 62719.9922 - val_reco_loss: 50.9024 - val_kl_loss: 62669.0898 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.6534 - reco_loss: 49.3581 - kl_loss: 7.9975 - val_loss: 55644.6328 - val_reco_loss: 54.7612 - val_kl_loss: 55589.8711 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.1828 - reco_loss: 41.8873 - kl_loss: 7.0678 - val_loss: 49768.5742 - val_reco_loss: 40.1286 - val_kl_loss: 49728.4453 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.0320 - reco_loss: 38.3641 - kl_loss: 6.5364 - val_loss: 45051.7812 - val_reco_loss: 35.3765 - val_kl_loss: 45016.4062 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.3528 - reco_loss: 37.3059 - kl_loss: 5.9395 - val_loss: 42546.0586 - val_reco_loss: 41.8852 - val_kl_loss: 42504.1719 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 2103602405.0392 - reco_loss: 2103135666.1915 - kl_loss: 1419602.3750 - val_loss: 141615.3594 - val_reco_loss: 320.6424 - val_kl_loss: 141294.7188 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 218.3303 - reco_loss: 198.7683 - kl_loss: 19.5957 - val_loss: 143918.9844 - val_reco_loss: 143.1642 - val_kl_loss: 143775.8125 - lr: 0.0010\n",
      "Epoch 12/100\n",
      " 507/1800 [=======>......................] - ETA: 6s - loss: 126.7203 - reco_loss: 107.2751 - kl_loss: 19.3901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 1975.4608 - reco_loss: 1864.3125 - kl_loss: 104.1353 - val_loss: 724596.5625 - val_reco_loss: 1004.7347 - val_kl_loss: 723591.8125 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1797/1800 [============================>.] - ETA: 0s - loss: 744.9342 - reco_loss: 656.3452 - kl_loss: 84.4427\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 744.8184 - reco_loss: 656.2387 - kl_loss: 84.4287 - val_loss: 587708.3750 - val_reco_loss: 626.2408 - val_kl_loss: 587082.1250 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 577.7378 - reco_loss: 502.4379 - kl_loss: 74.5190 - val_loss: 567136.7500 - val_reco_loss: 593.1060 - val_kl_loss: 566543.6250 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 115.8783 - reco_loss: 95.9252 - kl_loss: 18.2924 - val_loss: 114799.6484 - val_reco_loss: 90.3189 - val_kl_loss: 114709.3281 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 83.0514 - reco_loss: 68.4731 - kl_loss: 13.6156 - val_loss: 88793.2812 - val_reco_loss: 65.6180 - val_kl_loss: 88727.6641 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 66.3080 - reco_loss: 55.0479 - kl_loss: 10.7024 - val_loss: 71644.8281 - val_reco_loss: 59.1952 - val_kl_loss: 71585.6328 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.4201 - reco_loss: 48.2580 - kl_loss: 8.8096 - val_loss: 62091.4688 - val_reco_loss: 49.2894 - val_kl_loss: 62042.1797 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.7630 - reco_loss: 44.8064 - kl_loss: 7.6522 - val_loss: 53394.1797 - val_reco_loss: 44.5482 - val_kl_loss: 53349.6328 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.4748 - reco_loss: 42.4783 - kl_loss: 6.7787 - val_loss: 47597.1953 - val_reco_loss: 38.4225 - val_kl_loss: 47558.7734 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.4857 - reco_loss: 41.1390 - kl_loss: 6.2111 - val_loss: 43712.1953 - val_reco_loss: 35.1767 - val_kl_loss: 43677.0195 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.9050 - reco_loss: 38.0754 - kl_loss: 5.7083 - val_loss: 40295.7773 - val_reco_loss: 39.4685 - val_kl_loss: 40256.3086 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 42.9531 - reco_loss: 37.5506 - kl_loss: 5.3381 - val_loss: 37909.9180 - val_reco_loss: 39.9771 - val_kl_loss: 37869.9414 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 41.6691 - reco_loss: 36.5698 - kl_loss: 5.0187 - val_loss: 35836.1367 - val_reco_loss: 35.6779 - val_kl_loss: 35800.4570 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 41.2930 - reco_loss: 36.4684 - kl_loss: 4.7709 - val_loss: 33961.6797 - val_reco_loss: 33.8297 - val_kl_loss: 33927.8516 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.2384 - reco_loss: 35.6062 - kl_loss: 4.5747 - val_loss: 32832.7227 - val_reco_loss: 40.7046 - val_kl_loss: 32792.0195 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.0300 - reco_loss: 35.5444 - kl_loss: 4.4220 - val_loss: 31606.3320 - val_reco_loss: 33.6246 - val_kl_loss: 31572.7070 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.0872 - reco_loss: 33.8138 - kl_loss: 4.2560 - val_loss: 30495.0820 - val_reco_loss: 35.2926 - val_kl_loss: 30459.7891 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.2152 - reco_loss: 33.0604 - kl_loss: 4.1304 - val_loss: 29719.1836 - val_reco_loss: 43.7529 - val_kl_loss: 29675.4297 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.9386 - reco_loss: 34.8733 - kl_loss: 4.0379 - val_loss: 28949.6484 - val_reco_loss: 37.7421 - val_kl_loss: 28911.9062 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.2364 - reco_loss: 33.2674 - kl_loss: 3.9630 - val_loss: 28492.1484 - val_reco_loss: 34.4960 - val_kl_loss: 28457.6523 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.2837 - reco_loss: 33.3654 - kl_loss: 3.9148 - val_loss: 28257.2695 - val_reco_loss: 38.2467 - val_kl_loss: 28219.0234 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1124/1800 [=================>............] - ETA: 3s - loss: 37.3578 - reco_loss: 33.4762 - kl_loss: 3.8649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.8246 - reco_loss: 26.6641 - kl_loss: 3.1532 - val_loss: 22430.2715 - val_reco_loss: 30.1933 - val_kl_loss: 22400.0781 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5804 - reco_loss: 26.4455 - kl_loss: 3.1271 - val_loss: 22319.3574 - val_reco_loss: 29.9127 - val_kl_loss: 22289.4453 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5394 - reco_loss: 26.4260 - kl_loss: 3.1108 - val_loss: 22223.0605 - val_reco_loss: 30.0840 - val_kl_loss: 22192.9766 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3566 - reco_loss: 26.3084 - kl_loss: 3.0504 - val_loss: 21798.5703 - val_reco_loss: 29.7939 - val_kl_loss: 21768.7773 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.4153 - reco_loss: 26.3690 - kl_loss: 3.0444 - val_loss: 21728.4434 - val_reco_loss: 29.5754 - val_kl_loss: 21698.8672 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.9234 - reco_loss: 26.8788 - kl_loss: 3.0391 - val_loss: 21730.6777 - val_reco_loss: 30.3776 - val_kl_loss: 21700.3008 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3214 - reco_loss: 26.2908 - kl_loss: 3.0343 - val_loss: 21621.4297 - val_reco_loss: 29.5931 - val_kl_loss: 21591.8359 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7131 - reco_loss: 26.6800 - kl_loss: 3.0268 - val_loss: 21601.5918 - val_reco_loss: 29.9396 - val_kl_loss: 21571.6523 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7029 - reco_loss: 26.6820 - kl_loss: 3.0212 - val_loss: 21557.1270 - val_reco_loss: 30.0520 - val_kl_loss: 21527.0742 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.0662 - reco_loss: 26.0495 - kl_loss: 3.0161 - val_loss: 21524.0332 - val_reco_loss: 29.6460 - val_kl_loss: 21494.3867 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.0944 - reco_loss: 26.0818 - kl_loss: 3.0106 - val_loss: 21487.5020 - val_reco_loss: 29.6572 - val_kl_loss: 21457.8438 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.2992 - reco_loss: 26.2909 - kl_loss: 3.0060 - val_loss: 21445.6367 - val_reco_loss: 28.8756 - val_kl_loss: 21416.7617 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5817 - reco_loss: 26.5799 - kl_loss: 3.0009 - val_loss: 21418.8105 - val_reco_loss: 28.7588 - val_kl_loss: 21390.0527 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7770 - reco_loss: 26.7845 - kl_loss: 2.9953 - val_loss: 21336.2383 - val_reco_loss: 30.0479 - val_kl_loss: 21306.1895 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3116 - reco_loss: 26.3177 - kl_loss: 2.9910 - val_loss: 21326.7422 - val_reco_loss: 30.7376 - val_kl_loss: 21296.0039 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.2376 - reco_loss: 26.2521 - kl_loss: 2.9864 - val_loss: 21337.3965 - val_reco_loss: 29.3763 - val_kl_loss: 21308.0195 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.0995 - reco_loss: 26.1138 - kl_loss: 2.9816 - val_loss: 21272.4062 - val_reco_loss: 29.6219 - val_kl_loss: 21242.7852 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.0479 - reco_loss: 26.0733 - kl_loss: 2.9763 - val_loss: 21287.7324 - val_reco_loss: 29.8066 - val_kl_loss: 21257.9258 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5843 - reco_loss: 26.6086 - kl_loss: 2.9727 - val_loss: 21203.5723 - val_reco_loss: 29.5403 - val_kl_loss: 21174.0312 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.4819 - reco_loss: 26.5120 - kl_loss: 2.9684 - val_loss: 21156.6172 - val_reco_loss: 30.0708 - val_kl_loss: 21126.5469 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3291 - reco_loss: 26.3631 - kl_loss: 2.9637 - val_loss: 21129.9473 - val_reco_loss: 29.2519 - val_kl_loss: 21100.6953 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      " 663/1800 [==========>...................] - ETA: 5s - loss: 28.9755 - reco_loss: 26.0155 - kl_loss: 2.9618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 41.4917 - reco_loss: 36.9811 - kl_loss: 4.4542 - val_loss: 31369.7070 - val_reco_loss: 53.2602 - val_kl_loss: 31316.4473 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.4347 - reco_loss: 36.1255 - kl_loss: 4.2666 - val_loss: 30204.2441 - val_reco_loss: 37.9539 - val_kl_loss: 30166.2910 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 39.4137 - reco_loss: 35.2543 - kl_loss: 4.1610 - val_loss: 29661.0996 - val_reco_loss: 34.6690 - val_kl_loss: 29626.4297 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.6458 - reco_loss: 31.0979 - kl_loss: 3.5484 - val_loss: 25495.3164 - val_reco_loss: 35.1250 - val_kl_loss: 25460.1914 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.6217 - reco_loss: 31.0793 - kl_loss: 3.5190 - val_loss: 24772.5273 - val_reco_loss: 34.4797 - val_kl_loss: 24738.0469 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.9376 - reco_loss: 31.4622 - kl_loss: 3.4645 - val_loss: 24456.8672 - val_reco_loss: 35.0623 - val_kl_loss: 24421.8047 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.2833 - reco_loss: 30.8396 - kl_loss: 3.4331 - val_loss: 24248.3516 - val_reco_loss: 34.5760 - val_kl_loss: 24213.7754 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.8529 - reco_loss: 30.4549 - kl_loss: 3.4027 - val_loss: 24231.5977 - val_reco_loss: 46.3429 - val_kl_loss: 24185.2539 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.4770 - reco_loss: 30.0801 - kl_loss: 3.3976 - val_loss: 24064.6152 - val_reco_loss: 37.0894 - val_kl_loss: 24027.5254 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.6331 - reco_loss: 30.2626 - kl_loss: 3.3623 - val_loss: 23878.8125 - val_reco_loss: 36.7803 - val_kl_loss: 23842.0312 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.7224 - reco_loss: 31.3665 - kl_loss: 3.3603 - val_loss: 23701.6230 - val_reco_loss: 45.3729 - val_kl_loss: 23656.2500 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.2394 - reco_loss: 30.8948 - kl_loss: 3.3292 - val_loss: 23449.7598 - val_reco_loss: 34.6304 - val_kl_loss: 23415.1289 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.2005 - reco_loss: 29.9097 - kl_loss: 3.2914 - val_loss: 23285.0547 - val_reco_loss: 55.2884 - val_kl_loss: 23229.7656 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.8517 - reco_loss: 30.5811 - kl_loss: 3.2699 - val_loss: 23021.4434 - val_reco_loss: 35.8116 - val_kl_loss: 22985.6309 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.0915 - reco_loss: 30.8307 - kl_loss: 3.2550 - val_loss: 23185.0977 - val_reco_loss: 38.0916 - val_kl_loss: 23147.0059 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.7429 - reco_loss: 31.4919 - kl_loss: 3.2423 - val_loss: 22928.8906 - val_reco_loss: 31.0127 - val_kl_loss: 22897.8789 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.6902 - reco_loss: 30.4421 - kl_loss: 3.2478 - val_loss: 22895.8457 - val_reco_loss: 37.7171 - val_kl_loss: 22858.1289 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.3827 - reco_loss: 29.1637 - kl_loss: 3.2190 - val_loss: 22691.4863 - val_reco_loss: 35.8608 - val_kl_loss: 22655.6250 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.8355 - reco_loss: 29.6244 - kl_loss: 3.2165 - val_loss: 22846.2207 - val_reco_loss: 33.9002 - val_kl_loss: 22812.3203 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.5885 - reco_loss: 31.3681 - kl_loss: 3.2044 - val_loss: 22874.2812 - val_reco_loss: 34.5381 - val_kl_loss: 22839.7441 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.6894 - reco_loss: 29.5000 - kl_loss: 3.1807 - val_loss: 22486.4844 - val_reco_loss: 39.6791 - val_kl_loss: 22446.8047 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1539/1800 [========================>.....] - ETA: 1s - loss: 33.0728 - reco_loss: 29.9115 - kl_loss: 3.1620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.2820 - reco_loss: 28.3556 - kl_loss: 2.9237 - val_loss: 20623.5391 - val_reco_loss: 29.4972 - val_kl_loss: 20594.0410 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7988 - reco_loss: 27.8841 - kl_loss: 2.9184 - val_loss: 20617.2793 - val_reco_loss: 30.2033 - val_kl_loss: 20587.0762 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7426 - reco_loss: 27.8342 - kl_loss: 2.9095 - val_loss: 20534.1895 - val_reco_loss: 29.3759 - val_kl_loss: 20504.8145 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.9107 - reco_loss: 28.0402 - kl_loss: 2.8792 - val_loss: 20547.0781 - val_reco_loss: 29.4611 - val_kl_loss: 20517.6172 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.4805 - reco_loss: 27.5866 - kl_loss: 2.8878 - val_loss: 20309.8203 - val_reco_loss: 29.7854 - val_kl_loss: 20280.0352 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.4927 - reco_loss: 27.6161 - kl_loss: 2.8731 - val_loss: 20130.4219 - val_reco_loss: 32.6946 - val_kl_loss: 20097.7266 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.0019 - reco_loss: 28.1531 - kl_loss: 2.8460 - val_loss: 20117.1523 - val_reco_loss: 29.9051 - val_kl_loss: 20087.2480 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7775 - reco_loss: 26.9348 - kl_loss: 2.8396 - val_loss: 20089.8027 - val_reco_loss: 30.2795 - val_kl_loss: 20059.5234 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.5257 - reco_loss: 27.6816 - kl_loss: 2.8426 - val_loss: 20034.0840 - val_reco_loss: 31.5302 - val_kl_loss: 20002.5547 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7060 - reco_loss: 26.8743 - kl_loss: 2.8349 - val_loss: 20359.9238 - val_reco_loss: 32.2511 - val_kl_loss: 20327.6719 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.1889 - reco_loss: 27.3413 - kl_loss: 2.8368 - val_loss: 19942.6309 - val_reco_loss: 31.7191 - val_kl_loss: 19910.9121 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.1679 - reco_loss: 27.3401 - kl_loss: 2.8228 - val_loss: 19958.8066 - val_reco_loss: 31.2358 - val_kl_loss: 19927.5703 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.5497 - reco_loss: 27.7206 - kl_loss: 2.8273 - val_loss: 19796.0820 - val_reco_loss: 31.5169 - val_kl_loss: 19764.5645 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.4465 - reco_loss: 27.6266 - kl_loss: 2.8181 - val_loss: 19851.5781 - val_reco_loss: 29.5334 - val_kl_loss: 19822.0449 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.9300 - reco_loss: 27.1212 - kl_loss: 2.8073 - val_loss: 19828.1953 - val_reco_loss: 28.7187 - val_kl_loss: 19799.4766 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3253 - reco_loss: 26.5214 - kl_loss: 2.8057 - val_loss: 20024.1484 - val_reco_loss: 35.4920 - val_kl_loss: 19988.6562 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "1795/1800 [============================>.] - ETA: 0s - loss: 29.2954 - reco_loss: 26.4820 - kl_loss: 2.8074\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.2966 - reco_loss: 26.4833 - kl_loss: 2.8075 - val_loss: 19859.1621 - val_reco_loss: 31.2823 - val_kl_loss: 19827.8789 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.7142 - reco_loss: 24.9136 - kl_loss: 2.8012 - val_loss: 19781.4121 - val_reco_loss: 28.8643 - val_kl_loss: 19752.5469 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.7066 - reco_loss: 24.9072 - kl_loss: 2.7996 - val_loss: 19758.6641 - val_reco_loss: 28.8750 - val_kl_loss: 19729.7891 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.7655 - reco_loss: 24.9681 - kl_loss: 2.7976 - val_loss: 19768.0703 - val_reco_loss: 28.6874 - val_kl_loss: 19739.3828 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.7614 - reco_loss: 24.9674 - kl_loss: 2.7956 - val_loss: 19758.8730 - val_reco_loss: 28.2379 - val_kl_loss: 19730.6348 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1185/1800 [==================>...........] - ETA: 2s - loss: 27.7262 - reco_loss: 24.9323 - kl_loss: 2.7945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.2608 - reco_loss: 32.3526 - kl_loss: 3.8974 - val_loss: 27857.1133 - val_reco_loss: 39.6591 - val_kl_loss: 27817.4551 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.8489 - reco_loss: 31.9860 - kl_loss: 3.8432 - val_loss: 27178.0039 - val_reco_loss: 32.0871 - val_kl_loss: 27145.9160 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.5129 - reco_loss: 31.7304 - kl_loss: 3.7649 - val_loss: 26585.1699 - val_reco_loss: 34.6747 - val_kl_loss: 26550.4961 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.9458 - reco_loss: 30.4878 - kl_loss: 3.4575 - val_loss: 24674.1973 - val_reco_loss: 42.9348 - val_kl_loss: 24631.2617 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.7591 - reco_loss: 30.3164 - kl_loss: 3.4294 - val_loss: 24644.8535 - val_reco_loss: 37.7094 - val_kl_loss: 24607.1445 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.8025 - reco_loss: 30.3763 - kl_loss: 3.4085 - val_loss: 24089.7910 - val_reco_loss: 37.0810 - val_kl_loss: 24052.7109 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.3106 - reco_loss: 29.9314 - kl_loss: 3.3797 - val_loss: 23982.3594 - val_reco_loss: 30.4667 - val_kl_loss: 23951.8926 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.1015 - reco_loss: 28.7507 - kl_loss: 3.3500 - val_loss: 23744.6602 - val_reco_loss: 29.5446 - val_kl_loss: 23715.1152 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.2298 - reco_loss: 29.8876 - kl_loss: 3.3406 - val_loss: 23584.1758 - val_reco_loss: 29.6260 - val_kl_loss: 23554.5508 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6435 - reco_loss: 28.3384 - kl_loss: 3.2996 - val_loss: 23468.1367 - val_reco_loss: 32.9819 - val_kl_loss: 23435.1543 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.9740 - reco_loss: 27.6929 - kl_loss: 3.2752 - val_loss: 23319.9160 - val_reco_loss: 41.7995 - val_kl_loss: 23278.1172 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.3598 - reco_loss: 29.1109 - kl_loss: 3.2478 - val_loss: 23146.4395 - val_reco_loss: 29.4671 - val_kl_loss: 23116.9727 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6907 - reco_loss: 28.4570 - kl_loss: 3.2342 - val_loss: 23149.1641 - val_reco_loss: 27.9154 - val_kl_loss: 23121.2480 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.0515 - reco_loss: 27.8323 - kl_loss: 3.2029 - val_loss: 22677.5078 - val_reco_loss: 32.6095 - val_kl_loss: 22644.8984 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 1012.7641 - reco_loss: 1009.2381 - kl_loss: 4.0052 - val_loss: 34915.8633 - val_reco_loss: 141.5023 - val_kl_loss: 34774.3594 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 115.0584 - reco_loss: 110.0106 - kl_loss: 5.1537 - val_loss: 37198.0781 - val_reco_loss: 67.8267 - val_kl_loss: 37130.2500 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 70.7115 - reco_loss: 65.5588 - kl_loss: 5.0890 - val_loss: 35469.8477 - val_reco_loss: 52.0885 - val_kl_loss: 35417.7578 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1790/1800 [============================>.] - ETA: 0s - loss: 61.5309 - reco_loss: 56.6479 - kl_loss: 5.0967\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 61.6154 - reco_loss: 56.7310 - kl_loss: 5.1005 - val_loss: 41994.9609 - val_reco_loss: 66.9204 - val_kl_loss: 41928.0391 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 63.1746 - reco_loss: 57.3823 - kl_loss: 5.7777 - val_loss: 41506.3008 - val_reco_loss: 57.3849 - val_kl_loss: 41448.9141 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.2581 - reco_loss: 50.5443 - kl_loss: 5.6992 - val_loss: 40613.9922 - val_reco_loss: 50.2396 - val_kl_loss: 40563.7539 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.1657 - reco_loss: 46.5589 - kl_loss: 5.5656 - val_loss: 39421.6484 - val_reco_loss: 46.3215 - val_kl_loss: 39375.3281 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - ETA: 0s - loss: 48.0587 - reco_loss: 42.6346 - kl_loss: 5.3749\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.0579 - reco_loss: 42.6339 - kl_loss: 5.3749 - val_loss: 37942.4570 - val_reco_loss: 42.3921 - val_kl_loss: 37900.0664 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "  76/1800 [>.............................] - ETA: 8s - loss: 36149.3038 - reco_loss: 36107.3771 - kl_loss: 75.6038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.6400 - reco_loss: 32.6298 - kl_loss: 3.9683 - val_loss: 28031.2871 - val_reco_loss: 35.9769 - val_kl_loss: 27995.3105 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.4411 - reco_loss: 32.5539 - kl_loss: 3.8936 - val_loss: 27888.3047 - val_reco_loss: 35.6971 - val_kl_loss: 27852.6074 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.1384 - reco_loss: 32.3069 - kl_loss: 3.7937 - val_loss: 27143.9805 - val_reco_loss: 32.0855 - val_kl_loss: 27111.8945 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.8785 - reco_loss: 31.1505 - kl_loss: 3.7361 - val_loss: 27417.3047 - val_reco_loss: 33.7444 - val_kl_loss: 27383.5605 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5726 - reco_loss: 29.2183 - kl_loss: 3.3387 - val_loss: 23945.8555 - val_reco_loss: 31.3090 - val_kl_loss: 23914.5469 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.5307 - reco_loss: 28.2276 - kl_loss: 3.3004 - val_loss: 23505.9668 - val_reco_loss: 30.2868 - val_kl_loss: 23475.6797 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.4768 - reco_loss: 29.1990 - kl_loss: 3.2775 - val_loss: 23542.5977 - val_reco_loss: 31.9975 - val_kl_loss: 23510.5996 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.5059 - reco_loss: 28.2471 - kl_loss: 3.2572 - val_loss: 24242.6504 - val_reco_loss: 30.2721 - val_kl_loss: 24212.3789 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.4877 - reco_loss: 28.2406 - kl_loss: 3.2346 - val_loss: 23203.7148 - val_reco_loss: 32.5197 - val_kl_loss: 23171.1953 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.7426 - reco_loss: 34.5164 - kl_loss: 3.2733 - val_loss: 29222.4238 - val_reco_loss: 292.6448 - val_kl_loss: 28929.7793 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 135.3626 - reco_loss: 131.3648 - kl_loss: 3.9692 - val_loss: 28049.4590 - val_reco_loss: 61.6516 - val_kl_loss: 27987.8066 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.8113 - reco_loss: 41.9444 - kl_loss: 3.8586 - val_loss: 27419.6719 - val_reco_loss: 43.4452 - val_kl_loss: 27376.2266 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1796/1800 [============================>.] - ETA: 0s - loss: 38.4947 - reco_loss: 34.7120 - kl_loss: 3.7729\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.4921 - reco_loss: 34.7093 - kl_loss: 3.7729 - val_loss: 27204.6934 - val_reco_loss: 36.8923 - val_kl_loss: 27167.8008 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.0411 - reco_loss: 30.2927 - kl_loss: 3.7344 - val_loss: 26800.6777 - val_reco_loss: 34.7236 - val_kl_loss: 26765.9551 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.6178 - reco_loss: 29.9143 - kl_loss: 3.7056 - val_loss: 26684.4062 - val_reco_loss: 33.7395 - val_kl_loss: 26650.6660 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.3874 - reco_loss: 29.6904 - kl_loss: 3.6870 - val_loss: 26495.3574 - val_reco_loss: 33.0714 - val_kl_loss: 26462.2852 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1799/1800 [============================>.] - ETA: 0s - loss: 32.9023 - reco_loss: 29.2355 - kl_loss: 3.6630\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.9020 - reco_loss: 29.2352 - kl_loss: 3.6633 - val_loss: 26348.6660 - val_reco_loss: 30.4560 - val_kl_loss: 26318.2109 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 4620.7479 - reco_loss: 4519.5808 - kl_loss: 79.7936 - val_loss: 296880.0938 - val_reco_loss: 174.1089 - val_kl_loss: 296706.0000 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 135.1100 - reco_loss: 102.5519 - kl_loss: 27.4994 - val_loss: 147718.0781 - val_reco_loss: 99.6576 - val_kl_loss: 147618.4219 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 95.6495 - reco_loss: 78.1267 - kl_loss: 15.6763 - val_loss: 94398.9922 - val_reco_loss: 78.3200 - val_kl_loss: 94320.6719 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 75.3021 - reco_loss: 63.4874 - kl_loss: 11.0079 - val_loss: 70960.0625 - val_reco_loss: 71.6670 - val_kl_loss: 70888.3984 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1609/1800 [=========================>....] - ETA: 0s - loss: 63.0904 - reco_loss: 53.9062 - kl_loss: 8.9138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 10s 5ms/step - loss: 35.5378 - reco_loss: 31.8353 - kl_loss: 3.6728 - val_loss: 26223.6680 - val_reco_loss: 42.4702 - val_kl_loss: 26181.1973 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.1909 - reco_loss: 30.5611 - kl_loss: 3.6173 - val_loss: 25704.6406 - val_reco_loss: 32.9870 - val_kl_loss: 25671.6543 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.3750 - reco_loss: 29.7882 - kl_loss: 3.5869 - val_loss: 25605.8906 - val_reco_loss: 36.1843 - val_kl_loss: 25569.7070 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5669 - reco_loss: 29.1774 - kl_loss: 3.3770 - val_loss: 24072.6738 - val_reco_loss: 29.7088 - val_kl_loss: 24042.9648 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.6321 - reco_loss: 29.2664 - kl_loss: 3.3628 - val_loss: 23886.9473 - val_reco_loss: 29.9385 - val_kl_loss: 23857.0078 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.6617 - reco_loss: 29.3100 - kl_loss: 3.3452 - val_loss: 23793.6875 - val_reco_loss: 36.9098 - val_kl_loss: 23756.7773 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.1365 - reco_loss: 28.8156 - kl_loss: 3.3217 - val_loss: 23662.3164 - val_reco_loss: 33.4493 - val_kl_loss: 23628.8672 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5948 - reco_loss: 29.2871 - kl_loss: 3.3011 - val_loss: 23397.4375 - val_reco_loss: 29.9111 - val_kl_loss: 23367.5273 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6511 - reco_loss: 28.3746 - kl_loss: 3.2768 - val_loss: 23364.9492 - val_reco_loss: 32.6830 - val_kl_loss: 23332.2656 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.7113 - reco_loss: 28.4483 - kl_loss: 3.2605 - val_loss: 23188.1699 - val_reco_loss: 30.8539 - val_kl_loss: 23157.3164 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.8606 - reco_loss: 28.6173 - kl_loss: 3.2417 - val_loss: 22976.0762 - val_reco_loss: 33.9784 - val_kl_loss: 22942.0977 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.5365 - reco_loss: 28.3183 - kl_loss: 3.2205 - val_loss: 22839.1758 - val_reco_loss: 29.8131 - val_kl_loss: 22809.3633 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.8534 - reco_loss: 28.6331 - kl_loss: 3.2082 - val_loss: 22759.5527 - val_reco_loss: 32.6597 - val_kl_loss: 22726.8926 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.3610 - reco_loss: 29.1659 - kl_loss: 3.1883 - val_loss: 22635.0762 - val_reco_loss: 34.6630 - val_kl_loss: 22600.4141 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.4792 - reco_loss: 28.2794 - kl_loss: 3.1886 - val_loss: 22501.0293 - val_reco_loss: 30.9792 - val_kl_loss: 22470.0508 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.2370 - reco_loss: 28.0689 - kl_loss: 3.1557 - val_loss: 22402.9648 - val_reco_loss: 29.4971 - val_kl_loss: 22373.4668 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.9661 - reco_loss: 28.8218 - kl_loss: 3.1398 - val_loss: 22267.4961 - val_reco_loss: 28.7111 - val_kl_loss: 22238.7852 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7631 - reco_loss: 27.6380 - kl_loss: 3.1280 - val_loss: 22251.5234 - val_reco_loss: 28.1124 - val_kl_loss: 22223.4102 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.3612 - reco_loss: 27.2438 - kl_loss: 3.1166 - val_loss: 22107.8984 - val_reco_loss: 37.2720 - val_kl_loss: 22070.6270 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.8262 - reco_loss: 27.7245 - kl_loss: 3.1016 - val_loss: 21999.5449 - val_reco_loss: 27.7913 - val_kl_loss: 21971.7539 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.2761 - reco_loss: 28.1855 - kl_loss: 3.0868 - val_loss: 21944.9941 - val_reco_loss: 28.9468 - val_kl_loss: 21916.0469 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1119/1800 [=================>............] - ETA: 3s - loss: 32.5278 - reco_loss: 29.4420 - kl_loss: 3.0852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.4770 - reco_loss: 25.5437 - kl_loss: 2.9297 - val_loss: 20741.8496 - val_reco_loss: 25.6011 - val_kl_loss: 20716.2480 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.5324 - reco_loss: 25.6079 - kl_loss: 2.9213 - val_loss: 20654.6445 - val_reco_loss: 25.4875 - val_kl_loss: 20629.1562 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.3534 - reco_loss: 25.4428 - kl_loss: 2.9057 - val_loss: 20524.7734 - val_reco_loss: 25.7322 - val_kl_loss: 20499.0410 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.8560 - reco_loss: 24.9843 - kl_loss: 2.8726 - val_loss: 20353.0020 - val_reco_loss: 25.2361 - val_kl_loss: 20327.7656 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.9265 - reco_loss: 25.0567 - kl_loss: 2.8710 - val_loss: 20312.7578 - val_reco_loss: 25.4212 - val_kl_loss: 20287.3359 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.0381 - reco_loss: 25.1679 - kl_loss: 2.8689 - val_loss: 20337.9258 - val_reco_loss: 26.0604 - val_kl_loss: 20311.8652 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.7463 - reco_loss: 24.8792 - kl_loss: 2.8659 - val_loss: 20294.3691 - val_reco_loss: 25.2095 - val_kl_loss: 20269.1602 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.6737 - reco_loss: 24.8122 - kl_loss: 2.8634 - val_loss: 20263.2227 - val_reco_loss: 26.0939 - val_kl_loss: 20237.1289 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.0852 - reco_loss: 25.2230 - kl_loss: 2.8610 - val_loss: 20249.7910 - val_reco_loss: 25.2253 - val_kl_loss: 20224.5664 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.5802 - reco_loss: 24.7209 - kl_loss: 2.8582 - val_loss: 20273.0215 - val_reco_loss: 25.4560 - val_kl_loss: 20247.5664 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.6838 - reco_loss: 24.8275 - kl_loss: 2.8558 - val_loss: 20217.4375 - val_reco_loss: 25.6559 - val_kl_loss: 20191.7812 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.3364 - reco_loss: 24.4799 - kl_loss: 2.8557 - val_loss: 20186.4414 - val_reco_loss: 25.8360 - val_kl_loss: 20160.6055 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.4754 - reco_loss: 24.6277 - kl_loss: 2.8504 - val_loss: 20160.6133 - val_reco_loss: 24.9965 - val_kl_loss: 20135.6172 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.3502 - reco_loss: 24.5037 - kl_loss: 2.8486 - val_loss: 20182.5430 - val_reco_loss: 25.3711 - val_kl_loss: 20157.1719 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 6780.1054 - reco_loss: 6582.0495 - kl_loss: 143.5655 - val_loss: 373829.5000 - val_reco_loss: 184.6118 - val_kl_loss: 373644.8750 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 203.2515 - reco_loss: 164.3535 - kl_loss: 31.5584 - val_loss: 159236.4062 - val_reco_loss: 101.8439 - val_kl_loss: 159134.5625 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 113.2012 - reco_loss: 93.5516 - kl_loss: 17.7775 - val_loss: 106392.2812 - val_reco_loss: 65.2781 - val_kl_loss: 106327.0000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 67.2684 - reco_loss: 54.0294 - kl_loss: 12.2323 - val_loss: 78077.7578 - val_reco_loss: 85.1248 - val_kl_loss: 77992.6328 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 63.4921 - reco_loss: 53.3591 - kl_loss: 9.6081 - val_loss: 64955.5078 - val_reco_loss: 41.4990 - val_kl_loss: 64914.0078 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.0514 - reco_loss: 39.6379 - kl_loss: 8.1227 - val_loss: 56269.1719 - val_reco_loss: 35.6792 - val_kl_loss: 56233.4922 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 49.6492 - reco_loss: 42.1561 - kl_loss: 7.3959 - val_loss: 51228.5273 - val_reco_loss: 34.8498 - val_kl_loss: 51193.6758 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1129/1800 [=================>............] - ETA: 3s - loss: 42.3437 - reco_loss: 35.5253 - kl_loss: 6.7302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 94.8983 - reco_loss: 77.5537 - kl_loss: 15.7239 - val_loss: 96292.4219 - val_reco_loss: 83.8900 - val_kl_loss: 96208.5312 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 74.7315 - reco_loss: 62.5466 - kl_loss: 11.4616 - val_loss: 73378.5156 - val_reco_loss: 80.1406 - val_kl_loss: 73298.3750 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 62.3614 - reco_loss: 52.7457 - kl_loss: 9.1674 - val_loss: 60845.8086 - val_reco_loss: 52.6900 - val_kl_loss: 60793.1172 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 46.3755 - reco_loss: 41.3860 - kl_loss: 4.9688 - val_loss: 35412.9102 - val_reco_loss: 44.7296 - val_kl_loss: 35368.1797 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.0927 - reco_loss: 38.2253 - kl_loss: 4.8413 - val_loss: 34408.0742 - val_reco_loss: 47.3502 - val_kl_loss: 34360.7227 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 41.1788 - reco_loss: 36.4405 - kl_loss: 4.7408 - val_loss: 33821.4844 - val_reco_loss: 40.1268 - val_kl_loss: 33781.3594 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 39.9906 - reco_loss: 35.3520 - kl_loss: 4.5876 - val_loss: 32979.7969 - val_reco_loss: 40.6874 - val_kl_loss: 32939.1094 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.7572 - reco_loss: 33.2425 - kl_loss: 4.4707 - val_loss: 31647.0254 - val_reco_loss: 41.1582 - val_kl_loss: 31605.8672 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.0509 - reco_loss: 33.6607 - kl_loss: 4.3676 - val_loss: 31213.4668 - val_reco_loss: 38.2782 - val_kl_loss: 31175.1895 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.1931 - reco_loss: 31.8756 - kl_loss: 4.2919 - val_loss: 30505.2539 - val_reco_loss: 41.4051 - val_kl_loss: 30463.8496 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.8121 - reco_loss: 32.5605 - kl_loss: 4.2265 - val_loss: 29705.4844 - val_reco_loss: 40.5219 - val_kl_loss: 29664.9629 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.4506 - reco_loss: 32.2895 - kl_loss: 4.1422 - val_loss: 29105.4531 - val_reco_loss: 40.8809 - val_kl_loss: 29064.5723 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.2527 - reco_loss: 32.1571 - kl_loss: 4.0761 - val_loss: 28780.0645 - val_reco_loss: 40.9902 - val_kl_loss: 28739.0742 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.1677 - reco_loss: 31.1458 - kl_loss: 4.0243 - val_loss: 29151.6777 - val_reco_loss: 41.0162 - val_kl_loss: 29110.6621 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.4927 - reco_loss: 31.4780 - kl_loss: 3.9936 - val_loss: 28103.0391 - val_reco_loss: 48.4266 - val_kl_loss: 28054.6133 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.9472 - reco_loss: 34.0094 - kl_loss: 3.9249 - val_loss: 27871.2109 - val_reco_loss: 43.1254 - val_kl_loss: 27828.0859 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.7607 - reco_loss: 30.8868 - kl_loss: 3.8684 - val_loss: 27344.3184 - val_reco_loss: 40.2783 - val_kl_loss: 27304.0410 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.6544 - reco_loss: 30.8192 - kl_loss: 3.8167 - val_loss: 26983.6953 - val_reco_loss: 38.2309 - val_kl_loss: 26945.4648 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.1448 - reco_loss: 31.3565 - kl_loss: 3.7905 - val_loss: 26862.0840 - val_reco_loss: 36.5246 - val_kl_loss: 26825.5586 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.6939 - reco_loss: 30.9327 - kl_loss: 3.7506 - val_loss: 26472.6973 - val_reco_loss: 39.1649 - val_kl_loss: 26433.5332 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.5215 - reco_loss: 30.7956 - kl_loss: 3.7097 - val_loss: 26332.5098 - val_reco_loss: 35.5140 - val_kl_loss: 26296.9961 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1736/1800 [===========================>..] - ETA: 0s - loss: 35.0215 - reco_loss: 31.3230 - kl_loss: 3.7071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.4164 - reco_loss: 28.2764 - kl_loss: 3.1334 - val_loss: 21957.3145 - val_reco_loss: 28.6329 - val_kl_loss: 21928.6816 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.5931 - reco_loss: 28.4686 - kl_loss: 3.1544 - val_loss: 22441.7402 - val_reco_loss: 28.3427 - val_kl_loss: 22413.3984 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 43.3200 - reco_loss: 40.1711 - kl_loss: 3.1838 - val_loss: 23305.5938 - val_reco_loss: 43.4294 - val_kl_loss: 23262.1641 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 171.2875 - reco_loss: 142.3447 - kl_loss: 25.1209 - val_loss: 165185.6875 - val_reco_loss: 117.8634 - val_kl_loss: 165067.8281 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 93.7495 - reco_loss: 76.4018 - kl_loss: 15.7343 - val_loss: 110172.1953 - val_reco_loss: 70.1646 - val_kl_loss: 110102.0312 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 71.2354 - reco_loss: 59.1944 - kl_loss: 11.1795 - val_loss: 82626.6328 - val_reco_loss: 58.1030 - val_kl_loss: 82568.5312 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 58.0486 - reco_loss: 48.7884 - kl_loss: 8.8456 - val_loss: 69376.8672 - val_reco_loss: 62.9141 - val_kl_loss: 69313.9531 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 51.1512 - reco_loss: 43.1708 - kl_loss: 7.7497 - val_loss: 60882.1133 - val_reco_loss: 40.1515 - val_kl_loss: 60841.9609 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 44.9786 - reco_loss: 37.9128 - kl_loss: 6.8809 - val_loss: 54726.1445 - val_reco_loss: 36.6223 - val_kl_loss: 54689.5234 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.7682 - reco_loss: 34.4394 - kl_loss: 6.1565 - val_loss: 49425.9570 - val_reco_loss: 35.9418 - val_kl_loss: 49390.0156 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.9580 - reco_loss: 33.2129 - kl_loss: 5.6545 - val_loss: 46202.9414 - val_reco_loss: 33.7087 - val_kl_loss: 46169.2344 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 39.3447 - reco_loss: 33.9047 - kl_loss: 5.3246 - val_loss: 43158.5820 - val_reco_loss: 31.9531 - val_kl_loss: 43126.6289 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.7973 - reco_loss: 31.6756 - kl_loss: 5.0575 - val_loss: 41650.2969 - val_reco_loss: 31.0787 - val_kl_loss: 41619.2188 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.3499 - reco_loss: 29.4945 - kl_loss: 4.8125 - val_loss: 39628.2930 - val_reco_loss: 28.1872 - val_kl_loss: 39600.1055 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.5260 - reco_loss: 26.8276 - kl_loss: 4.6562 - val_loss: 38236.3945 - val_reco_loss: 28.0106 - val_kl_loss: 38208.3828 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.9725 - reco_loss: 26.4372 - kl_loss: 4.5078 - val_loss: 37262.2188 - val_reco_loss: 31.4598 - val_kl_loss: 37230.7578 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.7067 - reco_loss: 27.2627 - kl_loss: 4.4382 - val_loss: 36454.0195 - val_reco_loss: 48.0652 - val_kl_loss: 36405.9531 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 48.4490 - reco_loss: 43.9822 - kl_loss: 4.4287 - val_loss: 35905.8633 - val_reco_loss: 26.2727 - val_kl_loss: 35879.5898 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.9500 - reco_loss: 24.6705 - kl_loss: 4.2309 - val_loss: 34363.2812 - val_reco_loss: 29.3411 - val_kl_loss: 34333.9414 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3371 - reco_loss: 25.2277 - kl_loss: 4.0997 - val_loss: 34032.4922 - val_reco_loss: 33.4810 - val_kl_loss: 33999.0117 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.2519 - reco_loss: 25.2081 - kl_loss: 4.0023 - val_loss: 32750.9902 - val_reco_loss: 25.4012 - val_kl_loss: 32725.5898 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "  89/1800 [>.............................] - ETA: 8s - loss: 26.3046 - reco_loss: 22.3791 - kl_loss: 3.9367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.2059 - reco_loss: 20.1863 - kl_loss: 3.0226 - val_loss: 24764.4531 - val_reco_loss: 24.3353 - val_kl_loss: 24740.1172 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.3289 - reco_loss: 20.3128 - kl_loss: 3.0209 - val_loss: 24704.2812 - val_reco_loss: 22.9722 - val_kl_loss: 24681.3086 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.9864 - reco_loss: 19.9875 - kl_loss: 2.9965 - val_loss: 24580.9824 - val_reco_loss: 24.9130 - val_kl_loss: 24556.0703 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.0195 - reco_loss: 20.1075 - kl_loss: 2.9071 - val_loss: 23866.3945 - val_reco_loss: 23.1023 - val_kl_loss: 23843.2930 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.5026 - reco_loss: 19.6034 - kl_loss: 2.8990 - val_loss: 23696.6875 - val_reco_loss: 23.5751 - val_kl_loss: 23673.1133 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.2937 - reco_loss: 20.3978 - kl_loss: 2.8896 - val_loss: 23606.8711 - val_reco_loss: 24.2932 - val_kl_loss: 23582.5781 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.6418 - reco_loss: 19.7632 - kl_loss: 2.8787 - val_loss: 23576.3613 - val_reco_loss: 41.2985 - val_kl_loss: 23535.0625 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.0947 - reco_loss: 22.2146 - kl_loss: 2.8721 - val_loss: 23395.5176 - val_reco_loss: 22.5135 - val_kl_loss: 23373.0039 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.2689 - reco_loss: 19.4100 - kl_loss: 2.8625 - val_loss: 23397.4922 - val_reco_loss: 27.2314 - val_kl_loss: 23370.2617 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4079 - reco_loss: 19.5497 - kl_loss: 2.8550 - val_loss: 23284.1387 - val_reco_loss: 21.8024 - val_kl_loss: 23262.3359 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1838 - reco_loss: 19.3286 - kl_loss: 2.8551 - val_loss: 23141.3398 - val_reco_loss: 21.4281 - val_kl_loss: 23119.9121 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4684 - reco_loss: 19.6296 - kl_loss: 2.8368 - val_loss: 23132.3379 - val_reco_loss: 22.4385 - val_kl_loss: 23109.8984 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.9869 - reco_loss: 19.1577 - kl_loss: 2.8258 - val_loss: 23167.4883 - val_reco_loss: 24.6552 - val_kl_loss: 23142.8340 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1221 - reco_loss: 19.3002 - kl_loss: 2.8269 - val_loss: 23110.2168 - val_reco_loss: 21.3231 - val_kl_loss: 23088.8945 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8130 - reco_loss: 18.9975 - kl_loss: 2.8152 - val_loss: 22947.0840 - val_reco_loss: 29.0452 - val_kl_loss: 22918.0391 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.7490 - reco_loss: 18.9425 - kl_loss: 2.8062 - val_loss: 22865.3418 - val_reco_loss: 25.4185 - val_kl_loss: 22839.9238 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.6689 - reco_loss: 18.8664 - kl_loss: 2.8014 - val_loss: 22828.7441 - val_reco_loss: 20.9960 - val_kl_loss: 22807.7480 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8675 - reco_loss: 19.0648 - kl_loss: 2.7987 - val_loss: 22773.9180 - val_reco_loss: 22.7407 - val_kl_loss: 22751.1777 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.3798 - reco_loss: 18.5912 - kl_loss: 2.7890 - val_loss: 22728.8887 - val_reco_loss: 20.7916 - val_kl_loss: 22708.0977 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.5061 - reco_loss: 18.7169 - kl_loss: 2.7881 - val_loss: 22717.2305 - val_reco_loss: 21.4958 - val_kl_loss: 22695.7344 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.1700 - reco_loss: 18.3905 - kl_loss: 2.7799 - val_loss: 22586.1094 - val_reco_loss: 24.1875 - val_kl_loss: 22561.9219 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "1119/1800 [=================>............] - ETA: 3s - loss: 21.6927 - reco_loss: 18.9144 - kl_loss: 2.7792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.2555 - reco_loss: 16.5441 - kl_loss: 2.7088 - val_loss: 22020.8809 - val_reco_loss: 19.5834 - val_kl_loss: 22001.2969 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 18.9929 - reco_loss: 16.2851 - kl_loss: 2.7088 - val_loss: 22026.5781 - val_reco_loss: 19.8493 - val_kl_loss: 22006.7285 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.3441 - reco_loss: 16.6367 - kl_loss: 2.7057 - val_loss: 22067.8906 - val_reco_loss: 19.7576 - val_kl_loss: 22048.1328 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.5613 - reco_loss: 39.1915 - kl_loss: 6.3729 - val_loss: 52786.6836 - val_reco_loss: 33.6942 - val_kl_loss: 52752.9883 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.4784 - reco_loss: 31.3536 - kl_loss: 5.9794 - val_loss: 47666.4727 - val_reco_loss: 37.0574 - val_kl_loss: 47629.4141 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 79.0611 - reco_loss: 73.3576 - kl_loss: 6.1063 - val_loss: 60824.3242 - val_reco_loss: 88.1911 - val_kl_loss: 60736.1328 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 56.4668 - reco_loss: 49.2613 - kl_loss: 7.0497 - val_loss: 56416.9375 - val_reco_loss: 38.2848 - val_kl_loss: 56378.6523 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.3883 - reco_loss: 31.7779 - kl_loss: 6.4535 - val_loss: 51234.7461 - val_reco_loss: 30.2706 - val_kl_loss: 51204.4766 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.3226 - reco_loss: 30.3378 - kl_loss: 5.8405 - val_loss: 46078.3750 - val_reco_loss: 46.8427 - val_kl_loss: 46031.5312 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.6658 - reco_loss: 29.2267 - kl_loss: 5.3508 - val_loss: 42917.4648 - val_reco_loss: 29.0488 - val_kl_loss: 42888.4180 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.9993 - reco_loss: 27.9623 - kl_loss: 4.9697 - val_loss: 40351.0195 - val_reco_loss: 29.8155 - val_kl_loss: 40321.2031 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5122 - reco_loss: 27.7230 - kl_loss: 4.7106 - val_loss: 38150.8086 - val_reco_loss: 27.9463 - val_kl_loss: 38122.8633 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5494 - reco_loss: 27.9732 - kl_loss: 4.5835 - val_loss: 37956.0352 - val_reco_loss: 26.0282 - val_kl_loss: 37930.0078 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.4665 - reco_loss: 26.9375 - kl_loss: 4.4842 - val_loss: 36743.0078 - val_reco_loss: 31.4685 - val_kl_loss: 36711.5391 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7242 - reco_loss: 26.3241 - kl_loss: 4.3585 - val_loss: 35496.8555 - val_reco_loss: 26.6028 - val_kl_loss: 35470.2539 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.8454 - reco_loss: 27.5834 - kl_loss: 4.2080 - val_loss: 34739.6914 - val_reco_loss: 30.6690 - val_kl_loss: 34709.0234 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.5065 - reco_loss: 26.3963 - kl_loss: 4.0842 - val_loss: 33194.3281 - val_reco_loss: 53.1276 - val_kl_loss: 33141.1992 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.3636 - reco_loss: 26.3713 - kl_loss: 3.9671 - val_loss: 32362.9941 - val_reco_loss: 29.4510 - val_kl_loss: 32333.5430 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.7427 - reco_loss: 25.8294 - kl_loss: 3.9055 - val_loss: 31830.7402 - val_reco_loss: 28.2341 - val_kl_loss: 31802.5059 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 115.5058 - reco_loss: 110.8382 - kl_loss: 4.5833 - val_loss: 36679.9531 - val_reco_loss: 31.1171 - val_kl_loss: 36648.8359 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.8012 - reco_loss: 27.4732 - kl_loss: 4.2693 - val_loss: 34453.5039 - val_reco_loss: 28.8681 - val_kl_loss: 34424.6367 - lr: 0.0010\n",
      "Epoch 26/100\n",
      " 277/1800 [===>..........................] - ETA: 7s - loss: 28.4222 - reco_loss: 24.3175 - kl_loss: 4.1407"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.1900 - reco_loss: 21.8232 - kl_loss: 3.3599 - val_loss: 27611.2070 - val_reco_loss: 25.4845 - val_kl_loss: 27585.7227 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.3332 - reco_loss: 21.9807 - kl_loss: 3.3443 - val_loss: 27482.2363 - val_reco_loss: 24.8427 - val_kl_loss: 27457.3945 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.8504 - reco_loss: 21.5207 - kl_loss: 3.3303 - val_loss: 27381.6445 - val_reco_loss: 24.9702 - val_kl_loss: 27356.6738 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.6365 - reco_loss: 21.3838 - kl_loss: 3.2503 - val_loss: 26712.4961 - val_reco_loss: 24.8182 - val_kl_loss: 26687.6777 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.4948 - reco_loss: 21.2549 - kl_loss: 3.2417 - val_loss: 26568.2539 - val_reco_loss: 24.7442 - val_kl_loss: 26543.5098 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.3937 - reco_loss: 21.1607 - kl_loss: 3.2311 - val_loss: 26533.5566 - val_reco_loss: 24.3614 - val_kl_loss: 26509.1953 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.3884 - reco_loss: 21.1645 - kl_loss: 3.2216 - val_loss: 26473.3770 - val_reco_loss: 24.6231 - val_kl_loss: 26448.7539 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.5841 - reco_loss: 21.3662 - kl_loss: 3.2120 - val_loss: 26394.8809 - val_reco_loss: 25.0821 - val_kl_loss: 26369.7988 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.8371 - reco_loss: 21.6308 - kl_loss: 3.2021 - val_loss: 26249.5312 - val_reco_loss: 25.2352 - val_kl_loss: 26224.2969 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.0816 - reco_loss: 20.8929 - kl_loss: 3.1939 - val_loss: 26198.2852 - val_reco_loss: 24.7974 - val_kl_loss: 26173.4883 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.2986 - reco_loss: 21.1088 - kl_loss: 3.1897 - val_loss: 26165.3809 - val_reco_loss: 24.2694 - val_kl_loss: 26141.1113 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.3639 - reco_loss: 21.1849 - kl_loss: 3.1788 - val_loss: 26115.0664 - val_reco_loss: 25.3814 - val_kl_loss: 26089.6855 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.3456 - reco_loss: 21.1740 - kl_loss: 3.1695 - val_loss: 26005.7812 - val_reco_loss: 24.2131 - val_kl_loss: 25981.5684 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.2145 - reco_loss: 21.0517 - kl_loss: 3.1625 - val_loss: 25997.8320 - val_reco_loss: 24.4017 - val_kl_loss: 25973.4297 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.9348 - reco_loss: 20.7818 - kl_loss: 3.1547 - val_loss: 25882.0859 - val_reco_loss: 25.1093 - val_kl_loss: 25856.9766 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.1251 - reco_loss: 20.9718 - kl_loss: 3.1482 - val_loss: 25832.6621 - val_reco_loss: 24.1592 - val_kl_loss: 25808.5020 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.2398 - reco_loss: 21.0979 - kl_loss: 3.1390 - val_loss: 25776.6797 - val_reco_loss: 25.1721 - val_kl_loss: 25751.5078 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.9881 - reco_loss: 20.8534 - kl_loss: 3.1342 - val_loss: 25702.6621 - val_reco_loss: 24.9146 - val_kl_loss: 25677.7480 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.4209 - reco_loss: 21.2902 - kl_loss: 3.1266 - val_loss: 25656.6426 - val_reco_loss: 24.5996 - val_kl_loss: 25632.0430 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.3457 - reco_loss: 21.2273 - kl_loss: 3.1202 - val_loss: 25567.3164 - val_reco_loss: 23.6680 - val_kl_loss: 25543.6484 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.0519 - reco_loss: 20.9312 - kl_loss: 3.1157 - val_loss: 25537.7500 - val_reco_loss: 24.0389 - val_kl_loss: 25513.7109 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1017/1800 [===============>..............] - ETA: 3s - loss: 23.8873 - reco_loss: 20.7800 - kl_loss: 3.1100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.8599 - reco_loss: 20.8027 - kl_loss: 3.0562 - val_loss: 25004.2852 - val_reco_loss: 24.0547 - val_kl_loss: 24980.2305 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.7156 - reco_loss: 20.6636 - kl_loss: 3.0503 - val_loss: 24972.7246 - val_reco_loss: 24.4302 - val_kl_loss: 24948.2949 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.9466 - reco_loss: 20.8993 - kl_loss: 3.0453 - val_loss: 25033.9570 - val_reco_loss: 24.2749 - val_kl_loss: 25009.6816 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.6359 - reco_loss: 20.6249 - kl_loss: 3.0099 - val_loss: 24639.0273 - val_reco_loss: 24.3749 - val_kl_loss: 24614.6523 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.4247 - reco_loss: 20.4230 - kl_loss: 3.0066 - val_loss: 24587.7734 - val_reco_loss: 24.5344 - val_kl_loss: 24563.2383 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.5481 - reco_loss: 20.5466 - kl_loss: 3.0025 - val_loss: 24584.1426 - val_reco_loss: 23.8868 - val_kl_loss: 24560.2559 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.5612 - reco_loss: 20.5604 - kl_loss: 2.9981 - val_loss: 24502.6953 - val_reco_loss: 24.2202 - val_kl_loss: 24478.4746 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.7282 - reco_loss: 20.7329 - kl_loss: 2.9941 - val_loss: 24474.3301 - val_reco_loss: 23.4353 - val_kl_loss: 24450.8945 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 6577.6779 - reco_loss: 6471.5621 - kl_loss: 90.9995 - val_loss: 449439.4375 - val_reco_loss: 270.8845 - val_kl_loss: 449168.5625 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 246.2187 - reco_loss: 202.3493 - kl_loss: 37.3188 - val_loss: 226073.8438 - val_reco_loss: 156.5872 - val_kl_loss: 225917.2500 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 155.3667 - reco_loss: 131.2526 - kl_loss: 21.8938 - val_loss: 151474.1562 - val_reco_loss: 114.5830 - val_kl_loss: 151359.5781 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 96.4928 - reco_loss: 80.2086 - kl_loss: 15.0539 - val_loss: 109486.6016 - val_reco_loss: 77.9635 - val_kl_loss: 109408.6406 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 75.2205 - reco_loss: 62.9775 - kl_loss: 11.4307 - val_loss: 85543.0078 - val_reco_loss: 65.4569 - val_kl_loss: 85477.5547 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.9864 - reco_loss: 48.4301 - kl_loss: 9.1289 - val_loss: 70260.4297 - val_reco_loss: 48.5275 - val_kl_loss: 70211.8984 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.1170 - reco_loss: 44.1363 - kl_loss: 7.7316 - val_loss: 61162.4492 - val_reco_loss: 45.2372 - val_kl_loss: 61117.2109 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 42.7135 - reco_loss: 35.7108 - kl_loss: 6.8173 - val_loss: 55949.7539 - val_reco_loss: 53.7008 - val_kl_loss: 55896.0547 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 42.4945 - reco_loss: 35.9810 - kl_loss: 6.2571 - val_loss: 49368.1055 - val_reco_loss: 38.8742 - val_kl_loss: 49329.2305 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.6871 - reco_loss: 32.8998 - kl_loss: 5.7022 - val_loss: 46542.9180 - val_reco_loss: 31.9991 - val_kl_loss: 46510.9180 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.4287 - reco_loss: 31.9685 - kl_loss: 5.3362 - val_loss: 42928.9453 - val_reco_loss: 28.7135 - val_kl_loss: 42900.2305 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.7215 - reco_loss: 29.6435 - kl_loss: 5.0302 - val_loss: 40812.5234 - val_reco_loss: 28.2498 - val_kl_loss: 40784.2734 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.0886 - reco_loss: 29.2327 - kl_loss: 4.7957 - val_loss: 38885.2891 - val_reco_loss: 24.4724 - val_kl_loss: 38860.8164 - lr: 0.0010\n",
      "Epoch 14/100\n",
      " 942/1800 [==============>...............] - ETA: 4s - loss: 33.1908 - reco_loss: 28.5119 - kl_loss: 4.6574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.5029 - reco_loss: 24.5400 - kl_loss: 3.9341 - val_loss: 32777.3906 - val_reco_loss: 29.1776 - val_kl_loss: 32748.2148 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.6849 - reco_loss: 24.7654 - kl_loss: 3.8945 - val_loss: 31743.5879 - val_reco_loss: 23.6082 - val_kl_loss: 31719.9805 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.5291 - reco_loss: 23.6914 - kl_loss: 3.8216 - val_loss: 31459.3184 - val_reco_loss: 28.4866 - val_kl_loss: 31430.8320 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.8547 - reco_loss: 22.3018 - kl_loss: 3.5278 - val_loss: 28751.9805 - val_reco_loss: 22.6566 - val_kl_loss: 28729.3242 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.4196 - reco_loss: 22.9287 - kl_loss: 3.4756 - val_loss: 28445.0117 - val_reco_loss: 27.2221 - val_kl_loss: 28417.7891 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.7197 - reco_loss: 21.2685 - kl_loss: 3.4492 - val_loss: 28244.0508 - val_reco_loss: 28.0548 - val_kl_loss: 28215.9961 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.7638 - reco_loss: 21.3425 - kl_loss: 3.4166 - val_loss: 27928.8262 - val_reco_loss: 23.7191 - val_kl_loss: 27905.1074 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.7188 - reco_loss: 21.3105 - kl_loss: 3.4032 - val_loss: 27705.2031 - val_reco_loss: 23.6040 - val_kl_loss: 27681.5996 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.1255 - reco_loss: 20.7539 - kl_loss: 3.3695 - val_loss: 27521.3457 - val_reco_loss: 21.0921 - val_kl_loss: 27500.2539 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.3504 - reco_loss: 20.0032 - kl_loss: 3.3390 - val_loss: 27239.2422 - val_reco_loss: 21.6571 - val_kl_loss: 27217.5859 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.0434 - reco_loss: 20.7204 - kl_loss: 3.3160 - val_loss: 27021.8008 - val_reco_loss: 23.3245 - val_kl_loss: 26998.4766 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.6036 - reco_loss: 20.3068 - kl_loss: 3.2923 - val_loss: 26755.7637 - val_reco_loss: 21.9133 - val_kl_loss: 26733.8496 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.5681 - reco_loss: 20.2936 - kl_loss: 3.2712 - val_loss: 26593.5898 - val_reco_loss: 23.0819 - val_kl_loss: 26570.5078 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.1766 - reco_loss: 19.9374 - kl_loss: 3.2384 - val_loss: 26403.7285 - val_reco_loss: 28.3809 - val_kl_loss: 26375.3477 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.8464 - reco_loss: 19.6197 - kl_loss: 3.2228 - val_loss: 26069.2598 - val_reco_loss: 26.9722 - val_kl_loss: 26042.2871 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.3047 - reco_loss: 20.1061 - kl_loss: 3.1959 - val_loss: 26401.2578 - val_reco_loss: 30.8593 - val_kl_loss: 26370.3984 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.0615 - reco_loss: 19.8776 - kl_loss: 3.1707 - val_loss: 25801.5801 - val_reco_loss: 22.4049 - val_kl_loss: 25779.1758 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.2823 - reco_loss: 20.1248 - kl_loss: 3.1476 - val_loss: 25523.1738 - val_reco_loss: 21.4826 - val_kl_loss: 25501.6914 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1083 - reco_loss: 18.9808 - kl_loss: 3.1214 - val_loss: 25185.9883 - val_reco_loss: 21.9654 - val_kl_loss: 25164.0234 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.7224 - reco_loss: 23.5909 - kl_loss: 3.1601 - val_loss: 26021.4336 - val_reco_loss: 29.9590 - val_kl_loss: 25991.4746 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8793 - reco_loss: 18.7218 - kl_loss: 3.1507 - val_loss: 25539.3301 - val_reco_loss: 22.3564 - val_kl_loss: 25516.9746 - lr: 0.0010\n",
      "Epoch 48/100\n",
      " 416/1800 [=====>........................] - ETA: 6s - loss: 23.3007 - reco_loss: 20.1632 - kl_loss: 3.1391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.9398 - reco_loss: 16.8980 - kl_loss: 3.0380 - val_loss: 24727.9844 - val_reco_loss: 21.2149 - val_kl_loss: 24706.7695 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.9748 - reco_loss: 16.9416 - kl_loss: 3.0309 - val_loss: 24637.9141 - val_reco_loss: 20.9056 - val_kl_loss: 24617.0078 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8041 - reco_loss: 16.7769 - kl_loss: 3.0243 - val_loss: 24611.3984 - val_reco_loss: 20.1605 - val_kl_loss: 24591.2383 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.5292 - reco_loss: 16.5509 - kl_loss: 2.9754 - val_loss: 24133.0879 - val_reco_loss: 21.5416 - val_kl_loss: 24111.5469 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.0127 - reco_loss: 17.0408 - kl_loss: 2.9694 - val_loss: 24119.1426 - val_reco_loss: 20.7237 - val_kl_loss: 24098.4180 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.5759 - reco_loss: 16.6141 - kl_loss: 2.9637 - val_loss: 24072.0430 - val_reco_loss: 20.8145 - val_kl_loss: 24051.2285 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.6364 - reco_loss: 16.6777 - kl_loss: 2.9590 - val_loss: 24024.4902 - val_reco_loss: 20.9522 - val_kl_loss: 24003.5371 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.9308 - reco_loss: 16.9703 - kl_loss: 2.9540 - val_loss: 23989.1211 - val_reco_loss: 21.6863 - val_kl_loss: 23967.4355 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.3078 - reco_loss: 16.3636 - kl_loss: 2.9481 - val_loss: 23978.0098 - val_reco_loss: 23.2781 - val_kl_loss: 23954.7324 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7552 - reco_loss: 16.8095 - kl_loss: 2.9438 - val_loss: 23876.7090 - val_reco_loss: 20.9364 - val_kl_loss: 23855.7734 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.2905 - reco_loss: 16.3540 - kl_loss: 2.9392 - val_loss: 23855.7500 - val_reco_loss: 21.5510 - val_kl_loss: 23834.1992 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.0739 - reco_loss: 17.1393 - kl_loss: 2.9347 - val_loss: 23820.1016 - val_reco_loss: 21.4974 - val_kl_loss: 23798.6035 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7074 - reco_loss: 16.7773 - kl_loss: 2.9303 - val_loss: 23784.2051 - val_reco_loss: 21.0415 - val_kl_loss: 23763.1641 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7291 - reco_loss: 16.8013 - kl_loss: 2.9261 - val_loss: 23738.7910 - val_reco_loss: 20.4678 - val_kl_loss: 23718.3242 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7580 - reco_loss: 16.8341 - kl_loss: 2.9212 - val_loss: 23664.6152 - val_reco_loss: 22.0432 - val_kl_loss: 23642.5723 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.6525 - reco_loss: 16.7388 - kl_loss: 2.9165 - val_loss: 23734.4766 - val_reco_loss: 20.2419 - val_kl_loss: 23714.2344 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7649 - reco_loss: 16.8470 - kl_loss: 2.9131 - val_loss: 23655.0332 - val_reco_loss: 20.6940 - val_kl_loss: 23634.3398 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.6238 - reco_loss: 16.7114 - kl_loss: 2.9081 - val_loss: 23612.1738 - val_reco_loss: 20.9291 - val_kl_loss: 23591.2441 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8695 - reco_loss: 16.9653 - kl_loss: 2.9051 - val_loss: 23553.6738 - val_reco_loss: 20.5677 - val_kl_loss: 23533.1055 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.5863 - reco_loss: 16.6836 - kl_loss: 2.9001 - val_loss: 23570.5703 - val_reco_loss: 20.6761 - val_kl_loss: 23549.8945 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7299 - reco_loss: 16.8312 - kl_loss: 2.8974 - val_loss: 23480.1816 - val_reco_loss: 21.2284 - val_kl_loss: 23458.9531 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      " 865/1800 [=============>................] - ETA: 4s - loss: 19.2059 - reco_loss: 16.3149 - kl_loss: 2.8948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 45.4829 - reco_loss: 38.2451 - kl_loss: 6.9578 - val_loss: 54822.0430 - val_reco_loss: 34.1982 - val_kl_loss: 54787.8438 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 42.7106 - reco_loss: 36.3884 - kl_loss: 6.1091 - val_loss: 48326.4180 - val_reco_loss: 37.1202 - val_kl_loss: 48289.2969 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.0225 - reco_loss: 34.4017 - kl_loss: 5.4896 - val_loss: 43791.4375 - val_reco_loss: 32.1950 - val_kl_loss: 43759.2422 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.0230 - reco_loss: 30.0229 - kl_loss: 3.9889 - val_loss: 32477.4082 - val_reco_loss: 28.8157 - val_kl_loss: 32448.5918 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.2254 - reco_loss: 29.2876 - kl_loss: 3.9130 - val_loss: 31969.5215 - val_reco_loss: 33.4662 - val_kl_loss: 31936.0547 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.2774 - reco_loss: 28.4268 - kl_loss: 3.8360 - val_loss: 31281.7520 - val_reco_loss: 38.4432 - val_kl_loss: 31243.3086 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.1181 - reco_loss: 29.3443 - kl_loss: 3.7707 - val_loss: 30893.9863 - val_reco_loss: 28.6404 - val_kl_loss: 30865.3457 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.2848 - reco_loss: 27.5480 - kl_loss: 3.7187 - val_loss: 30494.0352 - val_reco_loss: 33.8357 - val_kl_loss: 30460.1992 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6827 - reco_loss: 28.0014 - kl_loss: 3.6818 - val_loss: 29904.8418 - val_reco_loss: 28.2463 - val_kl_loss: 29876.5957 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.9079 - reco_loss: 27.2720 - kl_loss: 3.6280 - val_loss: 29675.0371 - val_reco_loss: 28.4726 - val_kl_loss: 29646.5645 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.1360 - reco_loss: 27.5428 - kl_loss: 3.5893 - val_loss: 29295.0547 - val_reco_loss: 27.0108 - val_kl_loss: 29268.0430 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.8483 - reco_loss: 26.2914 - kl_loss: 3.5549 - val_loss: 28986.4414 - val_reco_loss: 31.5907 - val_kl_loss: 28954.8516 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.2889 - reco_loss: 27.7510 - kl_loss: 3.5170 - val_loss: 28483.9492 - val_reco_loss: 27.2422 - val_kl_loss: 28456.7070 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.9222 - reco_loss: 26.4526 - kl_loss: 3.4624 - val_loss: 28378.1621 - val_reco_loss: 33.9696 - val_kl_loss: 28344.1934 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5113 - reco_loss: 26.0755 - kl_loss: 3.4303 - val_loss: 27924.7324 - val_reco_loss: 33.4049 - val_kl_loss: 27891.3281 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7566 - reco_loss: 27.3350 - kl_loss: 3.4005 - val_loss: 28365.0352 - val_reco_loss: 168.4835 - val_kl_loss: 28196.5508 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 38.3437 - reco_loss: 34.7743 - kl_loss: 3.5054 - val_loss: 28127.0898 - val_reco_loss: 30.6246 - val_kl_loss: 28096.4648 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.0761 - reco_loss: 26.6583 - kl_loss: 3.3994 - val_loss: 27660.8477 - val_reco_loss: 32.3870 - val_kl_loss: 27628.4609 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.5633 - reco_loss: 26.1989 - kl_loss: 3.3499 - val_loss: 27231.9844 - val_reco_loss: 27.9530 - val_kl_loss: 27204.0312 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.2491 - reco_loss: 25.9249 - kl_loss: 3.3124 - val_loss: 26906.1797 - val_reco_loss: 27.7663 - val_kl_loss: 26878.4141 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.8991 - reco_loss: 25.6135 - kl_loss: 3.2758 - val_loss: 26650.1641 - val_reco_loss: 27.9446 - val_kl_loss: 26622.2188 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1489/1800 [=======================>......] - ETA: 1s - loss: 29.1163 - reco_loss: 25.8632 - kl_loss: 3.2516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 13s 5ms/step - loss: 5973.4458 - reco_loss: 5843.4151 - kl_loss: 104.6442 - val_loss: 450414.2500 - val_reco_loss: 219.8307 - val_kl_loss: 450194.4062 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 192.5754 - reco_loss: 150.9646 - kl_loss: 34.7387 - val_loss: 208073.0469 - val_reco_loss: 102.9541 - val_kl_loss: 207970.0938 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 85.9337 - reco_loss: 64.5033 - kl_loss: 19.1030 - val_loss: 131324.5938 - val_reco_loss: 57.1587 - val_kl_loss: 131267.4375 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.5330 - reco_loss: 28.4847 - kl_loss: 4.9798 - val_loss: 40657.2500 - val_reco_loss: 30.7839 - val_kl_loss: 40626.4648 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.5691 - reco_loss: 27.7586 - kl_loss: 4.7588 - val_loss: 38488.6484 - val_reco_loss: 34.4765 - val_kl_loss: 38454.1719 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.8732 - reco_loss: 28.2774 - kl_loss: 4.5434 - val_loss: 37000.3281 - val_reco_loss: 31.1409 - val_kl_loss: 36969.1875 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.7748 - reco_loss: 28.2943 - kl_loss: 4.4502 - val_loss: 36748.1445 - val_reco_loss: 29.9344 - val_kl_loss: 36718.2109 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.6427 - reco_loss: 25.2969 - kl_loss: 4.3087 - val_loss: 34829.1523 - val_reco_loss: 39.5970 - val_kl_loss: 34789.5547 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6237 - reco_loss: 27.4413 - kl_loss: 4.1615 - val_loss: 34140.5703 - val_reco_loss: 29.8114 - val_kl_loss: 34110.7578 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.6738 - reco_loss: 25.5985 - kl_loss: 4.0417 - val_loss: 32876.0430 - val_reco_loss: 32.1739 - val_kl_loss: 32843.8672 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.3498 - reco_loss: 24.3769 - kl_loss: 3.9517 - val_loss: 32268.5371 - val_reco_loss: 32.5174 - val_kl_loss: 32236.0195 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.3087 - reco_loss: 24.4253 - kl_loss: 3.8737 - val_loss: 32969.9570 - val_reco_loss: 38.2702 - val_kl_loss: 32931.6875 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.3222 - reco_loss: 24.4632 - kl_loss: 3.8122 - val_loss: 31249.2285 - val_reco_loss: 28.9045 - val_kl_loss: 31220.3242 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.6327 - reco_loss: 23.8732 - kl_loss: 3.7420 - val_loss: 30914.2266 - val_reco_loss: 31.0476 - val_kl_loss: 30883.1797 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.2064 - reco_loss: 23.5017 - kl_loss: 3.6939 - val_loss: 30315.2754 - val_reco_loss: 29.2853 - val_kl_loss: 30285.9902 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.7980 - reco_loss: 23.1551 - kl_loss: 3.6387 - val_loss: 29975.9980 - val_reco_loss: 28.5287 - val_kl_loss: 29947.4688 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.2525 - reco_loss: 23.6545 - kl_loss: 3.6015 - val_loss: 30143.3711 - val_reco_loss: 27.1924 - val_kl_loss: 30116.1777 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.9268 - reco_loss: 34.3139 - kl_loss: 3.7784 - val_loss: 64468.9023 - val_reco_loss: 507.8278 - val_kl_loss: 63961.0742 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 202.0994 - reco_loss: 195.5078 - kl_loss: 6.0574 - val_loss: 46329.0547 - val_reco_loss: 61.7277 - val_kl_loss: 46267.3281 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1790/1800 [============================>.] - ETA: 0s - loss: 52.2499 - reco_loss: 47.1010 - kl_loss: 5.0590\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 52.2730 - reco_loss: 47.1247 - kl_loss: 5.0582 - val_loss: 42787.1172 - val_reco_loss: 47.6639 - val_kl_loss: 42739.4531 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 40.6529 - reco_loss: 35.7391 - kl_loss: 4.9036 - val_loss: 42004.8125 - val_reco_loss: 45.1475 - val_kl_loss: 41959.6641 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1006/1800 [===============>..............] - ETA: 3s - loss: 38.2818 - reco_loss: 33.4316 - kl_loss: 4.8280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.1107 - reco_loss: 20.4163 - kl_loss: 3.6899 - val_loss: 29773.4043 - val_reco_loss: 28.3881 - val_kl_loss: 29745.0156 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.4142 - reco_loss: 24.7475 - kl_loss: 3.7401 - val_loss: 31616.3750 - val_reco_loss: 28.6811 - val_kl_loss: 31587.6934 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.0397 - reco_loss: 20.2029 - kl_loss: 3.8072 - val_loss: 30466.1641 - val_reco_loss: 25.2144 - val_kl_loss: 30440.9492 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0529 - reco_loss: 18.6845 - kl_loss: 3.3331 - val_loss: 26890.5176 - val_reco_loss: 32.8659 - val_kl_loss: 26857.6523 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4007 - reco_loss: 19.0961 - kl_loss: 3.2981 - val_loss: 26299.4102 - val_reco_loss: 24.9568 - val_kl_loss: 26274.4531 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.5211 - reco_loss: 19.2425 - kl_loss: 3.2748 - val_loss: 26730.0977 - val_reco_loss: 29.5161 - val_kl_loss: 26700.5820 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4510 - reco_loss: 19.1879 - kl_loss: 3.2665 - val_loss: 26185.4805 - val_reco_loss: 30.2122 - val_kl_loss: 26155.2676 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.5716 - reco_loss: 19.3333 - kl_loss: 3.2249 - val_loss: 26094.7070 - val_reco_loss: 24.4449 - val_kl_loss: 26070.2617 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.2236 - reco_loss: 19.0125 - kl_loss: 3.2021 - val_loss: 25978.0918 - val_reco_loss: 40.3935 - val_kl_loss: 25937.6992 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.8341 - reco_loss: 19.6401 - kl_loss: 3.1860 - val_loss: 25678.1426 - val_reco_loss: 26.9291 - val_kl_loss: 25651.2129 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.9038 - reco_loss: 18.7467 - kl_loss: 3.1546 - val_loss: 25432.0645 - val_reco_loss: 24.7354 - val_kl_loss: 25407.3281 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8606 - reco_loss: 18.7102 - kl_loss: 3.1465 - val_loss: 25438.0391 - val_reco_loss: 23.5789 - val_kl_loss: 25414.4609 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8553 - reco_loss: 18.7398 - kl_loss: 3.1098 - val_loss: 25130.0859 - val_reco_loss: 24.0679 - val_kl_loss: 25106.0176 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0221 - reco_loss: 18.9110 - kl_loss: 3.1236 - val_loss: 25235.5352 - val_reco_loss: 22.9341 - val_kl_loss: 25212.6016 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.4792 - reco_loss: 18.3688 - kl_loss: 3.1025 - val_loss: 25507.2285 - val_reco_loss: 24.3514 - val_kl_loss: 25482.8770 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.8977 - reco_loss: 17.7948 - kl_loss: 3.0713 - val_loss: 24765.2520 - val_reco_loss: 23.0426 - val_kl_loss: 24742.2090 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.8085 - reco_loss: 17.7596 - kl_loss: 3.0478 - val_loss: 24581.6250 - val_reco_loss: 22.5258 - val_kl_loss: 24559.0996 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0709 - reco_loss: 19.0283 - kl_loss: 3.0350 - val_loss: 24480.5469 - val_reco_loss: 26.1711 - val_kl_loss: 24454.3750 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.7043 - reco_loss: 18.6722 - kl_loss: 3.0231 - val_loss: 24494.9531 - val_reco_loss: 21.2209 - val_kl_loss: 24473.7324 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.3641 - reco_loss: 18.3549 - kl_loss: 3.0131 - val_loss: 24497.8477 - val_reco_loss: 22.4957 - val_kl_loss: 24475.3516 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.4953 - reco_loss: 17.4847 - kl_loss: 3.0022 - val_loss: 24210.4863 - val_reco_loss: 23.5528 - val_kl_loss: 24186.9336 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1024/1800 [================>.............] - ETA: 3s - loss: 20.9957 - reco_loss: 18.0038 - kl_loss: 2.9837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.9498 - reco_loss: 17.1489 - kl_loss: 2.7979 - val_loss: 22609.7637 - val_reco_loss: 21.5052 - val_kl_loss: 22588.2578 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.5332 - reco_loss: 17.7406 - kl_loss: 2.7921 - val_loss: 22491.6934 - val_reco_loss: 23.7589 - val_kl_loss: 22467.9336 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.0158 - reco_loss: 17.2337 - kl_loss: 2.7848 - val_loss: 22556.5645 - val_reco_loss: 27.4638 - val_kl_loss: 22529.1016 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.5099 - reco_loss: 16.7412 - kl_loss: 2.7644 - val_loss: 22081.3145 - val_reco_loss: 34.2723 - val_kl_loss: 22047.0430 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8826 - reco_loss: 17.1368 - kl_loss: 2.7441 - val_loss: 22152.6094 - val_reco_loss: 21.9339 - val_kl_loss: 22130.6758 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8670 - reco_loss: 17.1266 - kl_loss: 2.7364 - val_loss: 22124.0059 - val_reco_loss: 23.1353 - val_kl_loss: 22100.8711 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.6372 - reco_loss: 17.8909 - kl_loss: 2.7475 - val_loss: 22134.6172 - val_reco_loss: 24.0144 - val_kl_loss: 22110.6035 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.5124 - reco_loss: 16.7811 - kl_loss: 2.7315 - val_loss: 22030.9531 - val_reco_loss: 31.0552 - val_kl_loss: 21999.8984 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.9202 - reco_loss: 18.1902 - kl_loss: 2.7260 - val_loss: 22013.4395 - val_reco_loss: 22.1234 - val_kl_loss: 21991.3164 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7541 - reco_loss: 17.0289 - kl_loss: 2.7583 - val_loss: 23341.5215 - val_reco_loss: 22.7688 - val_kl_loss: 23318.7520 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7679 - reco_loss: 16.9025 - kl_loss: 2.8564 - val_loss: 22953.4922 - val_reco_loss: 23.5460 - val_kl_loss: 22929.9453 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.2595 - reco_loss: 18.4220 - kl_loss: 2.8227 - val_loss: 22628.3320 - val_reco_loss: 23.0945 - val_kl_loss: 22605.2383 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1798/1800 [============================>.] - ETA: 0s - loss: 19.7526 - reco_loss: 16.9582 - kl_loss: 2.7861\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7529 - reco_loss: 16.9585 - kl_loss: 2.7861 - val_loss: 22292.1836 - val_reco_loss: 24.8679 - val_kl_loss: 22267.3164 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.8391 - reco_loss: 15.0839 - kl_loss: 2.7518 - val_loss: 22192.5566 - val_reco_loss: 20.8453 - val_kl_loss: 22171.7109 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.9410 - reco_loss: 15.1897 - kl_loss: 2.7425 - val_loss: 22095.8672 - val_reco_loss: 21.7264 - val_kl_loss: 22074.1406 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 18.0389 - reco_loss: 15.3088 - kl_loss: 2.7278 - val_loss: 21994.8418 - val_reco_loss: 21.2330 - val_kl_loss: 21973.6094 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.9292 - reco_loss: 15.2104 - kl_loss: 2.7194 - val_loss: 21997.8262 - val_reco_loss: 21.1778 - val_kl_loss: 21976.6484 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.9650 - reco_loss: 15.2453 - kl_loss: 2.7172 - val_loss: 21947.7461 - val_reco_loss: 20.2237 - val_kl_loss: 21927.5215 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.9106 - reco_loss: 15.1953 - kl_loss: 2.7126 - val_loss: 21889.1465 - val_reco_loss: 20.3558 - val_kl_loss: 21868.7910 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.9298 - reco_loss: 15.2213 - kl_loss: 2.7082 - val_loss: 21857.7852 - val_reco_loss: 20.0410 - val_kl_loss: 21837.7441 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 17.7692 - reco_loss: 15.0646 - kl_loss: 2.7051 - val_loss: 21847.2480 - val_reco_loss: 21.0105 - val_kl_loss: 21826.2383 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      " 826/1800 [============>.................] - ETA: 4s - loss: 18.0145 - reco_loss: 15.3085 - kl_loss: 2.7060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 37.9427 - reco_loss: 31.3446 - kl_loss: 6.6185 - val_loss: 57491.4688 - val_reco_loss: 31.7415 - val_kl_loss: 57459.7266 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.2667 - reco_loss: 29.6307 - kl_loss: 6.4485 - val_loss: 52123.9570 - val_reco_loss: 37.9326 - val_kl_loss: 52086.0234 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 34.4403 - reco_loss: 28.3861 - kl_loss: 6.0578 - val_loss: 52280.8984 - val_reco_loss: 28.8987 - val_kl_loss: 52252.0000 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.1431 - reco_loss: 29.0478 - kl_loss: 6.0492 - val_loss: 49478.1406 - val_reco_loss: 34.9139 - val_kl_loss: 49443.2266 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.5448 - reco_loss: 25.0891 - kl_loss: 5.4378 - val_loss: 44392.0156 - val_reco_loss: 25.5898 - val_kl_loss: 44366.4258 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.9179 - reco_loss: 24.5720 - kl_loss: 5.3182 - val_loss: 43328.7227 - val_reco_loss: 25.9049 - val_kl_loss: 43302.8164 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.4841 - reco_loss: 24.2638 - kl_loss: 5.1698 - val_loss: 41923.9492 - val_reco_loss: 25.8466 - val_kl_loss: 41898.1016 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.8737 - reco_loss: 23.8299 - kl_loss: 5.0382 - val_loss: 41166.3750 - val_reco_loss: 23.3451 - val_kl_loss: 41143.0312 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.9534 - reco_loss: 23.9822 - kl_loss: 4.9128 - val_loss: 40080.4336 - val_reco_loss: 23.4681 - val_kl_loss: 40056.9648 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.4277 - reco_loss: 23.6309 - kl_loss: 4.7531 - val_loss: 38477.8125 - val_reco_loss: 23.3586 - val_kl_loss: 38454.4531 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.0048 - reco_loss: 23.4081 - kl_loss: 4.5301 - val_loss: 36652.3398 - val_reco_loss: 23.6203 - val_kl_loss: 36628.7188 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.0558 - reco_loss: 22.6598 - kl_loss: 4.3960 - val_loss: 36355.9336 - val_reco_loss: 23.2477 - val_kl_loss: 36332.6875 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.8503 - reco_loss: 22.4913 - kl_loss: 4.3528 - val_loss: 35814.5938 - val_reco_loss: 22.7245 - val_kl_loss: 35791.8711 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.8241 - reco_loss: 22.5096 - kl_loss: 4.2900 - val_loss: 35273.5586 - val_reco_loss: 22.6839 - val_kl_loss: 35250.8750 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.2535 - reco_loss: 22.0057 - kl_loss: 4.2409 - val_loss: 34991.0234 - val_reco_loss: 23.0535 - val_kl_loss: 34967.9688 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.0949 - reco_loss: 21.8821 - kl_loss: 4.1886 - val_loss: 34581.6641 - val_reco_loss: 23.0938 - val_kl_loss: 34558.5703 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.8442 - reco_loss: 21.6825 - kl_loss: 4.1438 - val_loss: 34134.2500 - val_reco_loss: 22.3112 - val_kl_loss: 34111.9375 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.6400 - reco_loss: 21.5338 - kl_loss: 4.1040 - val_loss: 33877.2031 - val_reco_loss: 22.1356 - val_kl_loss: 33855.0664 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.9750 - reco_loss: 20.9013 - kl_loss: 4.0654 - val_loss: 33486.4961 - val_reco_loss: 23.3421 - val_kl_loss: 33463.1523 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.9170 - reco_loss: 20.8973 - kl_loss: 4.0154 - val_loss: 33206.7773 - val_reco_loss: 21.4580 - val_kl_loss: 33185.3203 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.7147 - reco_loss: 20.7134 - kl_loss: 4.0022 - val_loss: 33117.0469 - val_reco_loss: 21.6085 - val_kl_loss: 33095.4375 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.6350 - reco_loss: 20.6456 - kl_loss: 3.9773 - val_loss: 32832.1445 - val_reco_loss: 21.5444 - val_kl_loss: 32810.6016 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      " 585/1800 [========>.....................] - ETA: 5s - loss: 23.6313 - reco_loss: 19.6794 - kl_loss: 3.9609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.6485 - reco_loss: 19.1675 - kl_loss: 3.4789 - val_loss: 28605.0195 - val_reco_loss: 21.5409 - val_kl_loss: 28583.4785 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.3678 - reco_loss: 18.9050 - kl_loss: 3.4646 - val_loss: 28573.5547 - val_reco_loss: 20.7958 - val_kl_loss: 28552.7598 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.2443 - reco_loss: 18.7942 - kl_loss: 3.4468 - val_loss: 28387.1562 - val_reco_loss: 20.9262 - val_kl_loss: 28366.2305 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.3374 - reco_loss: 18.9722 - kl_loss: 3.3621 - val_loss: 27853.1133 - val_reco_loss: 21.5406 - val_kl_loss: 27831.5723 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4019 - reco_loss: 19.0324 - kl_loss: 3.3603 - val_loss: 27586.7090 - val_reco_loss: 22.4348 - val_kl_loss: 27564.2734 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4105 - reco_loss: 19.0634 - kl_loss: 3.3436 - val_loss: 27681.1250 - val_reco_loss: 21.6494 - val_kl_loss: 27659.4746 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.9910 - reco_loss: 18.6469 - kl_loss: 3.3457 - val_loss: 27499.4512 - val_reco_loss: 22.6625 - val_kl_loss: 27476.7891 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4013 - reco_loss: 19.0637 - kl_loss: 3.3325 - val_loss: 27577.6934 - val_reco_loss: 21.8698 - val_kl_loss: 27555.8242 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1674 - reco_loss: 18.8390 - kl_loss: 3.3231 - val_loss: 27324.2930 - val_reco_loss: 20.6947 - val_kl_loss: 27303.5977 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.5032 - reco_loss: 19.1908 - kl_loss: 3.3105 - val_loss: 27311.9629 - val_reco_loss: 20.8095 - val_kl_loss: 27291.1543 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.4986 - reco_loss: 19.1894 - kl_loss: 3.3025 - val_loss: 27160.4102 - val_reco_loss: 20.7335 - val_kl_loss: 27139.6758 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0998 - reco_loss: 18.8033 - kl_loss: 3.2940 - val_loss: 27118.4121 - val_reco_loss: 21.6050 - val_kl_loss: 27096.8066 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0278 - reco_loss: 18.7368 - kl_loss: 3.2895 - val_loss: 27039.9531 - val_reco_loss: 22.3403 - val_kl_loss: 27017.6133 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.2325 - reco_loss: 18.9515 - kl_loss: 3.2785 - val_loss: 26998.6328 - val_reco_loss: 21.5446 - val_kl_loss: 26977.0879 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8779 - reco_loss: 18.6038 - kl_loss: 3.2754 - val_loss: 26822.7734 - val_reco_loss: 23.4875 - val_kl_loss: 26799.2852 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.8527 - reco_loss: 18.5882 - kl_loss: 3.2633 - val_loss: 26863.8633 - val_reco_loss: 21.1361 - val_kl_loss: 26842.7266 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1919 - reco_loss: 18.9186 - kl_loss: 3.2666 - val_loss: 26791.7676 - val_reco_loss: 22.1036 - val_kl_loss: 26769.6641 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.6586 - reco_loss: 18.4106 - kl_loss: 3.2515 - val_loss: 26709.2949 - val_reco_loss: 21.3538 - val_kl_loss: 26687.9414 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.9609 - reco_loss: 18.7215 - kl_loss: 3.2473 - val_loss: 26804.9180 - val_reco_loss: 20.2470 - val_kl_loss: 26784.6719 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.7417 - reco_loss: 18.4953 - kl_loss: 3.2437 - val_loss: 26602.7617 - val_reco_loss: 22.3099 - val_kl_loss: 26580.4512 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0077 - reco_loss: 18.7771 - kl_loss: 3.2303 - val_loss: 26604.1426 - val_reco_loss: 21.4124 - val_kl_loss: 26582.7305 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1179/1800 [==================>...........] - ETA: 2s - loss: 22.4136 - reco_loss: 19.1910 - kl_loss: 3.2245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 13s 5ms/step - loss: 6389.2530 - reco_loss: 6288.3963 - kl_loss: 92.4779 - val_loss: 467612.7812 - val_reco_loss: 278.5961 - val_kl_loss: 467334.1875 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 227.9186 - reco_loss: 183.5358 - kl_loss: 36.9542 - val_loss: 222473.8750 - val_reco_loss: 187.6912 - val_kl_loss: 222286.1875 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.7453 - reco_loss: 26.0617 - kl_loss: 5.5783 - val_loss: 48850.8438 - val_reco_loss: 72.7047 - val_kl_loss: 48778.1406 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 32.3073 - reco_loss: 26.7509 - kl_loss: 5.3827 - val_loss: 43512.4414 - val_reco_loss: 32.4489 - val_kl_loss: 43479.9922 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.3322 - reco_loss: 28.0780 - kl_loss: 5.1466 - val_loss: 41370.2578 - val_reco_loss: 24.7626 - val_kl_loss: 41345.4961 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 47.0247 - reco_loss: 41.5742 - kl_loss: 5.7623 - val_loss: 46863.6836 - val_reco_loss: 31.6038 - val_kl_loss: 46832.0781 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 35.7929 - reco_loss: 30.4011 - kl_loss: 5.1921 - val_loss: 40532.5625 - val_reco_loss: 30.2669 - val_kl_loss: 40502.2969 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 33.4022 - reco_loss: 28.5996 - kl_loss: 4.7223 - val_loss: 38085.5859 - val_reco_loss: 29.0888 - val_kl_loss: 38056.4961 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.3683 - reco_loss: 26.8591 - kl_loss: 4.4877 - val_loss: 36703.6758 - val_reco_loss: 34.4728 - val_kl_loss: 36669.2031 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.7250 - reco_loss: 26.3435 - kl_loss: 4.3268 - val_loss: 34638.4727 - val_reco_loss: 24.1996 - val_kl_loss: 34614.2734 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 30.8113 - reco_loss: 26.6224 - kl_loss: 4.1746 - val_loss: 33681.4570 - val_reco_loss: 26.4171 - val_kl_loss: 33655.0391 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 57.1866 - reco_loss: 53.0624 - kl_loss: 4.8834 - val_loss: 63588.5234 - val_reco_loss: 93.7675 - val_kl_loss: 63494.7578 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 63.4301 - reco_loss: 56.4708 - kl_loss: 6.6828 - val_loss: 53979.3047 - val_reco_loss: 36.4597 - val_kl_loss: 53942.8438 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 36.5081 - reco_loss: 30.6381 - kl_loss: 5.4960 - val_loss: 41974.9141 - val_reco_loss: 30.6147 - val_kl_loss: 41944.3008 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1798/1800 [============================>.] - ETA: 0s - loss: 31.3445 - reco_loss: 26.5103 - kl_loss: 4.7096\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.3427 - reco_loss: 26.5087 - kl_loss: 4.7096 - val_loss: 38072.4570 - val_reco_loss: 24.9161 - val_kl_loss: 38047.5391 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 27.1936 - reco_loss: 22.6851 - kl_loss: 4.5000 - val_loss: 37699.0078 - val_reco_loss: 23.1892 - val_kl_loss: 37675.8203 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.5193 - reco_loss: 22.0469 - kl_loss: 4.4481 - val_loss: 37132.0898 - val_reco_loss: 23.9647 - val_kl_loss: 37108.1250 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.2247 - reco_loss: 21.8350 - kl_loss: 4.3634 - val_loss: 36236.3867 - val_reco_loss: 22.2055 - val_kl_loss: 36214.1797 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1793/1800 [============================>.] - ETA: 0s - loss: 25.6969 - reco_loss: 21.4215 - kl_loss: 4.2639\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.6971 - reco_loss: 21.4217 - kl_loss: 4.2636 - val_loss: 35399.4062 - val_reco_loss: 21.4062 - val_kl_loss: 35378.0000 - lr: 1.0000e-04\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 12s 5ms/step - loss: 5902.2269 - reco_loss: 5832.3814 - kl_loss: 66.3966 - val_loss: 391942.2500 - val_reco_loss: 197.9161 - val_kl_loss: 391744.3438 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1409/1800 [======================>.......] - ETA: 1s - loss: 192.8731 - reco_loss: 152.4726 - kl_loss: 35.7112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.6190 - reco_loss: 27.3184 - kl_loss: 4.2926 - val_loss: 34834.5820 - val_reco_loss: 34.9648 - val_kl_loss: 34799.6172 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 31.4362 - reco_loss: 27.2319 - kl_loss: 4.1780 - val_loss: 34234.6719 - val_reco_loss: 26.9210 - val_kl_loss: 34207.7500 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.9863 - reco_loss: 25.8868 - kl_loss: 4.0870 - val_loss: 34267.8633 - val_reco_loss: 30.1459 - val_kl_loss: 34237.7188 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.7805 - reco_loss: 25.0497 - kl_loss: 3.7020 - val_loss: 29983.0273 - val_reco_loss: 35.4826 - val_kl_loss: 29947.5449 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.6160 - reco_loss: 25.9596 - kl_loss: 3.6460 - val_loss: 29915.8672 - val_reco_loss: 32.7648 - val_kl_loss: 29883.1016 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.3990 - reco_loss: 25.7800 - kl_loss: 3.6091 - val_loss: 29364.3027 - val_reco_loss: 25.6440 - val_kl_loss: 29338.6582 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 29.8910 - reco_loss: 26.2995 - kl_loss: 3.5721 - val_loss: 29352.4199 - val_reco_loss: 27.4754 - val_kl_loss: 29324.9453 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.7920 - reco_loss: 25.2252 - kl_loss: 3.5621 - val_loss: 29316.2207 - val_reco_loss: 26.1208 - val_kl_loss: 29290.0996 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 28.8828 - reco_loss: 25.3269 - kl_loss: 3.5545 - val_loss: 29526.8125 - val_reco_loss: 33.7953 - val_kl_loss: 29493.0176 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.4400 - reco_loss: 22.8774 - kl_loss: 3.5532 - val_loss: 29034.4434 - val_reco_loss: 22.7753 - val_kl_loss: 29011.6680 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.7031 - reco_loss: 23.1659 - kl_loss: 3.5223 - val_loss: 28775.9883 - val_reco_loss: 24.5689 - val_kl_loss: 28751.4199 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 26.1868 - reco_loss: 22.6974 - kl_loss: 3.4792 - val_loss: 28322.5098 - val_reco_loss: 22.7677 - val_kl_loss: 28299.7422 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 25.9210 - reco_loss: 22.4705 - kl_loss: 3.4414 - val_loss: 28077.7676 - val_reco_loss: 21.8467 - val_kl_loss: 28055.9199 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.9765 - reco_loss: 21.5677 - kl_loss: 3.4032 - val_loss: 27779.9434 - val_reco_loss: 24.2564 - val_kl_loss: 27755.6875 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.5209 - reco_loss: 21.1366 - kl_loss: 3.3797 - val_loss: 27556.5391 - val_reco_loss: 21.5659 - val_kl_loss: 27534.9727 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.0419 - reco_loss: 20.6952 - kl_loss: 3.3397 - val_loss: 27478.5469 - val_reco_loss: 25.2352 - val_kl_loss: 27453.3125 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.9729 - reco_loss: 20.6547 - kl_loss: 3.3157 - val_loss: 27196.9434 - val_reco_loss: 23.9084 - val_kl_loss: 27173.0352 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 24.2172 - reco_loss: 20.9139 - kl_loss: 3.2913 - val_loss: 26725.7832 - val_reco_loss: 23.8676 - val_kl_loss: 26701.9160 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.7082 - reco_loss: 20.4436 - kl_loss: 3.2600 - val_loss: 26717.2168 - val_reco_loss: 21.6342 - val_kl_loss: 26695.5820 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 10s 5ms/step - loss: 24.2411 - reco_loss: 20.9960 - kl_loss: 3.2404 - val_loss: 26321.0488 - val_reco_loss: 24.1420 - val_kl_loss: 26296.9062 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 23.6219 - reco_loss: 20.4014 - kl_loss: 3.2201 - val_loss: 26174.7305 - val_reco_loss: 22.0656 - val_kl_loss: 26152.6641 - lr: 0.0010\n",
      "Epoch 51/100\n",
      " 901/1800 [==============>...............] - ETA: 4s - loss: 22.7405 - reco_loss: 19.5422 - kl_loss: 3.1964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.0961 - reco_loss: 18.1849 - kl_loss: 2.9069 - val_loss: 23617.7656 - val_reco_loss: 30.5810 - val_kl_loss: 23587.1855 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.6745 - reco_loss: 18.7744 - kl_loss: 2.8948 - val_loss: 23437.2949 - val_reco_loss: 62.1779 - val_kl_loss: 23375.1172 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.0540 - reco_loss: 19.1705 - kl_loss: 2.8860 - val_loss: 23476.0254 - val_reco_loss: 29.6624 - val_kl_loss: 23446.3633 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 22.1759 - reco_loss: 19.2920 - kl_loss: 2.8769 - val_loss: 23317.6641 - val_reco_loss: 21.0043 - val_kl_loss: 23296.6602 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.9942 - reco_loss: 18.1708 - kl_loss: 2.8197 - val_loss: 22877.4180 - val_reco_loss: 21.0097 - val_kl_loss: 22856.4082 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 21.0348 - reco_loss: 18.2214 - kl_loss: 2.8141 - val_loss: 22770.3086 - val_reco_loss: 21.0109 - val_kl_loss: 22749.2969 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.4759 - reco_loss: 17.6670 - kl_loss: 2.8080 - val_loss: 22765.2402 - val_reco_loss: 20.6343 - val_kl_loss: 22744.6055 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.6386 - reco_loss: 17.8328 - kl_loss: 2.8043 - val_loss: 22790.3594 - val_reco_loss: 22.8865 - val_kl_loss: 22767.4727 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.1681 - reco_loss: 17.3700 - kl_loss: 2.7976 - val_loss: 22693.2422 - val_reco_loss: 30.2575 - val_kl_loss: 22662.9844 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.5280 - reco_loss: 17.7298 - kl_loss: 2.7930 - val_loss: 22608.3828 - val_reco_loss: 21.5564 - val_kl_loss: 22586.8262 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.7610 - reco_loss: 17.9624 - kl_loss: 2.7964 - val_loss: 22625.0254 - val_reco_loss: 21.5291 - val_kl_loss: 22603.4961 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.5207 - reco_loss: 17.7309 - kl_loss: 2.7899 - val_loss: 22601.2891 - val_reco_loss: 19.8401 - val_kl_loss: 22581.4492 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8972 - reco_loss: 17.1163 - kl_loss: 2.7791 - val_loss: 22597.0938 - val_reco_loss: 20.3708 - val_kl_loss: 22576.7227 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.0079 - reco_loss: 17.2139 - kl_loss: 2.7850 - val_loss: 22464.9336 - val_reco_loss: 21.2453 - val_kl_loss: 22443.6875 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.1119 - reco_loss: 17.3398 - kl_loss: 2.7737 - val_loss: 22475.6797 - val_reco_loss: 23.5774 - val_kl_loss: 22452.1016 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8035 - reco_loss: 17.0360 - kl_loss: 2.7698 - val_loss: 22518.3574 - val_reco_loss: 22.5088 - val_kl_loss: 22495.8496 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7712 - reco_loss: 17.0069 - kl_loss: 2.7667 - val_loss: 22456.3594 - val_reco_loss: 28.0439 - val_kl_loss: 22428.3164 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 20.0451 - reco_loss: 17.2848 - kl_loss: 2.7611 - val_loss: 22477.6973 - val_reco_loss: 28.9739 - val_kl_loss: 22448.7227 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7490 - reco_loss: 16.9926 - kl_loss: 2.7598 - val_loss: 22416.2031 - val_reco_loss: 20.9304 - val_kl_loss: 22395.2734 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.7079 - reco_loss: 16.9509 - kl_loss: 2.7555 - val_loss: 22487.7852 - val_reco_loss: 26.7995 - val_kl_loss: 22460.9863 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 9s 5ms/step - loss: 19.8908 - reco_loss: 17.1361 - kl_loss: 2.7514 - val_loss: 22266.0430 - val_reco_loss: 22.2016 - val_kl_loss: 22243.8418 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "#Here are the configurable parameters\n",
    "STOP_PATIENCE = 8\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "beta=0.83\n",
    "\n",
    "#latent_space_sizes=[7,8,9,10,11,12]\n",
    "#[0.001,0.1,0.2,0.3,0.4,0.5\n",
    "beta_values=[0.5]\n",
    "#[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "latent_sizes=[6,7,8]\n",
    "#[1,2,3,4,5,6,7,8]\n",
    "rep_num=10\n",
    "#Here is the loop training several models with differently sized latent spaces\n",
    "for b in beta_values:\n",
    "    for s in latent_sizes:\n",
    "            for n in range(0,rep_num):\n",
    "                vae_enc=make_encoder(57,32,16,s)\n",
    "                vae_dec=make_decoder(57,32,16,s)\n",
    "                vae_40MHZ=VAE_Model(vae_enc,vae_dec)\n",
    "                vae_40MHZ.set_beta(b)\n",
    "                opt=keras.optimizers.Adam(learning_rate=0.001)\n",
    "                vae_40MHZ.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "\n",
    "                early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "                reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "                callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "\n",
    "\n",
    "                history = vae_40MHZ.fit(x=Data_Train_Flat, validation_split=0.1,epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks,shuffle=True)\n",
    "                vae_40MHZ.save_weights(filepath='/eos/home-w/wsherman/AD_Work/ML_git_repo/AD_trigger_training/Miscellaneous Studies/Signal_Independant_Efficiency_Study/Models_for_Study/b_{}_s_{}_n{}/'.format(b,s,n),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f881a-94a2-4f17-a04c-1ccd0635cba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
