{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 00:45:29.342996: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-23 00:45:34.581995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('/eos/home-w/wsherman/AD_Work/n_tuples/40MHZ_data/background_for_training.h5','r')\n",
    "Dataset=np.array(f[\"Particles\"])\n",
    "\n",
    "truthtable=[]\n",
    "\n",
    "threshold=50\n",
    "for i, batch in enumerate(Dataset):\n",
    "  if np.sum(batch[:,0])>=threshold:\n",
    "    truthtable+=[1]\n",
    "  else:\n",
    "    truthtable+=[0]\n",
    "\n",
    "event_pt_br=[]\n",
    "Data_Test_full=Dataset[2000001:3600000,:,:]\n",
    "for j, br_1 in enumerate(Data_Test_full):\n",
    "  event_pt_br+=[np.sum(br_1[:,0])]\n",
    "\n",
    "for i, batch in enumerate(Dataset):\n",
    "  pt_sum=0\n",
    "  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "    if particle[3]!=0:\n",
    "      pt_sum+=particle[0]\n",
    "  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "    particle[0]=particle[0]/pt_sum\n",
    "\n",
    "    \n",
    "    \n",
    "Data_Train=Dataset[0:2000000,:,0:3]\n",
    "Data_Test=Dataset[2000001:3600000,:,0:3]\n",
    "Test_Truth=truthtable[2000001:3600000]\n",
    "Data_Validate=Dataset[3600001:4000000,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AE(input_dim, h_dim_1, h_dim_2, latent_dim):\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(h_dim_1, activation='relu')(inputs)\n",
    "    x = layers.Dense(h_dim_2, activation='relu')(x)\n",
    "    z = layers.Dense(latent_dim, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Dense(h_dim_2, activation='relu')(z)\n",
    "    x = layers.Dense(h_dim_1, activation='relu')(x)\n",
    "    outputs = layers.Dense(input_dim)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    \"\"\"masked mse\"\"\"\n",
    "    mask = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "    squared_difference = K.square(mask * (y_pred - y_true))\n",
    "    return K.mean(squared_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Train_Flat=np.reshape(Data_Train,(-1,57))\n",
    "Data_Val_Flat=np.reshape(Data_Validate,(-1,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 22:42:08.410020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:08.598026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:08.598449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:08.602892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:08.603185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:08.603479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:13.780599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:13.781032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:13.781321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-26 22:42:13.781583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13766 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1856      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 57)                1881      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5089 (19.88 KB)\n",
      "Trainable params: 5089 (19.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "INPUT_DIM = Data_Train_Flat.shape[1]\n",
    "H_DIM_1 = 32\n",
    "H_DIM_2 = 16\n",
    "LATENT_DIM = 8\n",
    "DNN_AE = create_AE(input_dim=INPUT_DIM, h_dim_1=H_DIM_1, h_dim_2=H_DIM_2, latent_dim=LATENT_DIM)\n",
    "DNN_AE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 22:42:29.430987: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89f800c730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-26 22:42:29.431061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-01-26 22:42:29.519699: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-26 22:42:31.559394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-26 22:42:32.728213: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954/1954 [==============================] - 28s 5ms/step - loss: 0.0234 - val_loss: 0.0077 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0073 - val_loss: 0.0068 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0067 - val_loss: 0.0064 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0064 - val_loss: 0.0062 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0062 - val_loss: 0.0061 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0061 - val_loss: 0.0059 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0060 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0059 - val_loss: 0.0058 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0057 - val_loss: 0.0055 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0055 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0054 - val_loss: 0.0054 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0054 - val_loss: 0.0053 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0053 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0053 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0052 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0051 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0049 - val_loss: 0.0049 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0048 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0047 - val_loss: 0.0046 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0046 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0046 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0046 - val_loss: 0.0047 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0045 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0045 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1948/1954 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0045 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1946/1954 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0044 - val_loss: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1954/1954 [==============================] - 10s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "1948/1954 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-06\n",
      "Epoch 36/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-06\n",
      "Epoch 37/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-06\n",
      "Epoch 38/50\n",
      "1950/1954 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-06\n",
      "Epoch 39/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-07\n",
      "Epoch 40/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-07\n",
      "Epoch 41/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-07\n",
      "Epoch 42/50\n",
      "1952/1954 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-07\n",
      "Epoch 43/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-08\n",
      "Epoch 44/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-08\n",
      "Epoch 45/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-08\n",
      "Epoch 46/50\n",
      "1954/1954 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-08\n",
      "Epoch 47/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-09\n",
      "Epoch 48/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-09\n",
      "Epoch 49/50\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-09\n",
      "Epoch 50/50\n",
      "1948/1954 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "1954/1954 [==============================] - 9s 5ms/step - loss: 0.0043 - val_loss: 0.0043 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "DNN_AE.compile(optimizer='adam', loss=loss_fn)\n",
    "\n",
    "STOP_PATIENCE = 8\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "history = DNN_AE.fit(x=Data_Train_Flat, y=Data_Train_Flat, validation_data=(Data_Val_Flat,Data_Val_Flat), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_AE.save('/eos/home-w/wsherman/AD_Work/ML_git_repo/AD_trigger_training/trained_models/40MHZ_norm_DNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
