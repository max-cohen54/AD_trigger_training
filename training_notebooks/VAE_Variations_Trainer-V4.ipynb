{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c66c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 22:59:12.009842: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 22:59:12.126109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20999b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('/eos/home-w/wsherman/AD_Work/n_tuples/40MHZ_data/background_for_training.h5','r')\n",
    "Dataset=np.array(f[\"Particles\"])\n",
    "\n",
    "#for i, batch in enumerate(Dataset):\n",
    "#  pt_sum=0\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    if particle[3]!=0:\n",
    "#      pt_sum+=particle[0]\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    particle[0]=particle[0]/pt_sum\n",
    "    \n",
    "    \n",
    "Data_Train=Dataset[0:2000000,:,0:3]\n",
    "Data_Test=Dataset[2000001:3600000,:,0:3]\n",
    "Data_Validate=Dataset[3600001:4000000,:,0:3]\n",
    "\n",
    "Data_Train_Flat=np.reshape(Data_Train,(-1,57))\n",
    "Data_Val_Flat=np.reshape(Data_Validate,(-1,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def make_encoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(input_dim))\n",
    "    #x=layers.BatchNormalization()(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(inputs)\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(x)\n",
    "    z_mean=layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_logvar=layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z=Sampling()([z_mean,z_logvar])\n",
    "    encoder=keras.Model(inputs,[z_mean,z_logvar,z],name='encoder')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_decoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(latent_dim))\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(x)\n",
    "    z=layers.Dense(input_dim)(x)\n",
    "    decoder=keras.Model(inputs,z,name='decoder')\n",
    "    return decoder\n",
    "\n",
    "class VAE_Model(keras.Model):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta=1\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def set_beta(self,beta):\n",
    "        self.beta=beta\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            #making a masked loss function\n",
    "            mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "            reconstruction_loss *=(1-self.beta)\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *=self.beta\n",
    "\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reco_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        \n",
    "        reconstruction = self.decoder(z)\n",
    "        mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "        \n",
    "        reconstruction_loss*=(1-self.beta)\n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        \n",
    "        #KL loss changed abck to sum as in paper\n",
    "        kl_loss = tf.reduce_sum(kl_loss)\n",
    "        \n",
    "        kl_loss *=self.beta\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reco_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean,z_log_var,x = self.encoder(data)\n",
    "        reconstruction = self.decoder(x)\n",
    "        return {\n",
    "            \"z_mean\": z_mean,\n",
    "            \"z_log_var\": z_log_var,\n",
    "            \"reconstruction\": reconstruction\n",
    "        }\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18000/18000 [==============================] - 51s 3ms/step - loss: 113.0161 - reco_loss: 95.8629 - kl_loss: 7.2736 - val_loss: 833.1437 - val_reco_loss: 8.3764 - val_kl_loss: 824.7673 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 20.6478 - reco_loss: 17.5558 - kl_loss: 3.0718 - val_loss: 777.8638 - val_reco_loss: 7.7402 - val_kl_loss: 770.1237 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 17.8315 - reco_loss: 15.1073 - kl_loss: 2.7481 - val_loss: 736.0100 - val_reco_loss: 7.2232 - val_kl_loss: 728.7869 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "18000/18000 [==============================] - 45s 3ms/step - loss: 29.2283 - reco_loss: 14.4081 - kl_loss: 41.0303 - val_loss: 900.8517 - val_reco_loss: 6.1680 - val_kl_loss: 894.6838 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "18000/18000 [==============================] - 44s 2ms/step - loss: 16.1860 - reco_loss: 13.3615 - kl_loss: 2.7319 - val_loss: 765.0691 - val_reco_loss: 8.7536 - val_kl_loss: 756.3156 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "18000/18000 [==============================] - 45s 2ms/step - loss: 15.5894 - reco_loss: 12.9691 - kl_loss: 2.6802 - val_loss: 782.5789 - val_reco_loss: 17.1233 - val_kl_loss: 765.4556 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "17990/18000 [============================>.] - ETA: 0s - loss: 3635.3487 - reco_loss: 3631.9071 - kl_loss: 6.0250\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "18000/18000 [==============================] - 45s 3ms/step - loss: 3642.4517 - reco_loss: 3639.0083 - kl_loss: 6.0237 - val_loss: 889.3967 - val_reco_loss: 8.5651 - val_kl_loss: 880.8316 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 18.7510 - reco_loss: 15.6589 - kl_loss: 3.0212 - val_loss: 851.9071 - val_reco_loss: 6.5443 - val_kl_loss: 845.3629 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "18000/18000 [==============================] - 45s 3ms/step - loss: 15.9985 - reco_loss: 13.0361 - kl_loss: 2.9010 - val_loss: 777.4252 - val_reco_loss: 6.2961 - val_kl_loss: 771.1291 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "18000/18000 [==============================] - 45s 2ms/step - loss: 14.3155 - reco_loss: 11.5966 - kl_loss: 2.6864 - val_loss: 744.0055 - val_reco_loss: 6.1016 - val_kl_loss: 737.9039 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "17999/18000 [============================>.] - ETA: 0s - loss: 138.6128 - reco_loss: 129.1857 - kl_loss: 15.3654\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "18000/18000 [==============================] - 44s 2ms/step - loss: 138.6248 - reco_loss: 129.1971 - kl_loss: 15.3647 - val_loss: 745.1964 - val_reco_loss: 6.1077 - val_kl_loss: 739.0887 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#Here is a normalized model with (1-beta)rl beta*Kl loss\n",
    "beta=0.83\n",
    "vae_enc=make_encoder(57,32,16,3)\n",
    "vae_dec=make_decoder(57,32,16,3)\n",
    "vae_40MHZ=VAE_Model(vae_enc,vae_dec)\n",
    "vae_40MHZ.set_beta(beta)\n",
    "opt=keras.optimizers.Adam(learning_rate=0.001)\n",
    "vae_40MHZ.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "STOP_PATIENCE = 8\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "history = vae_40MHZ.fit(x=Data_Train_Flat, validation_split=0.1,epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks,shuffle=True)\n",
    "vae_40MHZ.save_weights(filepath='/eos/home-w/wsherman/AD_Work/ML_git_repo/AD_trigger_training/trained_models/Different_VAE_Models/non_normed_new_beta_{}_v4_no_batchnorm/'.format(beta),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93fb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[-1.8108056e+00, -6.8010747e-02, -1.1608523e+00],\n",
      "       [ 2.2932932e+00, -1.1156259e+00, -7.9223716e-01],\n",
      "       [ 1.1637506e+00,  1.0667250e+00, -3.4212172e-01],\n",
      "       [ 1.4196062e+00,  7.4135202e-01, -1.4708246e+00],\n",
      "       [ 1.0880392e+00, -5.0630510e-01,  2.4788332e-01],\n",
      "       [ 1.7308694e-01,  6.1555749e-01, -6.1812007e-01],\n",
      "       [-7.6606154e-02,  1.0604949e+00, -6.4806461e-02],\n",
      "       [-1.6179707e+00,  2.3087865e-01,  3.9841056e-02],\n",
      "       [-3.1769425e-01,  4.6532989e-02,  2.3227453e-01],\n",
      "       [-1.3215661e+00,  3.3368200e-01, -2.5617993e-01],\n",
      "       [ 3.1449717e-01,  1.0733414e-01, -8.4114802e-01],\n",
      "       [-1.3019562e-01,  3.4888810e-01, -1.2383441e+00],\n",
      "       [ 4.9400014e-01,  4.1662371e-01,  3.5039926e-01],\n",
      "       [-1.7167914e-01, -2.1303892e-01, -1.7050529e-01],\n",
      "       [ 6.6929072e-01, -4.9087915e-01, -1.1899825e+00],\n",
      "       [-1.7296348e+00,  1.3355010e+00,  1.4060739e+00],\n",
      "       [-1.5893346e-01, -9.1810483e-01,  7.5310469e-02],\n",
      "       [-4.1246235e-01,  5.3084654e-01, -2.0881014e+00],\n",
      "       [ 7.6775008e-01,  8.5867566e-01, -9.9147475e-01],\n",
      "       [ 3.8737422e-01, -9.6456242e-01, -7.9882371e-01],\n",
      "       [ 4.4861728e-01, -1.4184999e+00, -1.2266608e+00],\n",
      "       [-3.9293319e-01, -7.8129190e-01, -5.4848874e-01],\n",
      "       [ 8.2972211e-01,  9.7198564e-01,  1.5369964e-01],\n",
      "       [ 1.1925390e+00, -9.0981382e-01, -1.4971125e-01],\n",
      "       [ 4.9432844e-01, -2.2696510e-01, -2.3807378e+00],\n",
      "       [-2.6139212e-01,  2.7628350e-01,  8.3939075e-01],\n",
      "       [-1.1374059e+00, -4.7649622e-02,  2.4850810e-01],\n",
      "       [ 2.1311939e-02, -8.5755157e-01, -3.4261453e-01],\n",
      "       [ 8.2199818e-01, -3.1736714e-01,  7.6609111e-01],\n",
      "       [-7.3027837e-01, -1.0046688e+00, -4.3073177e-02],\n",
      "       [ 5.3554994e-01, -4.4392318e-02,  6.3528937e-01],\n",
      "       [ 1.4679673e+00,  9.7505158e-01, -3.2154906e-01],\n",
      "       [-6.0269833e-03,  3.1754154e-01, -7.4186242e-01],\n",
      "       [-4.4206917e-01, -9.5877528e-01, -3.9130032e-01],\n",
      "       [ 2.1760178e+00, -5.9651184e-01, -3.4938061e-01],\n",
      "       [-5.2639836e-01, -9.5528203e-01, -1.9380295e-01],\n",
      "       [-4.2424613e-01, -1.3029472e+00, -6.2030399e-01],\n",
      "       [ 8.7689251e-01,  7.6620877e-02, -1.8256021e-01],\n",
      "       [-2.3157909e+00,  1.0557282e+00, -1.3474025e+00],\n",
      "       [ 2.2893113e-01, -1.2129636e+00, -6.4540517e-01],\n",
      "       [-4.6185827e-01,  7.0340699e-01, -6.2568986e-01],\n",
      "       [ 2.1975706e+00,  1.0393262e+00,  3.5937476e-01],\n",
      "       [ 1.6025748e+00, -5.5694270e-01,  2.7720249e-01],\n",
      "       [-3.2248104e-01, -7.7263755e-01,  1.5206695e-01],\n",
      "       [-3.6171550e-01, -4.8371452e-01, -1.7744900e+00],\n",
      "       [ 2.1426277e+00, -5.4180062e-01, -2.1836948e-01],\n",
      "       [-6.6601753e-01,  3.4594935e-01,  8.4892440e-01],\n",
      "       [ 4.7927499e-03, -9.1904056e-01, -1.9241297e-01],\n",
      "       [ 1.6450077e-01,  1.1806412e+00,  3.8607442e-01],\n",
      "       [ 4.2006546e-01,  7.2224718e-01, -6.9308507e-01],\n",
      "       [-2.5758463e-01, -8.1527942e-01,  2.9504919e-01],\n",
      "       [-8.8910252e-01, -6.7391229e-01,  6.8371820e-01],\n",
      "       [-2.7549320e-01,  9.0312821e-01,  1.2899995e-01],\n",
      "       [-1.5820780e+00, -8.2851744e-01,  3.9072204e-01],\n",
      "       [-4.4389760e-01, -3.9166325e-01,  9.3048900e-01],\n",
      "       [ 1.3806658e+00,  5.8855969e-01, -2.9359627e-01],\n",
      "       [ 1.1294587e+00, -1.0859516e+00, -4.3090737e-01],\n",
      "       [-2.0349896e+00,  3.4623728e+00, -7.6584423e-01],\n",
      "       [-6.4440739e-01, -1.2808523e-01, -2.2891340e+00],\n",
      "       [-3.8512808e-01,  4.8579496e-01, -6.9827378e-01],\n",
      "       [-2.3106387e+00, -8.1552756e-01, -1.0404855e+00],\n",
      "       [-1.1601493e+00, -9.9318624e-02, -2.2210348e-01],\n",
      "       [-1.1311787e-01,  5.0973493e-01,  2.9926062e-02],\n",
      "       [-2.2502244e-02,  9.6749955e-01, -3.3760262e-01],\n",
      "       [ 2.8457659e-01, -1.6159945e+00, -1.5911027e+00],\n",
      "       [-4.6538103e-01, -4.7000146e-01, -3.1676817e-01],\n",
      "       [ 1.4690194e+00, -8.9938706e-01, -7.4692023e-01],\n",
      "       [-2.5651586e-01, -4.6384147e-01,  2.2863853e-01],\n",
      "       [ 4.1733818e+00,  7.3829546e+00, -1.4611876e-01],\n",
      "       [-4.6789521e-01,  9.4886667e-01,  9.1927797e-01],\n",
      "       [ 3.4621670e+00,  7.6055306e-01, -2.4357839e+00],\n",
      "       [-1.2014103e+00, -1.0131204e+00, -1.6931988e+00],\n",
      "       [-7.1198666e-01, -5.5128598e-01,  8.3557129e-01],\n",
      "       [-2.9126364e-01,  5.8233857e-02,  4.0078902e-01],\n",
      "       [ 1.0953591e+00,  8.0930430e-01, -2.1981406e-01],\n",
      "       [ 2.2803178e+00,  1.2843511e+00, -1.9712579e-01],\n",
      "       [-2.6735198e-01,  7.8365022e-01,  1.4940643e-01],\n",
      "       [ 1.2812614e-03, -6.1009222e-01, -1.4730918e-01],\n",
      "       [-4.6273065e-01,  1.3477030e+00,  6.3354826e-01],\n",
      "       [-8.9422721e-01,  6.8400210e-01,  3.1743765e-02],\n",
      "       [-1.2701572e+00,  2.2759690e+00, -1.4823484e-01],\n",
      "       [-3.5654229e-01, -6.0808849e-01,  7.7106917e-01],\n",
      "       [-1.5057826e-01,  9.7443575e-01,  2.2093809e-01],\n",
      "       [ 5.3708082e-01,  9.4806343e-01, -4.0551198e-01],\n",
      "       [ 1.9845372e-01, -1.4252355e+00, -1.7223989e+00],\n",
      "       [ 7.6091272e-01, -1.9813555e-01,  6.6591382e-02],\n",
      "       [-2.6154888e-01, -3.5171562e-01,  8.3550936e-01],\n",
      "       [-4.8598915e-01, -8.3816957e-01,  2.8481221e-01],\n",
      "       [-1.1392431e+00, -7.5857639e-01,  5.8267629e-01],\n",
      "       [-1.1750227e-01,  1.4491051e-01,  5.5470347e-01],\n",
      "       [-5.1318645e-02,  2.6261938e-01, -9.0840638e-01],\n",
      "       [-1.1418458e+00, -2.1872339e-01, -1.2535015e+00],\n",
      "       [ 2.9873604e-01,  8.0036217e-01, -3.1407082e-01],\n",
      "       [ 5.9818178e-01,  6.6848344e-01, -3.5815024e-01],\n",
      "       [ 1.0032887e+00, -9.5171189e-01, -1.6463912e-01],\n",
      "       [ 2.4363917e-01, -4.5538861e-01,  4.8823655e-01],\n",
      "       [ 1.6355319e+00, -2.3698145e-01,  1.9508123e-02],\n",
      "       [-1.6419502e+00, -1.0873263e+00,  2.3034799e-01],\n",
      "       [-1.5189826e+00,  2.7810073e-01,  5.0722265e-01],\n",
      "       [-1.1542237e+00, -2.4159867e-01, -1.8700882e+00]], dtype=float32)>, <tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[ -7.1876106,  -6.4744954,  -6.794773 ],\n",
      "       [ -6.243283 ,  -2.2120934,  -6.2528462],\n",
      "       [ -8.067896 ,  -6.0851665,  -6.6749845],\n",
      "       [ -8.515099 ,  -6.4382977,  -6.7240143],\n",
      "       [ -6.1130543,  -2.622369 ,  -6.246794 ],\n",
      "       [ -6.6702967,  -2.1209583,  -5.992128 ],\n",
      "       [ -6.5235677,  -2.2354662,  -6.010729 ],\n",
      "       [ -5.5830336,  -5.4875917,  -6.5938497],\n",
      "       [ -7.3333893,  -5.544456 ,  -6.6432233],\n",
      "       [ -6.3342605,  -2.3837655,  -5.8454537],\n",
      "       [ -6.675544 ,  -2.18274  ,  -6.0131516],\n",
      "       [ -6.865318 ,  -2.5725093,  -6.0676622],\n",
      "       [ -7.289471 ,  -6.261315 ,  -6.729648 ],\n",
      "       [ -6.1442957,  -6.0606384,  -6.6797075],\n",
      "       [ -7.7377295,  -6.8376822,  -6.8247237],\n",
      "       [ -5.6458497,  -5.5556912,  -6.5393434],\n",
      "       [ -6.2815876,  -2.9711514,  -6.2507977],\n",
      "       [ -7.5169277,  -6.5895205,  -6.749563 ],\n",
      "       [ -6.9356794,  -1.9801126,  -5.9423   ],\n",
      "       [ -5.6919174,  -6.532658 ,  -6.734439 ],\n",
      "       [ -6.5450983,  -2.6633577,  -6.204905 ],\n",
      "       [ -6.3574934,  -6.409085 ,  -6.757366 ],\n",
      "       [ -6.454092 ,  -2.6062038,  -6.1206145],\n",
      "       [ -6.2555   ,  -2.2807639,  -6.2002053],\n",
      "       [ -9.023344 ,  -6.5192146,  -6.7850947],\n",
      "       [ -6.0658274,  -5.4518747,  -6.5901237],\n",
      "       [ -5.491994 ,  -5.8048906,  -6.644101 ],\n",
      "       [ -6.323124 ,  -2.577982 ,  -6.143116 ],\n",
      "       [ -5.9947677,  -2.7753882,  -6.271549 ],\n",
      "       [ -6.3754625,  -3.1107879,  -6.2486243],\n",
      "       [ -6.128802 ,  -2.8051417,  -6.226954 ],\n",
      "       [ -8.483401 ,  -6.64688  ,  -6.7766232],\n",
      "       [ -6.5766935,  -2.2027762,  -6.013751 ],\n",
      "       [ -6.25316  ,  -2.5635476,  -6.13612  ],\n",
      "       [ -6.5133047,  -6.353488 ,  -6.8157625],\n",
      "       [ -6.287763 ,  -2.58602  ,  -6.1495476],\n",
      "       [ -6.3328094,  -2.5133255,  -6.137105 ],\n",
      "       [ -6.8751535,  -6.3447957,  -6.7166424],\n",
      "       [ -9.49854  ,  -6.001178 ,  -6.77232  ],\n",
      "       [ -6.42466  ,  -2.7780533,  -6.226167 ],\n",
      "       [ -6.440687 ,  -2.0929594,  -5.9660945],\n",
      "       [ -8.502546 ,  -6.708949 ,  -6.784296 ],\n",
      "       [ -6.1677446,  -2.3625207,  -6.246576 ],\n",
      "       [ -6.2877913,  -2.739431 ,  -6.1744647],\n",
      "       [ -9.02647  ,  -6.6974163,  -6.8578696],\n",
      "       [ -6.3388095,  -6.2972527,  -6.7987247],\n",
      "       [ -6.264296 ,  -3.14326  ,  -6.1599064],\n",
      "       [ -6.244329 ,  -2.5648522,  -6.1649466],\n",
      "       [ -6.5728736,  -2.4251966,  -6.047406 ],\n",
      "       [ -6.734167 ,  -2.1166303,  -5.9809146],\n",
      "       [ -6.162645 ,  -2.8041856,  -6.2059836],\n",
      "       [ -6.179989 ,  -3.3084228,  -6.2767153],\n",
      "       [ -6.522408 ,  -2.7518506,  -6.1101913],\n",
      "       [ -6.3280935,  -3.1695714,  -6.12475  ],\n",
      "       [ -6.0891056,  -3.0253098,  -6.246218 ],\n",
      "       [ -6.446275 ,  -2.4380736,  -6.1360197],\n",
      "       [ -6.2304544,  -2.5646195,  -6.2485313],\n",
      "       [ -9.072611 ,  -7.644658 ,  -6.957272 ],\n",
      "       [ -8.375587 ,  -7.4263935,  -6.9365654],\n",
      "       [ -6.395382 ,  -2.0953012,  -5.9936094],\n",
      "       [ -6.0772133,  -6.3931117,  -6.7807603],\n",
      "       [ -6.4226165,  -6.272804 ,  -6.743306 ],\n",
      "       [ -6.5748034,  -2.8031821,  -6.129963 ],\n",
      "       [ -6.536623 ,  -2.1708841,  -5.993864 ],\n",
      "       [ -5.626287 ,  -6.5431237,  -6.7369366],\n",
      "       [ -6.522116 ,  -6.2424297,  -6.733987 ],\n",
      "       [ -6.33675  ,  -6.841814 ,  -6.783272 ],\n",
      "       [ -6.363451 ,  -2.685856 ,  -6.155728 ],\n",
      "       [-18.42313  , -12.277059 ,  -7.7801733],\n",
      "       [ -6.3399134,  -3.0766902,  -6.118612 ],\n",
      "       [-11.163341 ,  -7.2262564,  -6.870685 ],\n",
      "       [ -5.367051 ,  -6.2509227,  -6.695649 ],\n",
      "       [ -6.1323485,  -3.0437727,  -6.2066765],\n",
      "       [ -5.870512 ,  -5.595417 ,  -6.6032133],\n",
      "       [ -6.745199 ,  -2.116963 ,  -6.0351024],\n",
      "       [ -6.4642744,  -2.1744652,  -6.109357 ],\n",
      "       [ -6.466231 ,  -2.4078398,  -6.0349817],\n",
      "       [ -6.371133 ,  -2.5620484,  -6.139195 ],\n",
      "       [ -6.4528613,  -2.6101916,  -5.9450274],\n",
      "       [ -6.4490337,  -2.8509288,  -6.069352 ],\n",
      "       [ -8.328621 ,  -6.780781 ,  -6.8240137],\n",
      "       [ -5.934138 ,  -3.0630965,  -6.269228 ],\n",
      "       [ -6.4660172,  -2.415662 ,  -6.037919 ],\n",
      "       [ -6.806559 ,  -2.1716046,  -5.989801 ],\n",
      "       [ -6.6115103,  -2.1816561,  -6.0478272],\n",
      "       [ -6.956167 ,  -5.616039 ,  -6.618677 ],\n",
      "       [ -6.1129565,  -3.1284018,  -6.2639256],\n",
      "       [ -6.286978 ,  -3.1058571,  -6.256789 ],\n",
      "       [ -6.1592712,  -3.0083008,  -6.120938 ],\n",
      "       [ -6.35613  ,  -2.6802793,  -6.1453376],\n",
      "       [ -6.8119516,  -2.672885 ,  -6.094759 ],\n",
      "       [ -7.9802833,  -6.5832157,  -6.826287 ],\n",
      "       [ -6.7109485,  -2.2156012,  -6.0079284],\n",
      "       [ -6.581238 ,  -2.6346042,  -6.10806  ],\n",
      "       [ -6.1591306,  -2.6364217,  -6.2590537],\n",
      "       [ -6.156042 ,  -2.8996887,  -6.2490654],\n",
      "       [ -6.737915 ,  -6.305499 ,  -6.761972 ],\n",
      "       [ -6.28345  ,  -3.2493706,  -6.182824 ],\n",
      "       [ -6.5090027,  -2.8309488,  -5.849694 ],\n",
      "       [ -7.907851 ,  -6.7924633,  -6.8435354]], dtype=float32)>, <tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[-1.78038633e+00, -1.16516426e-01, -1.16998839e+00],\n",
      "       [ 2.34740424e+00, -3.95756841e-01, -7.76704192e-01],\n",
      "       [ 1.18085957e+00,  1.04022753e+00, -3.42329741e-01],\n",
      "       [ 1.43057609e+00,  7.59988844e-01, -1.48954988e+00],\n",
      "       [ 9.75660145e-01, -3.14378679e-01,  3.09955060e-01],\n",
      "       [ 1.56381071e-01,  5.65888047e-01, -6.04855955e-01],\n",
      "       [-6.05539978e-03,  1.28432095e+00, -6.58203661e-02],\n",
      "       [-1.64734912e+00,  1.91255182e-01,  2.57377028e-02],\n",
      "       [-3.26278180e-01, -4.95308563e-02,  2.38054693e-01],\n",
      "       [-1.37205696e+00,  6.29530072e-01, -3.38984877e-01],\n",
      "       [ 3.23457122e-01,  3.49295318e-01, -7.96546817e-01],\n",
      "       [-1.41903877e-01,  6.33179665e-01, -1.27133107e+00],\n",
      "       [ 4.75295216e-01,  4.51646686e-01,  2.93902338e-01],\n",
      "       [-1.26192987e-01, -1.58331513e-01, -2.39967868e-01],\n",
      "       [ 6.85765266e-01, -4.71667022e-01, -1.17241549e+00],\n",
      "       [-1.82243669e+00,  1.39120162e+00,  1.38148403e+00],\n",
      "       [-1.84358239e-01, -8.38752568e-01,  3.83479781e-02],\n",
      "       [-4.15594429e-01,  5.58152795e-01, -2.07228255e+00],\n",
      "       [ 7.57210016e-01,  1.17305636e+00, -1.02066135e+00],\n",
      "       [ 3.43457222e-01, -9.96434569e-01, -8.35251272e-01],\n",
      "       [ 5.21115780e-01, -1.26468039e+00, -1.15484667e+00],\n",
      "       [-3.96467924e-01, -7.62543678e-01, -5.17229736e-01],\n",
      "       [ 8.53821278e-01,  1.02147365e+00,  2.42839038e-01],\n",
      "       [ 1.22003949e+00, -4.54858005e-01, -7.29172751e-02],\n",
      "       [ 4.99940127e-01, -1.48926884e-01, -2.34992027e+00],\n",
      "       [-2.08055258e-01,  3.48219752e-01,  7.82364428e-01],\n",
      "       [-1.06846714e+00, -9.72217172e-02,  1.91919640e-01],\n",
      "       [ 9.16903168e-02, -6.58880353e-01, -2.80692875e-01],\n",
      "       [ 8.18923652e-01, -2.96397954e-01,  7.99768269e-01],\n",
      "       [-7.54080951e-01, -6.87833309e-01, -1.62004232e-02],\n",
      "       [ 4.77780163e-01, -5.82833290e-01,  6.34843767e-01],\n",
      "       [ 1.48137033e+00,  9.77983832e-01, -2.86243439e-01],\n",
      "       [-3.22842598e-02,  4.58447635e-02, -7.90211439e-01],\n",
      "       [-4.12826538e-01, -7.43243456e-01, -4.22179699e-01],\n",
      "       [ 2.14733672e+00, -6.00119054e-01, -3.18741739e-01],\n",
      "       [-5.04606962e-01, -9.47422624e-01, -1.95417523e-01],\n",
      "       [-4.03389335e-01, -1.16581559e+00, -6.57604218e-01],\n",
      "       [ 8.66410673e-01,  1.06979892e-01, -1.54294401e-01],\n",
      "       [-2.30553389e+00,  9.30008292e-01, -1.31634283e+00],\n",
      "       [ 2.26833448e-01, -1.27863932e+00, -6.35268807e-01],\n",
      "       [-5.02008557e-01,  1.05914986e+00, -6.39854908e-01],\n",
      "       [ 2.18510103e+00,  1.04849660e+00,  4.06152308e-01],\n",
      "       [ 1.62806296e+00,  1.47361338e-01,  2.66601950e-01],\n",
      "       [-3.15867543e-01, -8.95421743e-01,  1.71557814e-01],\n",
      "       [-3.45056444e-01, -4.74848449e-01, -1.79911077e+00],\n",
      "       [ 2.15128040e+00, -4.53752339e-01, -2.44055092e-01],\n",
      "       [-7.05766857e-01,  1.94420919e-01,  8.44606102e-01],\n",
      "       [-2.46370211e-02, -4.61463392e-01, -2.72642255e-01],\n",
      "       [ 1.62862986e-01,  1.51827836e+00,  3.63602072e-01],\n",
      "       [ 4.45283055e-01,  1.23377204e-01, -6.90698564e-01],\n",
      "       [-1.92159325e-01, -6.70793116e-01,  3.56590480e-01],\n",
      "       [-8.36107016e-01, -6.31716728e-01,  6.56169653e-01],\n",
      "       [-2.75764793e-01,  1.26198387e+00,  1.62311107e-01],\n",
      "       [-1.57319951e+00, -1.01380622e+00,  3.42916220e-01],\n",
      "       [-4.23440725e-01, -7.02590108e-01,  8.94141912e-01],\n",
      "       [ 1.37641621e+00,  6.95365310e-01, -3.08043480e-01],\n",
      "       [ 1.08347952e+00, -1.36550963e+00, -3.79509151e-01],\n",
      "       [-2.05681443e+00,  3.47317982e+00, -7.63001144e-01],\n",
      "       [-6.54608250e-01, -1.34967461e-01, -2.26634336e+00],\n",
      "       [-4.39344347e-01,  1.33794308e-01, -7.03786850e-01],\n",
      "       [-2.29329586e+00, -8.63323867e-01, -1.05976129e+00],\n",
      "       [-1.14746404e+00, -4.04138118e-02, -2.44427636e-01],\n",
      "       [-1.57813445e-01,  4.33132559e-01,  9.80714634e-02],\n",
      "       [ 2.15771683e-02,  1.19259799e+00, -2.36045778e-01],\n",
      "       [ 2.24933952e-01, -1.63700044e+00, -1.60917437e+00],\n",
      "       [-4.51627523e-01, -4.76733029e-01, -3.46486926e-01],\n",
      "       [ 1.45025647e+00, -8.94530952e-01, -7.80470431e-01],\n",
      "       [-3.17254633e-01, -4.48025286e-01,  2.35602558e-01],\n",
      "       [ 4.17348194e+00,  7.38456869e+00, -1.90981582e-01],\n",
      "       [-4.19502020e-01,  1.19573474e+00,  9.36539948e-01],\n",
      "       [ 3.46075225e+00,  7.10224628e-01, -2.46051383e+00],\n",
      "       [-1.23512626e+00, -1.00438488e+00, -1.67266512e+00],\n",
      "       [-6.87798202e-01, -1.36676848e-01,  7.96833158e-01],\n",
      "       [-3.20762128e-01,  7.25509375e-02,  4.03434306e-01],\n",
      "       [ 1.08156788e+00,  6.71875238e-01, -1.73848107e-01],\n",
      "       [ 2.30983758e+00,  1.34841835e+00, -2.61245608e-01],\n",
      "       [-3.05433840e-01,  8.77578735e-01,  1.60016969e-01],\n",
      "       [ 5.89015372e-02, -3.83817375e-01, -1.29536316e-01],\n",
      "       [-4.89355236e-01,  1.54716313e+00,  5.79890072e-01],\n",
      "       [-9.44099963e-01,  6.09066606e-01,  2.25997716e-02],\n",
      "       [-1.26723850e+00,  2.29423761e+00, -1.69755295e-01],\n",
      "       [-3.78607601e-01, -7.15839148e-01,  7.66449571e-01],\n",
      "       [-1.37617350e-01,  9.20737624e-01,  2.63665915e-01],\n",
      "       [ 5.69397628e-01,  1.14809525e+00, -3.49872172e-01],\n",
      "       [ 2.33700514e-01, -8.49296749e-01, -1.78104961e+00],\n",
      "       [ 7.89978385e-01, -2.05798164e-01,  2.85493881e-02],\n",
      "       [-2.26947159e-01, -3.61659259e-01,  8.49627256e-01],\n",
      "       [-4.58804637e-01, -5.84416568e-01,  2.65632570e-01],\n",
      "       [-1.08766305e+00, -8.22285235e-01,  6.89536631e-01],\n",
      "       [-1.59869716e-01, -1.13999069e-01,  5.78181982e-01],\n",
      "       [-2.38730982e-02,  5.92591017e-02, -9.03889239e-01],\n",
      "       [-1.15151513e+00, -2.75735289e-01, -1.24863911e+00],\n",
      "       [ 3.67736220e-01,  1.29331362e+00, -3.65054190e-01],\n",
      "       [ 5.69141030e-01,  1.14155090e+00, -3.31756353e-01],\n",
      "       [ 1.07641888e+00, -5.73805332e-01, -1.17917106e-01],\n",
      "       [ 2.69310296e-01, -3.30349207e-02,  5.63450456e-01],\n",
      "       [ 1.69955623e+00, -1.88748628e-01,  3.13134715e-02],\n",
      "       [-1.63614333e+00, -1.25166833e+00,  2.27887258e-01],\n",
      "       [-1.53998256e+00,  4.53762472e-01,  5.29185832e-01],\n",
      "       [-1.16300845e+00, -3.03590059e-01, -1.88721824e+00]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "a=Data_Train_Flat[0:100]\n",
    "b=vae_40MHZ.encoder(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67750e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
