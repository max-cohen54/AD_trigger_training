{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c66c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfmath\n",
    "import tensorflow.keras as keras\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20999b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=h5py.File('/eos/home-w/wsherman/AD_Work/n_tuples/40MHZ_data/background_for_training.h5','r')\n",
    "Dataset=np.array(f[\"Particles\"])\n",
    "\n",
    "#for i, batch in enumerate(Dataset):\n",
    "#  pt_sum=0\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    if particle[3]!=0:\n",
    "#      pt_sum+=particle[0]\n",
    "#  for j, particle in enumerate(Dataset[i,:,:]):\n",
    "#    particle[0]=particle[0]/pt_sum\n",
    "    \n",
    "    \n",
    "Data_Train=Dataset[0:2000000,:,0:3]\n",
    "Data_Test=Dataset[2000001:3600000,:,0:3]\n",
    "Data_Validate=Dataset[3600001:4000000,:,0:3]\n",
    "\n",
    "Data_Train_Flat=np.reshape(Data_Train,(-1,57))\n",
    "Data_Val_Flat=np.reshape(Data_Validate,(-1,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "591db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def make_encoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(input_dim))\n",
    "    x=layers.BatchNormalization()(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(x)\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(x)\n",
    "    z_mean=layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_logvar=layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z=Sampling()([z_mean,z_logvar])\n",
    "    encoder=keras.Model(inputs,[z_mean,z_logvar,z],name='encoder')\n",
    "    return encoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_decoder(input_dim,h_dim_1,h_dim_2,latent_dim):\n",
    "    inputs=keras.Input(shape=(latent_dim))\n",
    "    x=layers.Dense(h_dim_2, activation='relu')(inputs)\n",
    "    x=layers.Dense(h_dim_1, activation='relu')(x)\n",
    "    z=layers.Dense(input_dim)(x)\n",
    "    decoder=keras.Model(inputs,z,name='decoder')\n",
    "    return decoder\n",
    "\n",
    "class VAE_Model(keras.Model):\n",
    "    def __init__(self,encoder,decoder,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.beta=1\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def set_beta(self,beta):\n",
    "        self.beta=beta\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            #making a masked loss function\n",
    "            mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "            reconstruction_loss *=(1-self.beta)\n",
    "\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *=self.beta\n",
    "\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reco_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        \n",
    "        reconstruction = self.decoder(z)\n",
    "        mask = K.cast(K.not_equal(data, 0), K.floatx())\n",
    "        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(mask*data, mask*reconstruction)))\n",
    "        \n",
    "        reconstruction_loss*=(1-self.beta)\n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        \n",
    "        #KL loss changed abck to sum as in paper\n",
    "        kl_loss = tf.reduce_sum(kl_loss)\n",
    "        \n",
    "        kl_loss *=self.beta\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reco_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        z_mean,z_log_var,x = self.encoder(data)\n",
    "        reconstruction = self.decoder(x)\n",
    "        return {\n",
    "            \"z_mean\": z_mean,\n",
    "            \"z_log_var\": z_log_var,\n",
    "            \"reconstruction\": reconstruction\n",
    "        }\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74f8c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18000/18000 [==============================] - 49s 3ms/step - loss: 23252.5475 - reco_loss: 3630.5920 - kl_loss: 3382.8665 - val_loss: 945.9092 - val_reco_loss: 8.8327 - val_kl_loss: 937.0765 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 18.6809 - reco_loss: 15.6131 - kl_loss: 2.9534 - val_loss: 835.1618 - val_reco_loss: 9.5596 - val_kl_loss: 825.6022 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 16.6117 - reco_loss: 13.8992 - kl_loss: 2.6592 - val_loss: 773.0566 - val_reco_loss: 7.1584 - val_kl_loss: 765.8982 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 902409.0312 - reco_loss: 884351.8028 - kl_loss: 13007.3604 - val_loss: 784.4340 - val_reco_loss: 6.7893 - val_kl_loss: 777.6447 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 15.1461 - reco_loss: 12.5065 - kl_loss: 2.6226 - val_loss: 765.1358 - val_reco_loss: 7.2495 - val_kl_loss: 757.8863 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 14.4556 - reco_loss: 11.8804 - kl_loss: 2.5861 - val_loss: 768.3727 - val_reco_loss: 7.0844 - val_kl_loss: 761.2884 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 14.8586 - reco_loss: 12.2349 - kl_loss: 2.6385 - val_loss: 765.5270 - val_reco_loss: 6.8242 - val_kl_loss: 758.7029 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "18000/18000 [==============================] - 48s 3ms/step - loss: 14.7671 - reco_loss: 12.0691 - kl_loss: 2.7129 - val_loss: 773.8718 - val_reco_loss: 6.2805 - val_kl_loss: 767.5914 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "17993/18000 [============================>.] - ETA: 0s - loss: 20.3338 - reco_loss: 17.7187 - kl_loss: 2.6173\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 20.3338 - reco_loss: 17.7187 - kl_loss: 2.6173 - val_loss: 773.7220 - val_reco_loss: 8.3857 - val_kl_loss: 765.3363 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 13.1125 - reco_loss: 10.5393 - kl_loss: 2.5563 - val_loss: 756.7805 - val_reco_loss: 6.7547 - val_kl_loss: 750.0258 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.8543 - reco_loss: 10.3148 - kl_loss: 2.5410 - val_loss: 755.8820 - val_reco_loss: 6.2223 - val_kl_loss: 749.6597 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.7819 - reco_loss: 10.2411 - kl_loss: 2.5413 - val_loss: 762.2479 - val_reco_loss: 6.9434 - val_kl_loss: 755.3045 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "18000/18000 [==============================] - 48s 3ms/step - loss: 12.6137 - reco_loss: 10.0676 - kl_loss: 2.5411 - val_loss: 756.3947 - val_reco_loss: 6.9740 - val_kl_loss: 749.4207 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.6026 - reco_loss: 10.0532 - kl_loss: 2.5446 - val_loss: 756.8123 - val_reco_loss: 6.6660 - val_kl_loss: 750.1463 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "17998/18000 [============================>.] - ETA: 0s - loss: 12.5077 - reco_loss: 9.9695 - kl_loss: 2.5404\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.5077 - reco_loss: 9.9695 - kl_loss: 2.5404 - val_loss: 757.6762 - val_reco_loss: 6.4164 - val_kl_loss: 751.2598 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.4057 - reco_loss: 9.8698 - kl_loss: 2.5389 - val_loss: 758.4221 - val_reco_loss: 6.3373 - val_kl_loss: 752.0848 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "18000/18000 [==============================] - 47s 3ms/step - loss: 12.5142 - reco_loss: 9.9732 - kl_loss: 2.5395 - val_loss: 758.3187 - val_reco_loss: 6.2950 - val_kl_loss: 752.0237 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "18000/18000 [==============================] - 47s 3ms/step - loss: 12.3634 - reco_loss: 9.8264 - kl_loss: 2.5380 - val_loss: 760.6530 - val_reco_loss: 6.4101 - val_kl_loss: 754.2429 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "17997/18000 [============================>.] - ETA: 0s - loss: 12.5525 - reco_loss: 10.0129 - kl_loss: 2.5371\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "18000/18000 [==============================] - 46s 3ms/step - loss: 12.5524 - reco_loss: 10.0129 - kl_loss: 2.5372 - val_loss: 759.0984 - val_reco_loss: 6.3034 - val_kl_loss: 752.7951 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "#Here is a normalized model with (1-beta)rl beta*Kl loss\n",
    "beta=0.83\n",
    "vae_enc=make_encoder(57,32,16,3)\n",
    "vae_dec=make_decoder(57,32,16,3)\n",
    "vae_40MHZ=VAE_Model(vae_enc,vae_dec)\n",
    "vae_40MHZ.set_beta(beta)\n",
    "opt=keras.optimizers.Adam(learning_rate=0.001)\n",
    "vae_40MHZ.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "STOP_PATIENCE = 8\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "history = vae_40MHZ.fit(x=Data_Train_Flat, validation_split=0.1,epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks,shuffle=True)\n",
    "vae_40MHZ.save_weights(filepath='/eos/home-w/wsherman/AD_Work/ML_git_repo/AD_trigger_training/trained_models/Different_VAE_Models/non_normed_new_beta_{}_v4/'.format(beta),save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93fb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[ 4.31914687e-01, -7.97375023e-01, -1.51638985e+00],\n",
      "       [-1.65254939e+00, -1.82340443e-01,  1.42557144e+00],\n",
      "       [-6.27630830e-01, -5.48396647e-01,  8.90338361e-01],\n",
      "       [-1.69247043e+00, -7.02982962e-01,  7.27045834e-01],\n",
      "       [-1.67967439e-01, -3.08691561e-01,  8.30240071e-01],\n",
      "       [-4.05854821e-01,  1.08418977e+00, -9.63941216e-02],\n",
      "       [ 2.00008392e-01,  9.25589085e-01, -8.74878466e-02],\n",
      "       [ 1.10806060e+00, -5.09554207e-01, -1.22455978e+00],\n",
      "       [ 6.52772069e-01,  5.26440144e-02, -1.17008656e-01],\n",
      "       [ 5.90600610e-01,  6.62524879e-01, -1.17901170e+00],\n",
      "       [-6.69216275e-01,  1.05173016e+00, -7.16586113e-02],\n",
      "       [-6.34898067e-01,  8.49854052e-01, -3.81673247e-01],\n",
      "       [ 2.08062768e-01,  1.09507322e-01,  4.67751801e-01],\n",
      "       [ 1.45472765e-01,  1.83409870e-01, -2.23564684e-01],\n",
      "       [-9.93127465e-01,  2.10957587e-01,  2.44213760e-01],\n",
      "       [ 1.98210907e+00, -4.35363352e-01, -7.59065151e-01],\n",
      "       [ 3.70224357e-01, -8.18152130e-01, -1.29424632e-01],\n",
      "       [-1.31790507e+00, -1.28834915e+00, -9.35806036e-01],\n",
      "       [-1.02493727e+00,  1.27377141e+00,  2.50383854e-01],\n",
      "       [-6.80482507e-01,  6.76654100e-01, -3.32360268e-02],\n",
      "       [-9.76324916e-01, -2.15560138e-01, -2.81418562e-02],\n",
      "       [ 2.89208889e-02,  3.88618559e-01, -4.28310484e-01],\n",
      "       [-8.05087090e-02,  1.30029130e+00,  6.83767259e-01],\n",
      "       [-5.02764821e-01, -4.30275381e-01,  8.34610760e-01],\n",
      "       [-2.00776434e+00, -4.85471070e-01, -3.62428129e-01],\n",
      "       [ 1.10144114e+00,  1.43073380e-01,  9.98462439e-02],\n",
      "       [ 9.89853084e-01, -3.12252641e-02, -8.33154976e-01],\n",
      "       [-9.46455002e-02, -2.75756896e-01, -1.25025749e-01],\n",
      "       [ 3.79368305e-01, -5.15814245e-01,  7.71934211e-01],\n",
      "       [ 5.94271898e-01, -5.54930151e-01, -5.71175456e-01],\n",
      "       [ 4.27362680e-01, -3.65875900e-01,  5.41150153e-01],\n",
      "       [-8.14042211e-01, -3.25049460e-01,  1.06459212e+00],\n",
      "       [-4.18293118e-01,  1.08656216e+00, -2.93600768e-01],\n",
      "       [ 8.50056410e-02, -3.68411243e-01, -5.32439530e-01],\n",
      "       [-1.23496521e+00,  1.03664625e+00,  1.50913382e+00],\n",
      "       [ 2.89320469e-01, -6.11005843e-01, -5.30493915e-01],\n",
      "       [-1.31696820e-01, -7.82257974e-01, -6.05446577e-01],\n",
      "       [-3.98244023e-01,  2.59082317e-01,  6.27021730e-01],\n",
      "       [ 7.67380238e-01, -2.05105782e+00, -1.73588014e+00],\n",
      "       [-4.04209018e-01, -6.95899427e-01, -3.59727144e-02],\n",
      "       [-1.02969885e-01,  7.04824030e-01, -6.16856456e-01],\n",
      "       [-7.61597991e-01,  1.38950288e-01,  1.72987223e+00],\n",
      "       [-3.39514375e-01, -3.12583745e-01,  1.32965517e+00],\n",
      "       [ 4.93420362e-01, -5.29139459e-01, -2.25804746e-01],\n",
      "       [-9.08091187e-01, -3.29055727e-01, -6.62056863e-01],\n",
      "       [-1.11933267e+00,  1.03386235e+00,  1.51770687e+00],\n",
      "       [ 1.22737980e+00,  2.04396069e-01, -2.48930365e-01],\n",
      "       [ 4.38002348e-02, -6.60263717e-01, -9.46078598e-02],\n",
      "       [ 4.71632838e-01,  1.06024063e+00,  2.58739591e-01],\n",
      "       [-5.87677836e-01,  1.34689999e+00,  7.53568411e-02],\n",
      "       [ 5.92027187e-01, -7.42876112e-01, -1.24969274e-01],\n",
      "       [ 1.23277318e+00, -1.03485680e+00, -4.74479556e-01],\n",
      "       [ 5.03914595e-01,  7.41404235e-01, -1.43013328e-01],\n",
      "       [ 1.37498224e+00, -8.35622847e-01, -1.02304161e+00],\n",
      "       [ 1.25424099e+00, -9.03013527e-01, -1.69175267e-02],\n",
      "       [-7.22257972e-01,  1.08401775e+00,  9.61055100e-01],\n",
      "       [-7.20276237e-01, -4.08103168e-01,  6.72830045e-01],\n",
      "       [ 3.61165762e-01, -2.59697151e+00, -1.39235342e+00],\n",
      "       [-1.09574401e+00, -8.64717185e-01, -9.30642605e-01],\n",
      "       [-1.88924193e-01,  1.06138408e+00, -5.67543089e-01],\n",
      "       [ 7.84157872e-01, -2.80082881e-01, -1.92430353e+00],\n",
      "       [ 7.31106162e-01, -2.05714762e-01, -8.58973384e-01],\n",
      "       [ 3.25698733e-01,  7.67739058e-01, -6.61842823e-02],\n",
      "       [-5.89120388e-02,  9.94847476e-01, -1.44344360e-01],\n",
      "       [-1.27855217e+00,  7.86595583e-01, -3.88827085e-01],\n",
      "       [ 2.64895558e-01,  2.25939751e-01, -4.08941984e-01],\n",
      "       [-1.20393002e+00,  1.01301336e+00,  8.66320074e-01],\n",
      "       [ 5.26054025e-01, -2.88864434e-01, -1.50491208e-01],\n",
      "       [-1.84631121e+00, -3.99007320e+00,  5.20364857e+00],\n",
      "       [ 1.17957187e+00,  2.21617639e-01, -7.72380829e-02],\n",
      "       [-6.38340354e-01, -1.55414820e+00,  5.04050207e+00],\n",
      "       [-5.81907868e-01, -1.44784033e-01, -1.53589320e+00],\n",
      "       [ 1.27498031e+00, -1.11794114e+00, -2.60141641e-01],\n",
      "       [ 7.50977993e-01,  1.17119133e-01, -6.63391352e-02],\n",
      "       [-5.13260007e-01,  8.35337281e-01,  7.85056174e-01],\n",
      "       [-1.12522137e+00,  1.35460567e+00,  1.69557142e+00],\n",
      "       [ 4.64339852e-01,  5.97620487e-01, -1.88660949e-01],\n",
      "       [ 8.09669495e-02, -2.61844814e-01, -7.28858709e-02],\n",
      "       [ 9.27025557e-01,  6.59941435e-01, -1.49343073e-01],\n",
      "       [ 7.63017297e-01,  8.90185714e-01, -6.19184971e-01],\n",
      "       [ 5.86008787e-01, -1.58859825e+00, -8.08618069e-01],\n",
      "       [ 1.08096385e+00, -1.15608263e+00, -6.05034828e-03],\n",
      "       [ 4.79433537e-01,  9.18897450e-01, -6.84508085e-02],\n",
      "       [-4.03444409e-01,  1.17609262e+00,  2.72963464e-01],\n",
      "       [-1.38855088e+00, -1.59826100e-01, -4.92034554e-01],\n",
      "       [-5.00508547e-02,  4.84334737e-01,  6.32130563e-01],\n",
      "       [ 1.00902557e+00, -8.86232793e-01, -4.97221947e-04],\n",
      "       [ 7.07491517e-01, -6.99614227e-01, -3.13323677e-01],\n",
      "       [ 1.23837566e+00, -9.03962195e-01, -7.25136220e-01],\n",
      "       [ 7.54432201e-01, -1.44605637e-02,  9.61869359e-02],\n",
      "       [-4.28390145e-01,  6.80527985e-01, -2.48978049e-01],\n",
      "       [ 2.82839537e-02, -5.80449164e-01, -1.01815510e+00],\n",
      "       [-2.06918597e-01,  9.73501742e-01,  1.10082567e-01],\n",
      "       [-3.53499055e-01,  9.69533682e-01,  3.80729556e-01],\n",
      "       [-4.40064549e-01, -7.75523722e-01,  6.53348148e-01],\n",
      "       [ 4.74742293e-01, -2.64077485e-01,  2.78320909e-01],\n",
      "       [-6.70554519e-01,  7.77489901e-01,  1.21564341e+00],\n",
      "       [ 1.30325294e+00, -1.18878222e+00, -1.10256577e+00],\n",
      "       [ 1.30546463e+00,  3.81706834e-01, -1.05430877e+00],\n",
      "       [-4.92637753e-01, -7.90095508e-01, -1.21381080e+00]], dtype=float32)>, <tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[ -6.7953634,  -6.8914137,  -6.718942 ],\n",
      "       [ -6.753015 ,  -1.538363 ,  -6.6044755],\n",
      "       [ -6.6501045,  -7.9296007,  -6.533173 ],\n",
      "       [ -6.6427917,  -8.194305 ,  -6.497428 ],\n",
      "       [ -6.688744 ,  -2.2304358,  -6.5592384],\n",
      "       [ -6.4912634,  -5.334386 ,  -6.393306 ],\n",
      "       [ -6.461629 ,  -5.3391833,  -6.4193635],\n",
      "       [ -6.583777 ,  -6.8147   ,  -6.4882154],\n",
      "       [ -6.710738 ,  -6.670599 ,  -6.6018662],\n",
      "       [ -6.467784 ,  -5.1307135,  -6.3949604],\n",
      "       [ -6.495844 ,  -4.6708074,  -6.3895044],\n",
      "       [ -6.838285 ,  -4.0546393,  -6.6619525],\n",
      "       [ -6.7801414,  -6.403263 ,  -6.5981636],\n",
      "       [ -6.599685 ,  -6.3030834,  -6.4691   ],\n",
      "       [ -6.7173333,  -6.396173 ,  -6.6887755],\n",
      "       [ -6.5856557,  -6.6331606,  -6.5375714],\n",
      "       [ -6.6954627,  -2.0354605,  -6.585471 ],\n",
      "       [ -6.6969733,  -8.06494  ,  -6.4874225],\n",
      "       [ -6.493391 ,  -5.46783  ,  -6.383067 ],\n",
      "       [ -6.57971  ,  -5.952348 ,  -6.4310527],\n",
      "       [ -6.806805 ,  -2.0637953,  -6.656847 ],\n",
      "       [ -6.7555923,  -5.482443 ,  -6.657431 ],\n",
      "       [ -6.758474 ,  -4.9112816,  -6.5761003],\n",
      "       [ -6.4693403,  -2.1314797,  -6.4456506],\n",
      "       [ -7.223506 ,  -7.8835235,  -6.547102 ],\n",
      "       [ -6.612358 ,  -6.7482014,  -6.507028 ],\n",
      "       [ -6.544768 ,  -6.0005703,  -6.479698 ],\n",
      "       [ -6.4455647,  -2.619284 ,  -6.427781 ],\n",
      "       [ -6.673124 ,  -2.452681 ,  -6.5307827],\n",
      "       [ -6.725647 ,  -2.710326 ,  -6.604022 ],\n",
      "       [ -6.6847644,  -2.6384516,  -6.543801 ],\n",
      "       [ -6.8209867,  -7.5557327,  -6.6338015],\n",
      "       [ -6.504292 ,  -4.783252 ,  -6.3939285],\n",
      "       [ -6.4369755,  -2.627026 ,  -6.42047  ],\n",
      "       [ -6.7765636,  -5.7209654,  -6.6044483],\n",
      "       [ -6.443556 ,  -2.4021711,  -6.4284687],\n",
      "       [ -6.4524493,  -1.8743942,  -6.415222 ],\n",
      "       [ -6.6231456,  -6.5530586,  -6.486324 ],\n",
      "       [ -6.676849 ,  -8.445335 ,  -6.7311587],\n",
      "       [ -6.7457337,  -1.6753588,  -6.622505 ],\n",
      "       [ -6.459634 ,  -5.6160603,  -6.383297 ],\n",
      "       [ -6.7950068,  -6.1457024,  -6.627954 ],\n",
      "       [ -6.4688687,  -2.383637 ,  -6.4680395],\n",
      "       [ -6.431469 ,  -2.552977 ,  -6.446027 ],\n",
      "       [ -7.0591164,  -6.570054 ,  -6.723694 ],\n",
      "       [ -6.7628455,  -5.6762915,  -6.5970817],\n",
      "       [ -6.7126255,  -4.334814 ,  -6.55433  ],\n",
      "       [ -6.456274 ,  -2.0156245,  -6.440054 ],\n",
      "       [ -6.4714804,  -5.0999804,  -6.444548 ],\n",
      "       [ -6.5049257,  -5.2200594,  -6.3953066],\n",
      "       [ -6.4223537,  -2.1860518,  -6.4569383],\n",
      "       [ -6.6654835,  -2.2713702,  -6.5592527],\n",
      "       [ -6.74778  ,  -4.5047827,  -6.5904846],\n",
      "       [ -6.689288 ,  -2.7839637,  -6.586058 ],\n",
      "       [ -6.479602 ,  -2.7118757,  -6.493403 ],\n",
      "       [ -6.7713966,  -4.238613 ,  -6.5913486],\n",
      "       [ -6.733906 ,  -1.8072422,  -6.5993147],\n",
      "       [ -6.8269873,  -8.99047  ,  -6.7640934],\n",
      "       [ -6.8084364,  -7.0181265,  -6.786047 ],\n",
      "       [ -6.4936347,  -5.1926994,  -6.3857803],\n",
      "       [ -6.7399535,  -5.7019386,  -6.690206 ],\n",
      "       [ -6.745582 ,  -6.050045 ,  -6.651997 ],\n",
      "       [ -6.7604647,  -4.4341917,  -6.59687  ],\n",
      "       [ -6.4751043,  -5.313828 ,  -6.4089284],\n",
      "       [ -6.6251397,  -6.489914 ,  -6.380561 ],\n",
      "       [ -6.7711716,  -5.9702473,  -6.6418   ],\n",
      "       [ -6.589247 ,  -5.974571 ,  -6.4339533],\n",
      "       [ -6.4424605,  -2.9850168,  -6.4461374],\n",
      "       [-12.318874 , -11.632692 ,  -7.062869 ],\n",
      "       [ -6.703415 ,  -4.347331 ,  -6.544341 ],\n",
      "       [ -7.600006 ,  -8.82723  ,  -6.555044 ],\n",
      "       [ -6.647054 ,  -6.941021 ,  -6.4130235],\n",
      "       [ -6.4655895,  -2.222701 ,  -6.4873834],\n",
      "       [ -6.6058564,  -6.8553224,  -6.4816556],\n",
      "       [ -6.474047 ,  -5.2998743,  -6.419192 ],\n",
      "       [ -6.7528977,  -4.288497 ,  -6.567633 ],\n",
      "       [ -6.4635925,  -5.070606 ,  -6.4270673],\n",
      "       [ -6.4576807,  -2.765902 ,  -6.4345217],\n",
      "       [ -6.4364696,  -5.2494135,  -6.448326 ],\n",
      "       [ -6.772262 ,  -4.98547  ,  -6.6074553],\n",
      "       [ -6.817259 ,  -8.233539 ,  -6.686584 ],\n",
      "       [ -6.4517612,  -1.9853649,  -6.491638 ],\n",
      "       [ -6.471904 ,  -5.2680826,  -6.430941 ],\n",
      "       [ -6.4844794,  -5.365917 ,  -6.4079638],\n",
      "       [ -6.4869204,  -2.2760742,  -6.365918 ],\n",
      "       [ -6.7597713,  -6.426169 ,  -6.5156536],\n",
      "       [ -6.660115 ,  -2.3796575,  -6.541274 ],\n",
      "       [ -6.693223 ,  -2.4428906,  -6.5801373],\n",
      "       [ -6.411672 ,  -2.4177535,  -6.4606614],\n",
      "       [ -6.4705076,  -3.5338023,  -6.4625664],\n",
      "       [ -6.810575 ,  -3.959048 ,  -6.642762 ],\n",
      "       [ -6.6429987,  -6.637721 ,  -6.7138205],\n",
      "       [ -6.483158 ,  -5.3068037,  -6.4097886],\n",
      "       [ -6.7791634,  -4.387138 ,  -6.6059184],\n",
      "       [ -6.6954412,  -1.5164909,  -6.580286 ],\n",
      "       [ -6.693178 ,  -2.8699026,  -6.559443 ],\n",
      "       [ -6.769396 ,  -5.846233 ,  -6.594064 ],\n",
      "       [ -6.685632 ,  -2.139737 ,  -6.589222 ],\n",
      "       [ -6.453801 ,  -4.6593556,  -6.432669 ],\n",
      "       [ -6.8047266,  -7.0331116,  -6.758354 ]], dtype=float32)>, <tf.Tensor: shape=(100, 3), dtype=float32, numpy=\n",
      "array([[ 4.35021967e-01, -8.40384781e-01, -1.47901630e+00],\n",
      "       [-1.69499910e+00, -6.11055851e-01,  1.34063661e+00],\n",
      "       [-6.85290575e-01, -5.25787771e-01,  9.08624649e-01],\n",
      "       [-1.71449041e+00, -6.77315056e-01,  6.64785087e-01],\n",
      "       [-1.91388577e-01, -2.68665642e-01,  8.52433920e-01],\n",
      "       [-3.74886662e-01,  9.80668962e-01, -5.95749579e-02],\n",
      "       [ 1.54486850e-01,  8.06027591e-01, -8.34984481e-02],\n",
      "       [ 1.09099412e+00, -4.88699079e-01, -1.21009040e+00],\n",
      "       [ 6.42431557e-01,  1.11556426e-03, -1.30124882e-01],\n",
      "       [ 6.02482915e-01,  6.09192967e-01, -1.10747278e+00],\n",
      "       [-6.93146527e-01,  9.64187980e-01, -2.18921565e-02],\n",
      "       [-6.14941537e-01,  8.39553177e-01, -3.98099840e-01],\n",
      "       [ 2.52667516e-01,  9.15025175e-02,  4.85080481e-01],\n",
      "       [ 1.10758051e-01,  1.79028377e-01, -1.89914227e-01],\n",
      "       [-9.61584985e-01,  2.00238392e-01,  1.98884621e-01],\n",
      "       [ 1.99872100e+00, -4.10557598e-01, -7.04835296e-01],\n",
      "       [ 3.74187112e-01, -1.12324572e+00, -1.25790611e-01],\n",
      "       [-1.33445394e+00, -1.27868819e+00, -9.88957047e-01],\n",
      "       [-1.06644011e+00,  1.14198983e+00,  2.40288779e-01],\n",
      "       [-7.07474887e-01,  7.56803691e-01, -6.28736317e-02],\n",
      "       [-1.01118290e+00, -1.05579114e+00, -9.06742588e-02],\n",
      "       [ 1.95581615e-02,  4.31127548e-01, -3.99329931e-01],\n",
      "       [-3.05329859e-02,  1.34811127e+00,  7.19661772e-01],\n",
      "       [-4.47376996e-01, -3.48681301e-01,  8.42087150e-01],\n",
      "       [-2.00417447e+00, -4.83003080e-01, -4.25153732e-01],\n",
      "       [ 1.12522757e+00,  1.64356411e-01,  1.35711208e-01],\n",
      "       [ 1.04695809e+00, -5.32736108e-02, -8.30360234e-01],\n",
      "       [-5.51657081e-02, -4.62111354e-01, -1.32910877e-01],\n",
      "       [ 4.31392193e-01, -6.94755733e-01,  8.47798288e-01],\n",
      "       [ 5.77364683e-01, -6.24742389e-01, -5.44592023e-01],\n",
      "       [ 4.61750537e-01, -1.89792395e-01,  6.10484242e-01],\n",
      "       [-8.15252125e-01, -3.17927390e-01,  9.80223358e-01],\n",
      "       [-4.09938455e-01,  1.11653066e+00, -2.55095452e-01],\n",
      "       [ 6.77284300e-02,  4.00449753e-01, -5.70228994e-01],\n",
      "       [-1.24432027e+00,  1.04208016e+00,  1.52810264e+00],\n",
      "       [ 3.39641720e-01, -8.15201283e-01, -5.70001304e-01],\n",
      "       [-1.16165698e-01, -1.29179716e+00, -6.73497140e-01],\n",
      "       [-3.78771693e-01,  2.87408292e-01,  6.08779848e-01],\n",
      "       [ 7.87858903e-01, -2.05087137e+00, -1.74743211e+00],\n",
      "       [-3.65263194e-01, -9.63678241e-01,  9.37462598e-03],\n",
      "       [-3.42532396e-02,  5.96095204e-01, -5.93020856e-01],\n",
      "       [-8.01128924e-01,  1.20349690e-01,  1.76198137e+00],\n",
      "       [-3.21779072e-01, -3.86263847e-01,  1.24189389e+00],\n",
      "       [ 4.19755399e-01, -4.49820817e-01, -3.08023244e-01],\n",
      "       [-8.67116630e-01, -2.90654808e-01, -6.23833954e-01],\n",
      "       [-1.11560774e+00,  1.03062713e+00,  1.53156781e+00],\n",
      "       [ 1.26040351e+00,  2.20460817e-01, -2.59169877e-01],\n",
      "       [ 6.76960424e-02, -1.15060031e+00, -2.03071102e-01],\n",
      "       [ 3.95330012e-01,  8.69339108e-01,  3.09815198e-01],\n",
      "       [-6.25258684e-01,  1.31629574e+00,  6.17805421e-02],\n",
      "       [ 5.96269608e-01, -6.08376086e-01, -1.03747837e-01],\n",
      "       [ 1.23577118e+00, -7.04880118e-01, -4.34539407e-01],\n",
      "       [ 4.99219418e-01,  7.48768508e-01, -9.85491946e-02],\n",
      "       [ 1.35107565e+00, -6.31573975e-01, -9.83364284e-01],\n",
      "       [ 1.25248814e+00, -1.21407247e+00,  3.47657539e-02],\n",
      "       [-6.76807463e-01,  9.21049297e-01,  9.12237704e-01],\n",
      "       [-7.10635066e-01, -2.66513050e-01,  6.55445278e-01],\n",
      "       [ 3.33885223e-01, -2.60509062e+00, -1.42973590e+00],\n",
      "       [-1.11027467e+00, -8.17944348e-01, -9.23693895e-01],\n",
      "       [-1.00094467e-01,  1.03533792e+00, -5.29833198e-01],\n",
      "       [ 7.27183759e-01, -2.88073391e-01, -1.92272031e+00],\n",
      "       [ 7.41792262e-01, -2.51718551e-01, -8.74082327e-01],\n",
      "       [ 2.59680539e-01,  8.85527134e-01, -1.29669994e-01],\n",
      "       [-9.36398134e-02,  9.82658863e-01, -1.04988456e-01],\n",
      "       [-1.28861237e+00,  8.10864449e-01, -3.71624887e-01],\n",
      "       [ 2.55502880e-01,  2.92542338e-01, -4.36003804e-01],\n",
      "       [-1.24850130e+00,  1.00178444e+00,  9.44310606e-01],\n",
      "       [ 5.08635700e-01, -4.65796828e-01, -1.63539678e-01],\n",
      "       [-1.84605563e+00, -3.98399711e+00,  5.19127607e+00],\n",
      "       [ 1.15224540e+00,  2.56869674e-01, -7.39686862e-02],\n",
      "       [-5.98646343e-01, -1.54811835e+00,  5.03057480e+00],\n",
      "       [-5.56358099e-01, -1.86920196e-01, -1.55250120e+00],\n",
      "       [ 1.33242548e+00, -1.22114682e+00, -2.68575519e-01],\n",
      "       [ 7.01188445e-01,  1.23660736e-01, -3.17166187e-02],\n",
      "       [-6.06098950e-01,  8.68244886e-01,  8.29519570e-01],\n",
      "       [-1.08518243e+00,  1.22752917e+00,  1.69744027e+00],\n",
      "       [ 5.27224779e-01,  6.31934464e-01, -1.66471303e-01],\n",
      "       [ 4.83418033e-02, -2.02673733e-01, -1.32279754e-01],\n",
      "       [ 9.08623517e-01,  5.81831634e-01, -1.48487434e-01],\n",
      "       [ 7.47695327e-01,  8.80727649e-01, -6.18620396e-01],\n",
      "       [ 6.20634258e-01, -1.57410371e+00, -7.86342025e-01],\n",
      "       [ 9.87027228e-01, -1.36059380e+00,  3.46042365e-02],\n",
      "       [ 4.72100019e-01,  9.48440671e-01, -3.29200253e-02],\n",
      "       [-4.19818819e-01,  1.16381729e+00,  2.87149340e-01],\n",
      "       [-1.32314050e+00, -4.55548584e-01, -5.16761303e-01],\n",
      "       [-7.09775463e-02,  4.36516553e-01,  6.27468646e-01],\n",
      "       [ 1.03213489e+00, -1.26610732e+00,  1.34937232e-02],\n",
      "       [ 7.86117375e-01, -5.08132696e-01, -3.52678746e-01],\n",
      "       [ 1.14695883e+00, -6.51652217e-01, -7.07577586e-01],\n",
      "       [ 7.01240242e-01, -1.26099199e-01,  1.58954173e-01],\n",
      "       [-4.10190970e-01,  5.69335699e-01, -2.71301270e-01],\n",
      "       [ 1.46828294e-02, -5.78161120e-01, -1.03125036e+00],\n",
      "       [-2.79748857e-01,  1.09194696e+00,  6.34861141e-02],\n",
      "       [-4.10505950e-01,  1.09687591e+00,  3.74254555e-01],\n",
      "       [-3.87341827e-01, -1.28167439e+00,  6.73104942e-01],\n",
      "       [ 4.46804523e-01, -1.05810285e-01,  3.47493231e-01],\n",
      "       [-6.41572773e-01,  7.23053932e-01,  1.20120227e+00],\n",
      "       [ 1.28607416e+00, -9.50930417e-01, -1.05549324e+00],\n",
      "       [ 1.32730746e+00,  2.13712662e-01, -1.08325791e+00],\n",
      "       [-5.48592031e-01, -7.57510066e-01, -1.22797191e+00]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "a=Data_Train_Flat[0:100]\n",
    "b=vae_40MHZ.encoder(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67750e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
