{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1998017a",
   "metadata": {},
   "source": [
    "# This is the template training procedure\n",
    "## If you want to make changes, either copy this into a different file, or call functions from here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee502e9",
   "metadata": {},
   "source": [
    "This first code vlock just imports lots of packages, not all of them are used in the example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a869d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import sklearn\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pylab\n",
    "from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f44783",
   "metadata": {},
   "source": [
    "The below code is just to help run the training on a GPU if yoy want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec72804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check GPUs available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs Available: {gpus}\")\n",
    "\n",
    "# Check if TensorFlow is currently executing eagerly (which means operations are executed as they are defined and is the default mode in TF 2.x)\n",
    "print(f\"Eager execution: {tf.executing_eagerly()}\")\n",
    "\n",
    "# If you have GPUs listed and eager execution is enabled, then operations should automatically run on the GPU if possible.\n",
    "# To test if TensorFlow will place tensors and operations on the GPU by default, you can create a simple operation and see where it is placed:\n",
    "if gpus:\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        print(a.device)\n",
    "else:\n",
    "    print(\"No GPU found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaf0a2",
   "metadata": {},
   "source": [
    "Below just defines a function that creates a dense AE with 3 layers in and 3 out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AE(input_dim, h_dim_1, h_dim_2, latent_dim):\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(h_dim_1, activation='relu')(inputs)\n",
    "    x = layers.Dense(h_dim_2, activation='relu')(x)\n",
    "    z = layers.Dense(latent_dim, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Dense(h_dim_2, activation='relu')(z)\n",
    "    x = layers.Dense(h_dim_1, activation='relu')(z)\n",
    "    outputs = layers.Dense(input_dim)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75506302",
   "metadata": {},
   "source": [
    "Below defines the loss function we want to use, a masked loss function which just ignores empty events in the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    \"\"\"masked mse\"\"\"\n",
    "    mask = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "    squared_difference = K.square(mask * (y_pred - y_true))\n",
    "    return K.mean(squared_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ad63d",
   "metadata": {},
   "source": [
    "The below code initialized the model for an imagined training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b78037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dataset_Train=[]\n",
    "\n",
    "INPUT_DIM = Dataset_Train.shape[1]\n",
    "H_DIM_1 = 32\n",
    "H_DIM_2 = 16\n",
    "LATENT_DIM = 8\n",
    "DNN_AE = create_AE(input_dim=INPUT_DIM, h_dim_1=H_DIM_1, h_dim_2=H_DIM_2, latent_dim=LATENT_DIM)\n",
    "DNN_AE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_AE.compile(optimizer='adam', loss=loss_fn)\n",
    "\n",
    "STOP_PATIENCE = 8\n",
    "LR_PATIENCE = 4\n",
    "\n",
    "early_stopping = EarlyStopping(patience=STOP_PATIENCE, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=LR_PATIENCE, verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "history = DNN_AE.fit(x=X_train, y=X_train, validation_data=(X_val, X_val), epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0584a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_AE.save('Trained_Models/DNN_1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'loss_fn': loss_fn}\n",
    "loaded_model = load_model('Trained_Models/DNN_1.keras', custom_objects=custom_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
