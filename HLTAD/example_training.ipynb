{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4db7479-2e95-49b5-afd6-177cecaa3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 17:52:44.706968: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 17:52:44.784266: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#import random\n",
    "#import sklearn\n",
    "#import collections\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import json\n",
    "#import pylab \n",
    "#from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "#import shap\n",
    "#import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tarfile\n",
    "from tensorflow.keras.models import load_model\n",
    "#from qkeras import QActivation, QDense, QConv2D, QBatchNormalization\n",
    "import ensembler_functions as ef\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import load_and_match as lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a2b96d-16e4-43ac-af26-5b123306af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set matplotlib default color cycle\n",
    "new_color_cycle = [\n",
    "    '#1f77b4',\n",
    "    '#ff7f0e',\n",
    "    '#2ca02c',\n",
    "    '#d62728',\n",
    "    '#9467bd',\n",
    "    '#8c564b',\n",
    "    '#e377c2',\n",
    "    '#7f7f7f',\n",
    "    '#bcbd22',\n",
    "    '#17becf',\n",
    "    '#aec7e8',\n",
    "    '#ffbb78',\n",
    "    '#98df8a',\n",
    "    '#ff9896',\n",
    "    '#c5b0d5',\n",
    "    '#c49c94',\n",
    "    '#f7b6d2',\n",
    "    '#c7c7c7',\n",
    "    '#dbdb8d',\n",
    "    '#9edae5'\n",
    "]\n",
    "\n",
    "# You can then apply this new color cycle to your matplotlib plots\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=new_color_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53f2bf9-443e-4302-aab7-bfd6c88fade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1AD_rate = 1000\n",
    "target_rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00654e-c94f-4a1f-9e73-bcc24b1d917a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581906c7-abf9-4816-af30-1793a2214aa9",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3383e299-c4ce-4bc3-8d53-bacb25c32b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and match my data with the topo2A (L1AD) scores. Only needs to be done once ever.\n",
    "#lam.load_and_match('./h5_ntuples/11-5-2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7cac3-e4eb-476a-bc80-a712b7eeca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info = {\n",
    "    \"save_path\": \"../../../trained_models/trial_102\", \n",
    "    \"dropout_p\": 0.1, \n",
    "    \"L2_reg_coupling\": 0.01, \n",
    "    \"latent_dim\": 4, \n",
    "    \"large_network\": True, \n",
    "    \"num_trainings\": 10,\n",
    "    \"training_weights\": True\n",
    "}\n",
    "\n",
    "data_info = {\n",
    "    #\"train_data_scheme\": \"topo2A_train\", \n",
    "    \"pt_normalization_type\": \"global_division\", \n",
    "    \"L1AD_rate\": 1000,\n",
    "    \"comments\": \"train over run 475321\"\n",
    "}\n",
    "datasets, data_info = ef.load_and_preprocess(**data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418324c9-1618-4a16-af4a-43137b7c05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info, data_info = ef.train_multiple_models(datasets, data_info, **training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23296cf-2e2e-4d87-b8a2-36c8e51d671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef.process_multiple_models(\n",
    "    training_info=training_info,\n",
    "    data_info=data_info,\n",
    "    plots_path=training_info['save_path']+'/plots',\n",
    "    target_rate=target_rate,\n",
    "    L1AD_rate=L1AD_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934532b8-e325-4830-98ca-23d3679dfbbc",
   "metadata": {},
   "source": [
    "### old main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc193906-ab9c-44e9-99ed-563de39ea3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded A14N23LO from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/A14N23LO.h5\n",
      "Loaded EB_473255 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_473255.h5\n",
      "Loaded EB_475321 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_475321.h5\n",
      "Loaded EB_482596 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_482596.h5\n",
      "Loaded HAHMggfZdZd2l2nu from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HAHMggfZdZd2l2nu.h5\n",
      "Loaded HHbbttHadHad from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HHbbttHadHad.h5\n",
      "Loaded HLT_noalg_eb_L1All from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HLT_noalg_eb_L1All.h5\n",
      "Loaded ZZ4lep from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/ZZ4lep.h5\n",
      "Loaded Zprime2EJs from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/Zprime2EJs.h5\n",
      "Loaded jjJZ1 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ1.h5\n",
      "Loaded jjJZ2 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ2.h5\n",
      "Loaded jjJZ4 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ4.h5\n",
      "Loaded qqa from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/qqa.h5\n",
      "Loaded topo2A_train from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/topo2A_train.h5\n",
      "A14N23LO:\n",
      "    HLT_data: (10000, 16, 3)\n",
      "    L1_data: (10000, 16, 3)\n",
      "    passHLT: (10000,)\n",
      "    passL1: (10000,)\n",
      "    topo2A_AD_scores: (10000,)\n",
      "    weights: (10000,)\n",
      "EB_473255:\n",
      "    HLT_data: (484956, 16, 3)\n",
      "    L1_data: (484956, 16, 3)\n",
      "    event_numbers: (484956,)\n",
      "    passHLT: (484956,)\n",
      "    passL1: (484956,)\n",
      "    pileups: (484956,)\n",
      "    run_numbers: (484956,)\n",
      "    topo2A_AD_scores: (484956,)\n",
      "    weights: (484956,)\n",
      "EB_475321:\n",
      "    HLT_data: (26772, 16, 3)\n",
      "    L1_data: (26772, 16, 3)\n",
      "    event_numbers: (26772,)\n",
      "    passHLT: (26772,)\n",
      "    passL1: (26772,)\n",
      "    pileups: (26772,)\n",
      "    run_numbers: (26772,)\n",
      "    topo2A_AD_scores: (26772,)\n",
      "    weights: (26772,)\n",
      "EB_482596:\n",
      "    HLT_data: (1048336, 16, 3)\n",
      "    L1_data: (1048336, 16, 3)\n",
      "    event_numbers: (1048336,)\n",
      "    passHLT: (1048336,)\n",
      "    passL1: (1048336,)\n",
      "    pileups: (1048336,)\n",
      "    run_numbers: (1048336,)\n",
      "    topo2A_AD_scores: (1048336,)\n",
      "    weights: (1048336,)\n",
      "HAHMggfZdZd2l2nu:\n",
      "    HLT_data: (70000, 16, 3)\n",
      "    L1_data: (70000, 16, 3)\n",
      "    passHLT: (70000,)\n",
      "    passL1: (70000,)\n",
      "    topo2A_AD_scores: (70000,)\n",
      "    weights: (70000,)\n",
      "HHbbttHadHad:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "HLT_noalg_eb_L1All:\n",
      "    HLT_data: (1107321, 16, 3)\n",
      "    L1_data: (1107321, 16, 3)\n",
      "    event_numbers: (1107321,)\n",
      "    passHLT: (1107321,)\n",
      "    passL1: (1107321,)\n",
      "    pileups: (1107321,)\n",
      "    run_numbers: (1107321,)\n",
      "    topo2A_AD_scores: (1107321,)\n",
      "    weights: (1107321,)\n",
      "ZZ4lep:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "Zprime2EJs:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ1:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ2:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ4:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "qqa:\n",
      "    HLT_data: (50000, 16, 3)\n",
      "    L1_data: (50000, 16, 3)\n",
      "    passHLT: (50000,)\n",
      "    passL1: (50000,)\n",
      "    topo2A_AD_scores: (50000,)\n",
      "    weights: (50000,)\n",
      "topo2A_train:\n",
      "    HLT_data: (1754041, 16, 3)\n",
      "    L1_data: (1754041, 16, 3)\n",
      "    event_numbers: (1754041,)\n",
      "    passHLT: (1754041,)\n",
      "    passL1: (1754041,)\n",
      "    pileups: (1754041,)\n",
      "    run_numbers: (1754041,)\n",
      "    topo2A_AD_scores: (1754041,)\n",
      "    weights: (1754041,)\n",
      "A14N23LO:\n",
      "    HLT_data: (10000, 16, 3)\n",
      "    L1_data: (10000, 16, 3)\n",
      "    passHLT: (10000,)\n",
      "    passL1: (10000,)\n",
      "    topo2A_AD_scores: (10000,)\n",
      "    weights: (10000,)\n",
      "EB_473255:\n",
      "    HLT_data: (242478, 16, 3)\n",
      "    L1_data: (242478, 16, 3)\n",
      "    event_numbers: (242478,)\n",
      "    passHLT: (242478,)\n",
      "    passL1: (242478,)\n",
      "    pileups: (242478,)\n",
      "    run_numbers: (242478,)\n",
      "    topo2A_AD_scores: (242478,)\n",
      "    weights: (242478,)\n",
      "EB_475321:\n",
      "    HLT_data: (13386, 16, 3)\n",
      "    L1_data: (13386, 16, 3)\n",
      "    event_numbers: (13386,)\n",
      "    passHLT: (13386,)\n",
      "    passL1: (13386,)\n",
      "    pileups: (13386,)\n",
      "    run_numbers: (13386,)\n",
      "    topo2A_AD_scores: (13386,)\n",
      "    weights: (13386,)\n",
      "EB_482596:\n",
      "    HLT_data: (524168, 16, 3)\n",
      "    L1_data: (524168, 16, 3)\n",
      "    event_numbers: (524168,)\n",
      "    passHLT: (524168,)\n",
      "    passL1: (524168,)\n",
      "    pileups: (524168,)\n",
      "    run_numbers: (524168,)\n",
      "    topo2A_AD_scores: (524168,)\n",
      "    weights: (524168,)\n",
      "HAHMggfZdZd2l2nu:\n",
      "    HLT_data: (70000, 16, 3)\n",
      "    L1_data: (70000, 16, 3)\n",
      "    passHLT: (70000,)\n",
      "    passL1: (70000,)\n",
      "    topo2A_AD_scores: (70000,)\n",
      "    weights: (70000,)\n",
      "HHbbttHadHad:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "HLT_noalg_eb_L1All:\n",
      "    HLT_data: (1107321, 16, 3)\n",
      "    L1_data: (1107321, 16, 3)\n",
      "    event_numbers: (1107321,)\n",
      "    passHLT: (1107321,)\n",
      "    passL1: (1107321,)\n",
      "    pileups: (1107321,)\n",
      "    run_numbers: (1107321,)\n",
      "    topo2A_AD_scores: (1107321,)\n",
      "    weights: (1107321,)\n",
      "ZZ4lep:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "Zprime2EJs:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ1:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ2:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ4:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "qqa:\n",
      "    HLT_data: (50000, 16, 3)\n",
      "    L1_data: (50000, 16, 3)\n",
      "    passHLT: (50000,)\n",
      "    passL1: (50000,)\n",
      "    topo2A_AD_scores: (50000,)\n",
      "    weights: (50000,)\n",
      "EB_train:\n",
      "    HLT_data: (780032, 16, 3)\n",
      "    L1_data: (780032, 16, 3)\n",
      "    event_numbers: (780032,)\n",
      "    passHLT: (780032,)\n",
      "    passL1: (780032,)\n",
      "    pileups: (780032,)\n",
      "    run_numbers: (780032,)\n",
      "    topo2A_AD_scores: (780032,)\n",
      "    weights: (780032,)\n"
     ]
    }
   ],
   "source": [
    "# data_info = {\n",
    "#     #\"train_data_scheme\": \"topo2A_train\", \n",
    "#     \"pt_normalization_type\": \"global_division\", \n",
    "#     \"L1AD_rate\": 1000,\n",
    "#     \"comments\": \"train over combination of all three EB runs\"\n",
    "# }\n",
    "\n",
    "# training_info = {\n",
    "#     \"save_path\": \"../../../trained_models/trial_101\", \n",
    "#     \"dropout_p\": 0.1, \n",
    "#     \"L2_reg_coupling\": 0.01, \n",
    "#     \"latent_dim\": 4, \n",
    "#     \"large_network\": True, \n",
    "#     \"num_trainings\": 10,\n",
    "#     \"training_weights\": True\n",
    "# }\n",
    "\n",
    "# datasets, data_info = ef.load_and_preprocess(**data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8bcb27-cef2-4ae9-af02-c39cf55afb53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booting up... initializing trainings of 10 models\n",
      "\n",
      "starting training model 0...\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "model 0 success\n",
      "\n",
      "starting training model 1...\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "model 1 success\n",
      "\n",
      "starting training model 2...\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "model 2 success\n",
      "\n",
      "starting training model 3...\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "model 3 success\n",
      "\n",
      "starting training model 4...\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "model 4 success\n",
      "\n",
      "starting training model 5...\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "model 5 success\n",
      "\n",
      "starting training model 6...\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "model 6 success\n",
      "\n",
      "starting training model 7...\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "model 7 success\n",
      "\n",
      "starting training model 8...\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "model 8 success\n",
      "\n",
      "starting training model 9...\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "model 9 success\n",
      "\n",
      "Powering off... finished trainings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 07:31:32.860326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.873695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.874001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.878482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.878778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.878912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.988691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.988972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.989135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 07:31:32.989281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n",
      "2024-11-11 07:31:41.685650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2585df4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-11 07:31:41.685738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-11-11 07:31:41.693011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-11 07:31:41.719277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-11-11 07:31:41.891385: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# training_info, data_info = ef.train_multiple_models(datasets, data_info, **training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba24f4e-09dd-4843-87b2-83f2012966a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "powering on... preparing to run evals\n",
      "Loaded A14N23LO from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/A14N23LO.h5\n",
      "Loaded EB_473255 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_473255.h5\n",
      "Loaded EB_475321 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_475321.h5\n",
      "Loaded EB_482596 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_482596.h5\n",
      "Loaded HAHMggfZdZd2l2nu from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HAHMggfZdZd2l2nu.h5\n",
      "Loaded HHbbttHadHad from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HHbbttHadHad.h5\n",
      "Loaded HLT_noalg_eb_L1All from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HLT_noalg_eb_L1All.h5\n",
      "Loaded ZZ4lep from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/ZZ4lep.h5\n",
      "Loaded Zprime2EJs from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/Zprime2EJs.h5\n",
      "Loaded jjJZ1 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ1.h5\n",
      "Loaded jjJZ2 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ2.h5\n",
      "Loaded jjJZ4 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ4.h5\n",
      "Loaded qqa from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/qqa.h5\n",
      "Loaded topo2A_train from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/topo2A_train.h5\n",
      "evals phase 1 of 2 initiated.\n",
      "phase 1: starting evals of model 0...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.802846167895942\n",
      "l1Seeded: tag EB_473255, pure rate 7.019695323316727, uncertainty 1.7164311435937558\n",
      "l1Seeded: tag EB_475321, pure rate 530.9835886195866, uncertainty 312.28272066098197\n",
      "l1Seeded: tag EB_test, pure rate 4.936519793819482, uncertainty 1.2454364531777031\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.2405986365802153, uncertainty 0.0031699266090618556\n",
      "l1All: tag EB_475321, pure rate 0.12285193681190043, uncertainty 0.00827784283305323\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.6666580852542907\n",
      "l1Seeded: tag EB_473255, pure rate 3.8788320247006283, uncertainty 0.9484383269243191\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.1726895189531118, uncertainty 0.0022752128150695227\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 1...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 5.020432015140609\n",
      "l1Seeded: tag EB_473255, pure rate 12.450060157897605, uncertainty 3.0442448012878023\n",
      "l1Seeded: tag EB_475321, pure rate 537.1978495684144, uncertainty 315.93745944686856\n",
      "l1Seeded: tag EB_test, pure rate 7.404779690729224, uncertainty 1.868154679766555\n",
      "pure_rate = 8.333883952226767\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.34238114659450397, uncertainty 0.004510927919033243\n",
      "l1All: tag EB_475321, pure rate 0.18506144677635578, uncertainty 0.012469559785757688\n",
      "l1All: tag EB_test, pure rate 0.10529271634996616, uncertainty 0.002307526991685522\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.663388133012137\n",
      "l1Seeded: tag EB_473255, pure rate 2.3272992148203766, uncertainty 0.5690629961545913\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.1535017946249883, uncertainty 0.0020224113911729096\n",
      "l1All: tag EB_475321, pure rate 0.12285193681190043, uncertainty 0.00827784283305323\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 2...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.986353636152439\n",
      "l1Seeded: tag EB_473255, pure rate 5.468162513436476, uncertainty 1.3370558128240284\n",
      "l1Seeded: tag EB_475321, pure rate 524.7693276707587, uncertainty 308.6279818750954\n",
      "l1Seeded: tag EB_test, pure rate 4.936519793819482, uncertainty 1.2454364531777031\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.382216113171316, uncertainty 0.0050357601554820415\n",
      "l1All: tag EB_475321, pure rate 0.18506144677635578, uncertainty 0.012469559785757688\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.628608786274771\n",
      "l1Seeded: tag EB_473255, pure rate 3.8892685264630704, uncertainty 0.950990223528111\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.12472020813280296, uncertainty 0.0016432092553279886\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 3...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 5.284514400755475\n",
      "l1Seeded: tag EB_473255, pure rate 7.795461728256852, uncertainty 1.9061188089786196\n",
      "l1Seeded: tag EB_475321, pure rate 530.9835886195866, uncertainty 312.28272066098197\n",
      "l1Seeded: tag EB_test, pure rate 4.936519793819482, uncertainty 1.2454364531777031\n",
      "pure_rate = 9.197804013154899\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.5901987688395559, uncertainty 0.00777596585156169\n",
      "l1All: tag EB_475321, pure rate 0.3087998095123605, uncertainty 0.020807130569979602\n",
      "l1All: tag EB_test, pure rate 0.11620773393909951, uncertainty 0.002546733449404148\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.649374285278397\n",
      "l1Seeded: tag EB_473255, pure rate 3.8892685264630704, uncertainty 0.950990223528111\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.13431407029686473, uncertainty 0.0017696099672762956\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 4...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.856029890453791\n",
      "l1Seeded: tag EB_473255, pure rate 8.571228133196977, uncertainty 2.095806474363483\n",
      "l1Seeded: tag EB_475321, pure rate 530.9835886195866, uncertainty 312.28272066098197\n",
      "l1Seeded: tag EB_test, pure rate 8.638909639184094, uncertainty 2.179513793060981\n",
      "pure_rate = 9.1937951924691\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.49118390348183183, uncertainty 0.006471428715144948\n",
      "l1All: tag EB_475321, pure rate 0.3702257779183108, uncertainty 0.02494605198650622\n",
      "l1All: tag EB_test, pure rate 0.11615708533134503, uncertainty 0.002545623467312924\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.6222170180379436\n",
      "l1Seeded: tag EB_473255, pure rate 4.665034931403197, uncertainty 1.140677888912975\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.13431407029686473, uncertainty 0.0017696099672762956\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 5...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.875369560436293\n",
      "l1Seeded: tag EB_473255, pure rate 12.450060157897605, uncertainty 3.0442448012878023\n",
      "l1Seeded: tag EB_475321, pure rate 537.1978495684144, uncertainty 315.93745944686856\n",
      "l1Seeded: tag EB_test, pure rate 9.873039587638964, uncertainty 2.4908729063554063\n",
      "pure_rate = 9.204425785017799\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.6304548953161087, uncertainty 0.008306346938959246\n",
      "l1All: tag EB_475321, pure rate 0.3702257779183108, uncertainty 0.02494605198650622\n",
      "l1All: tag EB_test, pure rate 0.11629139533281357, uncertainty 0.0025485669183358027\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.47651952936144\n",
      "l1Seeded: tag EB_473255, pure rate 5.440801336343322, uncertainty 1.3303655542978388\n",
      "l1Seeded: tag EB_475321, pure rate 18.642782846483573, uncertainty 10.964216357659806\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.13431407029686473, uncertainty 0.0017696099672762956\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 6...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.935946070645577\n",
      "l1Seeded: tag EB_473255, pure rate 7.019695323316727, uncertainty 1.7164311435937558\n",
      "l1Seeded: tag EB_475321, pure rate 530.9835886195866, uncertainty 312.28272066098197\n",
      "l1Seeded: tag EB_test, pure rate 4.936519793819482, uncertainty 1.2454364531777031\n",
      "pure_rate = 6.667107161781413\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.33369657478508963, uncertainty 0.00439650725706165\n",
      "l1All: tag EB_475321, pure rate 0.12363547837040557, uncertainty 0.008330638369231074\n",
      "l1All: tag EB_test, pure rate 0.08423417307997291, uncertainty 0.0018460215933484173\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 3.4771865998828755\n",
      "l1Seeded: tag EB_473255, pure rate 2.3272992148203766, uncertainty 0.5690629961545913\n",
      "l1Seeded: tag EB_475321, pure rate 6.214260948827858, uncertainty 3.654738785886602\n",
      "l1Seeded: tag EB_test, pure rate 9.873039587638964, uncertainty 2.4908729063554063\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.11512634596874119, uncertainty 0.0015168085433796819\n",
      "l1All: tag EB_475321, pure rate 0.061425968405950215, uncertainty 0.004138921416526615\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 7...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.200275487915543\n",
      "l1Seeded: tag EB_473255, pure rate 12.450060157897605, uncertainty 3.0442448012878023\n",
      "l1Seeded: tag EB_475321, pure rate 24.857043795311434, uncertainty 14.618955143546408\n",
      "l1Seeded: tag EB_test, pure rate 9.873039587638964, uncertainty 2.4908729063554063\n",
      "pure_rate = 9.19655117391844\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.5639490151899706, uncertainty 0.00743012102983762\n",
      "l1All: tag EB_475321, pure rate 0.36973771166784036, uncertainty 0.024913165767384598\n",
      "l1All: tag EB_test, pure rate 0.11619190520340883, uncertainty 0.002546386557082279\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.6184287720987625\n",
      "l1Seeded: tag EB_473255, pure rate 3.8892685264630704, uncertainty 0.950990223528111\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.14390793246092648, uncertainty 0.0018960106792246022\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 8...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.828080867529975\n",
      "l1Seeded: tag EB_473255, pure rate 5.468162513436476, uncertainty 1.3370558128240284\n",
      "l1Seeded: tag EB_475321, pure rate 530.9835886195866, uncertainty 312.28272066098197\n",
      "l1Seeded: tag EB_test, pure rate 4.936519793819482, uncertainty 1.2454364531777031\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.42124271684985726, uncertainty 0.005549942077791788\n",
      "l1All: tag EB_475321, pure rate 0.30850433420432577, uncertainty 0.020787221252923375\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.6739376661794303\n",
      "l1Seeded: tag EB_473255, pure rate 3.8788320247006283, uncertainty 0.9484383269243191\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.878976082189034, uncertainty 2.4923706268195285\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.1535017946249883, uncertainty 0.0020224113911729096\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "phase 1: starting evals of model 9...\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 4.9685652857905\n",
      "l1Seeded: tag EB_473255, pure rate 12.450060157897605, uncertainty 3.0442448012878023\n",
      "l1Seeded: tag EB_475321, pure rate 537.1978495684144, uncertainty 315.93745944686856\n",
      "l1Seeded: tag EB_test, pure rate 9.873039587638964, uncertainty 2.4908729063554063\n",
      "pure_rate = 9.208434605703598\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.6309934894992039, uncertainty 0.008313443005906036\n",
      "l1All: tag EB_475321, pure rate 0.3087998095123605, uncertainty 0.020807130569979602\n",
      "l1All: tag EB_test, pure rate 0.11634204394056806, uncertainty 0.0025496769004270266\n",
      "pure_rate = 951.8805794687856\n",
      "HLTAD threshold: 2.809433449703475\n",
      "l1Seeded: tag EB_473255, pure rate 3.1135021215229446, uncertainty 0.7613025581432472\n",
      "l1Seeded: tag EB_475321, pure rate 0.0, uncertainty 0.0\n",
      "l1Seeded: tag EB_test, pure rate 9.873039587638964, uncertainty 2.4908729063554063\n",
      "pure_rate = 9.167272347449444\n",
      "l1All: tag EB_473255, total rate: 1248.4547902126037\n",
      "l1All: tag EB_475321, total rate: 1248.4547902126037\n",
      "l1All: tag EB_test, total rate: 1248.4547902126037\n",
      "l1All: tag EB_473255, pure rate 0.10553248380467943, uncertainty 0.001390407831431375\n",
      "l1All: tag EB_475321, pure rate 0.18427790521785065, uncertainty 0.012416764249579843\n",
      "l1All: tag EB_test, pure rate 0.11582198798496278, uncertainty 0.002538279690854074\n",
      "evals phase 1 complete.\n",
      "evals phase 2 of 2 initiated.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sub_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2954/42039995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m ef.process_multiple_models(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtraining_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdata_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i03/m/mmcohen/ad_trigger_development/src/AD_trigger_training/HLTAD/ensembler_functions.py\u001b[0m in \u001b[0;36mprocess_multiple_models\u001b[0;34m(training_info, data_info, plots_path, target_rate, L1AD_rate, custom_datasets)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'l1Seeded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1All'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m             \u001b[0mplot_efficiency_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplots_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1AD_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL1AD_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             \u001b[0mplot_rate_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_rate_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkg_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbkg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplots_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m             \u001b[0mplot_rate_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_rate_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkg_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbkg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplots_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/eos/home-i03/m/mmcohen/ad_trigger_development/src/AD_trigger_training/HLTAD/ensembler_functions.py\u001b[0m in \u001b[0;36mplot_rate_distribution\u001b[0;34m(results, bkg_type, save_path, seed_type, rate_type)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{bkg_type}_{seed_type}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'tag {tag}, pure_rate = {sub_dict[tag][0]}, uncertainty = {sub_dict[tag][1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msub_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{bkg_type}_{seed_type}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub_dict' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 16:29:32.166936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.183118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.183323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.187431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.187775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.187941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.280690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.280981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.281130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-12 16:29:32.281265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_0_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_0_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_1_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_1_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_2_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_2_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_3_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_3_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_4_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_4_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_5_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_5_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_6_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_6_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_7_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_7_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_8_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_8_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/HLT_9_pileup_efficiency.png has been created\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n",
      "Info in <TCanvas::Print>: png file ../../../trained_models/trial_100/plots_11-12-2024/L1_9_pileup_efficiency.png has been created\n"
     ]
    }
   ],
   "source": [
    "training_info = {\n",
    "    \"save_path\": \"../../../trained_models/trial_102\", \n",
    "    \"dropout_p\": 0.1, \n",
    "    \"L2_reg_coupling\": 0.01, \n",
    "    \"latent_dim\": 4, \n",
    "    \"large_network\": True, \n",
    "    \"num_trainings\": 10,\n",
    "    \"training_weights\": True\n",
    "}\n",
    "\n",
    "data_info = {\n",
    "    #\"train_data_scheme\": \"topo2A_train\", \n",
    "    \"pt_normalization_type\": \"global_division\", \n",
    "    \"L1AD_rate\": 1000,\n",
    "    \"comments\": \"train over run \"\n",
    "}\n",
    "\n",
    "ef.process_multiple_models(\n",
    "    training_info=training_info,\n",
    "    data_info=data_info,\n",
    "    plots_path=training_info['save_path']+'/plots_11-12-2024',\n",
    "    target_rate=target_rate,\n",
    "    L1AD_rate=L1AD_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14800679-eb58-4bd9-a6c2-5bbf0db0044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remake efficiency gain plots\n",
    "# data_info = {\n",
    "#     #\"train_data_scheme\": \"topo2A_train\", \n",
    "#     \"pt_normalization_type\": \"global_division\", \n",
    "#     \"L1AD_rate\": 1000,\n",
    "#     \"comments\": \"train over combination of all three EB runs\"\n",
    "# }\n",
    "\n",
    "# training_info = {\n",
    "#     \"save_path\": \"../../../trained_models/trial_101\", \n",
    "#     \"dropout_p\": 0.1, \n",
    "#     \"L2_reg_coupling\": 0.01, \n",
    "#     \"latent_dim\": 4, \n",
    "#     \"large_network\": True, \n",
    "#     \"num_trainings\": 10,\n",
    "#     \"training_weights\": True\n",
    "# }\n",
    "\n",
    "# plots_path = training_info['save_path']+'/plots'\n",
    "# ef.remake_distribution_plots(results_path=plots_path+'/stability_EG_results.json', plots_path=plots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cce132-9ca9-4273-b3e3-e3137aa435bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_path = '../../../trained_models/trial_100/plots3'\n",
    "# ef.remake_distribution_plots(results_path=plots_path+'/stability_EG_results.json', plots_path=plots_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6bf04-80e5-4f4b-a5e2-3811ad2ac00f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26414c2-21d0-4cf1-a476-b2a53faa437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-10-30 15:45:26.715362: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-10-30 15:45:26.715559: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-10-30 15:45:27.230193: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-10-30 15:45:27.230453: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX HLT_AE model saved to: ./trained_models/multiple_trainings/trial_2/onnx/HLT_AE_0.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2024-10-30 15:45:29.812788: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-10-30 15:45:29.812992: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-10-30 15:45:30.345443: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-10-30 15:45:30.345661: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX L1_AE model saved to: ./trained_models/multiple_trainings/trial_2/onnx/L1_AE_0.onnx\n",
      "Loaded A14N23LO from ./h5_ntuples/A14N23LO.h5\n",
      "Loaded EB from ./h5_ntuples/EB.h5\n",
      "Loaded EB_test2 from ./h5_ntuples/EB_test2.h5\n",
      "Loaded EB_train from ./h5_ntuples/EB_train.h5\n",
      "Loaded HAHMggfZdZd2l2nu from ./h5_ntuples/HAHMggfZdZd2l2nu.h5\n",
      "Loaded HHbbttHadHad from ./h5_ntuples/HHbbttHadHad.h5\n",
      "Loaded HLT_noalg_eb_L1All from ./h5_ntuples/HLT_noalg_eb_L1All.h5\n",
      "Loaded ZZ4lep from ./h5_ntuples/ZZ4lep.h5\n",
      "Loaded Zprime2EJs from ./h5_ntuples/Zprime2EJs.h5\n",
      "Loaded jjJZ1 from ./h5_ntuples/jjJZ1.h5\n",
      "Loaded jjJZ2 from ./h5_ntuples/jjJZ2.h5\n",
      "Loaded jjJZ4 from ./h5_ntuples/jjJZ4.h5\n",
      "Loaded qqa from ./h5_ntuples/qqa.h5\n"
     ]
    }
   ],
   "source": [
    "training_info = {\n",
    "    \"save_path\": \"./trained_models/multiple_trainings/trial_2\", \n",
    "    \"dropout_p\": 0.1, \n",
    "    \"L2_reg_coupling\": 0.01, \n",
    "    \"latent_dim\": 4, \n",
    "    \"large_network\": True, \n",
    "    \"num_trainings\": 10,\n",
    "    \"training_weights\": True\n",
    "}\n",
    "\n",
    "data_info = {\n",
    "    \"train_data_scheme\": \n",
    "    \"topo2A_train+overlap\", \n",
    "    \"pt_normalization_type\": \n",
    "    \"global_division\", \n",
    "    \"L1AD_rate\": 1000\n",
    "}\n",
    "model_version=0\n",
    "ef.convert_to_onnx(training_info=training_info, model_version=model_version, object_type='HLT', save_dir='./trained_models/multiple_trainings/trial_2/onnx')\n",
    "ef.convert_to_onnx(training_info=training_info, model_version=model_version, object_type='L1', save_dir='./trained_models/multiple_trainings/trial_2/onnx')\n",
    "datasets, data_info = ef.load_and_preprocess(**data_info)\n",
    "datasets = ef.compare_tf_with_onnx(datasets=datasets, training_info=training_info, model_version=0, onnx_path='./trained_models/multiple_trainings/trial_2/onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328a96a8-96f2-4714-b7ce-079282e725b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A14N23LO:\n",
      "    HLT_data: (10000, 48)\n",
      "    L1_data: (10000, 48)\n",
      "    passHLT: (10000,)\n",
      "    passL1: (10000,)\n",
      "    topo2A_AD_scores: (10000,)\n",
      "    weights: (10000,)\n",
      "    L1Seeded: (10000,)\n",
      "    HLT_model_outputs: (10000, 48)\n",
      "    L1_model_outputs: (10000, 48)\n",
      "    HLT_AD_scores: (10000,)\n",
      "    L1_AD_scores: (10000,)\n",
      "    ONNX_HLT_model_outputs: (10000, 48)\n",
      "    ONNX_L1_model_outputs: (10000, 48)\n",
      "    ONNX_HLT_AD_scores: (10000,)\n",
      "    ONNX_L1_AD_scores: (10000,)\n",
      "HAHMggfZdZd2l2nu:\n",
      "    HLT_data: (70000, 48)\n",
      "    L1_data: (70000, 48)\n",
      "    passHLT: (70000,)\n",
      "    passL1: (70000,)\n",
      "    topo2A_AD_scores: (70000,)\n",
      "    weights: (70000,)\n",
      "    L1Seeded: (70000,)\n",
      "    HLT_model_outputs: (70000, 48)\n",
      "    L1_model_outputs: (70000, 48)\n",
      "    HLT_AD_scores: (70000,)\n",
      "    L1_AD_scores: (70000,)\n",
      "    ONNX_HLT_model_outputs: (70000, 48)\n",
      "    ONNX_L1_model_outputs: (70000, 48)\n",
      "    ONNX_HLT_AD_scores: (70000,)\n",
      "    ONNX_L1_AD_scores: (70000,)\n",
      "HHbbttHadHad:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "ZZ4lep:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "Zprime2EJs:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "jjJZ1:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "jjJZ2:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "jjJZ4:\n",
      "    HLT_data: (100000, 48)\n",
      "    L1_data: (100000, 48)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "    L1Seeded: (100000,)\n",
      "    HLT_model_outputs: (100000, 48)\n",
      "    L1_model_outputs: (100000, 48)\n",
      "    HLT_AD_scores: (100000,)\n",
      "    L1_AD_scores: (100000,)\n",
      "    ONNX_HLT_model_outputs: (100000, 48)\n",
      "    ONNX_L1_model_outputs: (100000, 48)\n",
      "    ONNX_HLT_AD_scores: (100000,)\n",
      "    ONNX_L1_AD_scores: (100000,)\n",
      "qqa:\n",
      "    HLT_data: (50000, 48)\n",
      "    L1_data: (50000, 48)\n",
      "    passHLT: (50000,)\n",
      "    passL1: (50000,)\n",
      "    topo2A_AD_scores: (50000,)\n",
      "    weights: (50000,)\n",
      "    L1Seeded: (50000,)\n",
      "    HLT_model_outputs: (50000, 48)\n",
      "    L1_model_outputs: (50000, 48)\n",
      "    HLT_AD_scores: (50000,)\n",
      "    L1_AD_scores: (50000,)\n",
      "    ONNX_HLT_model_outputs: (50000, 48)\n",
      "    ONNX_L1_model_outputs: (50000, 48)\n",
      "    ONNX_HLT_AD_scores: (50000,)\n",
      "    ONNX_L1_AD_scores: (50000,)\n",
      "EB_test:\n",
      "    HLT_data: (509167, 48)\n",
      "    L1_data: (509167, 48)\n",
      "    event_numbers: (509167,)\n",
      "    passHLT: (509167,)\n",
      "    passL1: (509167,)\n",
      "    pileups: (509167,)\n",
      "    run_numbers: (509167,)\n",
      "    topo2A_AD_scores: (509167,)\n",
      "    weights: (509167,)\n",
      "    L1Seeded: (509167,)\n",
      "    HLT_model_outputs: (509167, 48)\n",
      "    L1_model_outputs: (509167, 48)\n",
      "    HLT_AD_scores: (509167,)\n",
      "    L1_AD_scores: (509167,)\n",
      "    ONNX_HLT_model_outputs: (509167, 48)\n",
      "    ONNX_L1_model_outputs: (509167, 48)\n",
      "    ONNX_HLT_AD_scores: (509167,)\n",
      "    ONNX_L1_AD_scores: (509167,)\n",
      "EB_train:\n",
      "    HLT_data: (1493152, 48)\n",
      "    L1_data: (1493152, 48)\n",
      "    event_numbers: (1493152,)\n",
      "    passHLT: (1493152,)\n",
      "    passL1: (1493152,)\n",
      "    pileups: (1493152,)\n",
      "    run_numbers: (1493152,)\n",
      "    topo2A_AD_scores: (1493152,)\n",
      "    weights: (1493152,)\n",
      "    L1Seeded: (1493152,)\n",
      "EB_val:\n",
      "    HLT_data: (263498, 48)\n",
      "    L1_data: (263498, 48)\n",
      "    event_numbers: (263498,)\n",
      "    passHLT: (263498,)\n",
      "    passL1: (263498,)\n",
      "    pileups: (263498,)\n",
      "    run_numbers: (263498,)\n",
      "    topo2A_AD_scores: (263498,)\n",
      "    weights: (263498,)\n",
      "    L1Seeded: (263498,)\n"
     ]
    }
   ],
   "source": [
    "for tag, data_dict in datasets.items():\n",
    "    print(f'{tag}:')\n",
    "    for key, value in data_dict.items():\n",
    "        print(f'    {key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f166e0-967b-4beb-9593-c0aea74b474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.62544931 1.92602879 1.33561259 0.         1.06108748]\n",
      "\n",
      "[1.62544931 1.92602879 1.33561259 0.         1.06108748]\n"
     ]
    }
   ],
   "source": [
    "print(datasets['EB_test']['HLT_AD_scores'][0:5])\n",
    "print()\n",
    "print(datasets['EB_test']['ONNX_HLT_AD_scores'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706dfe9-b68b-453f-a6cf-4a21d13c02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success! These AD scores are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8511137-fa7c-45cf-b05f-1eeb919f84b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ffd29d-9ad7-407a-b3aa-ecbb8472820c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2d29e2-b0dc-4a56-b698-ba081a9ca2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subdicts_from_h5(save_dir):\n",
    "    \"\"\"\n",
    "    Loads sub-dictionaries of NumPy arrays from HDF5 files in a directory and reconstructs the original structure.\n",
    "    \n",
    "    Args:\n",
    "        save_dir (str): The directory where the HDF5 files are stored.\n",
    "    \n",
    "    Returns:\n",
    "        main_dict (dict): A dictionary of dictionaries where the innermost values are NumPy arrays.\n",
    "    \"\"\"\n",
    "    main_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(save_dir):\n",
    "        if filename.endswith(\".h5\"):\n",
    "            sub_dict_name = os.path.splitext(filename)[0]\n",
    "            file_path = os.path.join(save_dir, filename)\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                sub_dict = {key: np.array(f[key]) for key in f}\n",
    "            main_dict[sub_dict_name] = sub_dict\n",
    "            print(f\"Loaded {sub_dict_name} from {file_path}\")\n",
    "    \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736adce7-2ef6-4aed-be0e-ff993ad57ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded A14N23LO from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/A14N23LO.h5\n",
      "Loaded EB_473255 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_473255.h5\n",
      "Loaded EB_475321 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_475321.h5\n",
      "Loaded EB_482596 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/EB_482596.h5\n",
      "Loaded HAHMggfZdZd2l2nu from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HAHMggfZdZd2l2nu.h5\n",
      "Loaded HHbbttHadHad from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HHbbttHadHad.h5\n",
      "Loaded HLT_noalg_eb_L1All from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/HLT_noalg_eb_L1All.h5\n",
      "Loaded ZZ4lep from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/ZZ4lep.h5\n",
      "Loaded Zprime2EJs from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/Zprime2EJs.h5\n",
      "Loaded jjJZ1 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ1.h5\n",
      "Loaded jjJZ2 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ2.h5\n",
      "Loaded jjJZ4 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/jjJZ4.h5\n",
      "Loaded qqa from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/qqa.h5\n",
      "Loaded topo2A_train from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024/topo2A_train.h5\n",
      "A14N23LO:\n",
      "    HLT_data: (10000, 16, 3)\n",
      "    L1_data: (10000, 16, 3)\n",
      "    passHLT: (10000,)\n",
      "    passL1: (10000,)\n",
      "    topo2A_AD_scores: (10000,)\n",
      "    weights: (10000,)\n",
      "EB_473255:\n",
      "    HLT_data: (484956, 16, 3)\n",
      "    L1_data: (484956, 16, 3)\n",
      "    event_numbers: (484956,)\n",
      "    passHLT: (484956,)\n",
      "    passL1: (484956,)\n",
      "    pileups: (484956,)\n",
      "    run_numbers: (484956,)\n",
      "    topo2A_AD_scores: (484956,)\n",
      "    weights: (484956,)\n",
      "EB_475321:\n",
      "    HLT_data: (26772, 16, 3)\n",
      "    L1_data: (26772, 16, 3)\n",
      "    event_numbers: (26772,)\n",
      "    passHLT: (26772,)\n",
      "    passL1: (26772,)\n",
      "    pileups: (26772,)\n",
      "    run_numbers: (26772,)\n",
      "    topo2A_AD_scores: (26772,)\n",
      "    weights: (26772,)\n",
      "EB_482596:\n",
      "    HLT_data: (1048336, 16, 3)\n",
      "    L1_data: (1048336, 16, 3)\n",
      "    event_numbers: (1048336,)\n",
      "    passHLT: (1048336,)\n",
      "    passL1: (1048336,)\n",
      "    pileups: (1048336,)\n",
      "    run_numbers: (1048336,)\n",
      "    topo2A_AD_scores: (1048336,)\n",
      "    weights: (1048336,)\n",
      "HAHMggfZdZd2l2nu:\n",
      "    HLT_data: (70000, 16, 3)\n",
      "    L1_data: (70000, 16, 3)\n",
      "    passHLT: (70000,)\n",
      "    passL1: (70000,)\n",
      "    topo2A_AD_scores: (70000,)\n",
      "    weights: (70000,)\n",
      "HHbbttHadHad:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "HLT_noalg_eb_L1All:\n",
      "    HLT_data: (1107321, 16, 3)\n",
      "    L1_data: (1107321, 16, 3)\n",
      "    event_numbers: (1107321,)\n",
      "    passHLT: (1107321,)\n",
      "    passL1: (1107321,)\n",
      "    pileups: (1107321,)\n",
      "    run_numbers: (1107321,)\n",
      "    topo2A_AD_scores: (1107321,)\n",
      "    weights: (1107321,)\n",
      "ZZ4lep:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "Zprime2EJs:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ1:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ2:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ4:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "qqa:\n",
      "    HLT_data: (50000, 16, 3)\n",
      "    L1_data: (50000, 16, 3)\n",
      "    passHLT: (50000,)\n",
      "    passL1: (50000,)\n",
      "    topo2A_AD_scores: (50000,)\n",
      "    weights: (50000,)\n",
      "topo2A_train:\n",
      "    HLT_data: (1754041, 16, 3)\n",
      "    L1_data: (1754041, 16, 3)\n",
      "    event_numbers: (1754041,)\n",
      "    passHLT: (1754041,)\n",
      "    passL1: (1754041,)\n",
      "    pileups: (1754041,)\n",
      "    run_numbers: (1754041,)\n",
      "    topo2A_AD_scores: (1754041,)\n",
      "    weights: (1754041,)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_subdicts_from_h5('/eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/11-5-2024')\n",
    "\n",
    "for tag, data_dict in datasets.items():\n",
    "        print(f'{tag}:')\n",
    "        for key, value in data_dict.items():\n",
    "            print(f'    {key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ced633-58f9-4a38-a2f5-05a4a8a5332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119657\n",
      "26772\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(datasets['EB_475321']['run_numbers']==475321) + np.sum(datasets['topo2A_train']['run_numbers']==475321))\n",
    "print(np.sum(datasets['EB_475321']['run_numbers']==475321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c772d4-e307-403a-b1eb-6c9338ce0d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded A14N23LO from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/A14N23LO.h5\n",
      "Loaded EB from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/EB.h5\n",
      "Loaded EB_test2 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/EB_test2.h5\n",
      "Loaded EB_train from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/EB_train.h5\n",
      "Loaded HAHMggfZdZd2l2nu from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/HAHMggfZdZd2l2nu.h5\n",
      "Loaded HHbbttHadHad from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/HHbbttHadHad.h5\n",
      "Loaded HLT_noalg_eb_L1All from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/HLT_noalg_eb_L1All.h5\n",
      "Loaded ZZ4lep from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/ZZ4lep.h5\n",
      "Loaded Zprime2EJs from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/Zprime2EJs.h5\n",
      "Loaded jjJZ1 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/jjJZ1.h5\n",
      "Loaded jjJZ2 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/jjJZ2.h5\n",
      "Loaded jjJZ4 from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/jjJZ4.h5\n",
      "Loaded qqa from /eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples/qqa.h5\n",
      "A14N23LO:\n",
      "    HLT_data: (10000, 16, 3)\n",
      "    L1_data: (10000, 16, 3)\n",
      "    passHLT: (10000,)\n",
      "    passL1: (10000,)\n",
      "    topo2A_AD_scores: (10000,)\n",
      "    weights: (10000,)\n",
      "EB:\n",
      "    HLT_data: (2265769, 16, 3)\n",
      "    L1_data: (2265769, 16, 3)\n",
      "    event_numbers: (2265769,)\n",
      "    passHLT: (2265769,)\n",
      "    passL1: (2265769,)\n",
      "    pileups: (2265769,)\n",
      "    run_numbers: (2265769,)\n",
      "    weights: (2265769,)\n",
      "EB_test2:\n",
      "    HLT_data: (1398336, 16, 3)\n",
      "    L1_data: (1398336, 16, 3)\n",
      "    event_numbers: (1398336,)\n",
      "    passHLT: (1398336,)\n",
      "    passL1: (1398336,)\n",
      "    pileups: (1398336,)\n",
      "    run_numbers: (1398336,)\n",
      "    topo2A_AD_scores: (1398336,)\n",
      "    weights: (1398336,)\n",
      "EB_train:\n",
      "    HLT_data: (1754041, 16, 3)\n",
      "    L1_data: (1754041, 16, 3)\n",
      "    event_numbers: (1754041,)\n",
      "    passHLT: (1754041,)\n",
      "    passL1: (1754041,)\n",
      "    pileups: (1754041,)\n",
      "    run_numbers: (1754041,)\n",
      "    topo2A_AD_scores: (1754041,)\n",
      "    weights: (1754041,)\n",
      "HAHMggfZdZd2l2nu:\n",
      "    HLT_data: (70000, 16, 3)\n",
      "    L1_data: (70000, 16, 3)\n",
      "    passHLT: (70000,)\n",
      "    passL1: (70000,)\n",
      "    topo2A_AD_scores: (70000,)\n",
      "    weights: (70000,)\n",
      "HHbbttHadHad:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "HLT_noalg_eb_L1All:\n",
      "    HLT_data: (1107321, 16, 3)\n",
      "    L1_data: (1107321, 16, 3)\n",
      "    event_numbers: (1107321,)\n",
      "    passHLT: (1107321,)\n",
      "    passL1: (1107321,)\n",
      "    pileups: (1107321,)\n",
      "    run_numbers: (1107321,)\n",
      "    topo2A_AD_scores: (1107321,)\n",
      "    weights: (1107321,)\n",
      "ZZ4lep:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "Zprime2EJs:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ1:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ2:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "jjJZ4:\n",
      "    HLT_data: (100000, 16, 3)\n",
      "    L1_data: (100000, 16, 3)\n",
      "    passHLT: (100000,)\n",
      "    passL1: (100000,)\n",
      "    topo2A_AD_scores: (100000,)\n",
      "    weights: (100000,)\n",
      "qqa:\n",
      "    HLT_data: (50000, 16, 3)\n",
      "    L1_data: (50000, 16, 3)\n",
      "    passHLT: (50000,)\n",
      "    passL1: (50000,)\n",
      "    topo2A_AD_scores: (50000,)\n",
      "    weights: (50000,)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_subdicts_from_h5('/eos/home-m/mmcohen/git_repos/AD_trigger_training/training_notebooks/cohen/h5_ntuples')\n",
    "\n",
    "for tag, data_dict in datasets.items():\n",
    "        print(f'{tag}:')\n",
    "        for key, value in data_dict.items():\n",
    "            print(f'    {key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1610ac8a-9524-4338-8c03-49d1fb4126c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092885\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(datasets['EB_test2']['run_numbers']==475321) + np.sum(datasets['EB_train']['run_numbers']==475321))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c707ad-3e89-47a0-a7bd-d06c4e276c50",
   "metadata": {},
   "source": [
    "Okay so basically, run 475321 has so few events because most of them are in topo2A_train. So I have really low stats calculating rate, so the rate can't really be trusted in trial_100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0a379-5f0d-48c0-b05e-644c0495490b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
