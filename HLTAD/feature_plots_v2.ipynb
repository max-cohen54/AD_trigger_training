{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2830efb7-0299-4f6a-9184-d2a4690d030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 15:24:16.244161: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-12 15:24:16.335722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "#import random\n",
    "#import sklearn\n",
    "#import collections\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import json\n",
    "#import pylab \n",
    "#from scipy.optimize import curve_fit\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "#import shap\n",
    "#import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tarfile\n",
    "from tensorflow.keras.models import load_model\n",
    "#from qkeras import QActivation, QDense, QConv2D, QBatchNormalization\n",
    "import ensembler_functions as ef\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import load_and_match as lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7584aae7-107e-4085-aba9-2a461dfc4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7372918-d14e-4ac8-99ad-4323d93446f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect new EB data that will have incorrect ordering.\n",
    "\n",
    "# Define the base path where the h5 files are stored\n",
    "base_path = '/eos/home-m/mmcohen/ntuples/EB_h5_10-06-2024/'\n",
    "\n",
    "# Initialize empty lists to collect arrays from all files\n",
    "HLT_jets_list = []\n",
    "ofl_jets_list = []\n",
    "L1_jFexSR_jets_list = []\n",
    "L1_jFexLR_jets_list = []\n",
    "HLT_electrons_list = []\n",
    "LRT_electrons_list = []\n",
    "ofl_electrons_list = []\n",
    "L1_egammas_list = []\n",
    "HLT_muons_list = []\n",
    "LRT_muons_list = []\n",
    "ofl_muons_list = []\n",
    "L1_muons_list = []\n",
    "L1_eFex_taus_list = []\n",
    "L1_jFex_taus_list = []\n",
    "HLT_photons_list = []\n",
    "ofl_photons_list = []\n",
    "HLT_MET_list = []\n",
    "L1_MET_list = []\n",
    "pass_L1_unprescaled_list = []\n",
    "pass_HLT_unprescaled_list = []\n",
    "EB_weights_list = []\n",
    "event_number_list = []\n",
    "run_number_list = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for file_name in os.listdir(base_path):\n",
    "    if (file_name.startswith('EB') == False): continue\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    \n",
    "    # Open each h5 file and append data to lists\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        HLT_jets = hf['HLT_jets'][:]\n",
    "        ofl_jets = hf['ofl_jets'][:]\n",
    "        L1_jFexSR_jets = hf['L1_jFexSR_jets'][:]\n",
    "        L1_jFexLR_jets = hf['L1_jFexLR_jets'][:]\n",
    "        HLT_electrons = hf['HLT_electrons'][:]\n",
    "        LRT_electrons = hf['LRT_electrons'][:]\n",
    "        ofl_electrons = hf['ofl_electrons'][:]\n",
    "        L1_egammas = hf['L1_egammas'][:]\n",
    "        HLT_muons = hf['HLT_muons'][:]\n",
    "        LRT_muons = hf['LRT_muons'][:]\n",
    "        ofl_muons = hf['ofl_muons'][:]\n",
    "        L1_muons = hf['L1_muons'][:]\n",
    "        L1_eFex_taus = hf['L1_eFex_taus'][:]\n",
    "        L1_jFex_taus = hf['L1_jFex_taus'][:]\n",
    "        HLT_photons = hf['HLT_photons'][:]\n",
    "        ofl_photons = hf['ofl_photons'][:]\n",
    "        HLT_MET = hf['HLT_MET'][:].reshape(-1, 1, 3)  # Broadcasting MET\n",
    "        L1_MET = hf['L1_MET'][:].reshape(-1, 1, 3)\n",
    "        pass_L1_unprescaled = hf[\"pass_L1_unprescaled\"][:]\n",
    "        pass_HLT_unprescaled = hf[\"pass_HLT_unprescaled\"][:]\n",
    "        EB_weights = hf[\"EB_weights\"][:]\n",
    "        event_number = hf[\"event_number\"][:]\n",
    "        run_number = hf[\"run_number\"][:]\n",
    "        mu = hf[\"mu\"][:]\n",
    "\n",
    "    HLT_objects = np.concatenate([HLT_jets[:, :6, [0, 2, 3]], HLT_electrons[:, :3, :], HLT_muons[:, :3, :], HLT_photons[:, :3, :], HLT_MET], axis=1)\n",
    "    L1_objects = np.concatenate([L1_jFexSR_jets[:, :6, :], L1_egammas[:, :3, :], L1_muons[:, :3, :], L1_eFex_taus[:, :3, :], L1_MET], axis=1)\n",
    "    \n",
    "    datasets[file_name.split('_10')[0]] = {\n",
    "        'HLT_data': HLT_objects,\n",
    "        'L1_data': L1_objects,\n",
    "        'passL1': pass_L1_unprescaled==1,\n",
    "        'passHLT': pass_HLT_unprescaled==1,\n",
    "        'weights': EB_weights,\n",
    "        'event_numbers': event_number,\n",
    "        'run_numbers': run_number,\n",
    "        'pileups': mu\n",
    "    }\n",
    "\n",
    "def combine_data(datasets, tags_to_combine, new_tag):\n",
    "\n",
    "    # initialize empty lists for new tag\n",
    "    datasets[new_tag] = {key: [] for key in datasets[tags_to_combine[0]].keys()}\n",
    "\n",
    "    # Loop through old tags and append np arrays to lists\n",
    "    for tag in tags_to_combine:\n",
    "        for key, value in datasets[tag].items():\n",
    "            datasets[new_tag][key].append(value)\n",
    "\n",
    "    # Concatenate lists into single np array\n",
    "    for key, value in datasets[new_tag].items():\n",
    "        datasets[new_tag][key] = np.concatenate(value, axis=0)\n",
    "\n",
    "    # Delete old tags\n",
    "    for tag in tags_to_combine:\n",
    "        del datasets[tag]\n",
    "\n",
    "    # Make sure everything is an np array\n",
    "    for tag, data_dict in datasets.items():\n",
    "        for key, value in data_dict.items():\n",
    "            data_dict[key] = np.array(value)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "datasets = combine_data(datasets, tags_to_combine=['EB_475341_0', 'EB_475341_1'], new_tag='HLT_noalg_eb_L1All')\n",
    "#datasets = combine_data(datasets, tags_to_combine=['EB_473255_0', 'EB_475321_0', 'EB_482596_0'], new_tag='EB')\n",
    "#datasets = combine_data(datasets, tags_to_combine=['EB_473255_0', 'EB_475321_0'], new_tag='EB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc22bad-c2c8-4d6d-9452-63af7bea6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EB_473255_0:\n",
      "    HLT_data: (1146112, 16, 3)\n",
      "    L1_data: (1146112, 16, 3)\n",
      "    passL1: (1146112,)\n",
      "    passHLT: (1146112,)\n",
      "    weights: (1146112,)\n",
      "    event_numbers: (1146112,)\n",
      "    run_numbers: (1146112,)\n",
      "    pileups: (1146112,)\n",
      "EB_475321_0:\n",
      "    HLT_data: (1119657, 16, 3)\n",
      "    L1_data: (1119657, 16, 3)\n",
      "    passL1: (1119657,)\n",
      "    passHLT: (1119657,)\n",
      "    weights: (1119657,)\n",
      "    event_numbers: (1119657,)\n",
      "    run_numbers: (1119657,)\n",
      "    pileups: (1119657,)\n",
      "EB_482596_0:\n",
      "    HLT_data: (1048336, 16, 3)\n",
      "    L1_data: (1048336, 16, 3)\n",
      "    passL1: (1048336,)\n",
      "    passHLT: (1048336,)\n",
      "    weights: (1048336,)\n",
      "    event_numbers: (1048336,)\n",
      "    run_numbers: (1048336,)\n",
      "    pileups: (1048336,)\n",
      "HLT_noalg_eb_L1All:\n",
      "    HLT_data: (1107321, 16, 3)\n",
      "    L1_data: (1107321, 16, 3)\n",
      "    passL1: (1107321,)\n",
      "    passHLT: (1107321,)\n",
      "    weights: (1107321,)\n",
      "    event_numbers: (1107321,)\n",
      "    run_numbers: (1107321,)\n",
      "    pileups: (1107321,)\n"
     ]
    }
   ],
   "source": [
    "for tag, data_dict in datasets.items():\n",
    "        print(f'{tag}:')\n",
    "        for key, value in data_dict.items():\n",
    "            print(f'    {key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c793cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inputs(datasets, save_path, tags_to_plot):\n",
    "    plt.rcParams['axes.linewidth'] = 2.4\n",
    "    # HLT data -------------------------------------------------------------------------------------------------------------------------\n",
    "    bin_dict = {\n",
    "        'jets': {\n",
    "            'pt': np.linspace(0, 1500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'electrons': {\n",
    "            'pt': np.linspace(0, 500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'muons': {\n",
    "            'pt': np.linspace(0, 500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'photons': {\n",
    "            'pt': np.linspace(0, 500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'EMs': {\n",
    "            'pt': np.linspace(0, 500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'taus': {\n",
    "            'pt': np.linspace(0, 500, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        },\n",
    "\n",
    "        'MET': {\n",
    "            'pt': np.linspace(0, 100, 35),\n",
    "            'eta': np.linspace(-5, 5, 35),\n",
    "            'phi': np.linspace(-np.pi, np.pi, 35)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for obj_name, obj_data_range in zip(['jets', 'electrons', 'muons', 'photons'], [(0, 6), (6, 9), (9, 12), (12, 15)]):\n",
    "        for i, var_name in enumerate(['pt', 'eta', 'phi']):\n",
    "            bins = bin_dict[obj_name][var_name]\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            for tag in tags_to_plot:\n",
    "                data = datasets[tag][f'HLT_data']\n",
    "                weights = datasets[tag]['weights']\n",
    "                obj_data = data[:, obj_data_range[0]:obj_data_range[1], :]\n",
    "                # Mask out zero values\n",
    "                non_zero_mask = obj_data[:, :, i].flatten() != 0\n",
    "                non_zero_data = obj_data[:, :, i].flatten()[non_zero_mask]\n",
    "                non_zero_weights = np.repeat(weights, obj_data.shape[1])[non_zero_mask]\n",
    "                plt.hist(non_zero_data, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "            plt.title(f'HLT {obj_name} {var_name} Distribution (All Objects)')\n",
    "            if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "            plt.xlabel(var_name)\n",
    "            plt.ylabel('Normalized Frequency')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_path, f'HLT_{obj_name}_{var_name}_all.png'))\n",
    "            plt.clf()\n",
    "            \n",
    "            # For leading object\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            for tag in tags_to_plot:\n",
    "                data = datasets[tag][f'HLT_data']\n",
    "                weights = datasets[tag]['weights']\n",
    "                obj_data = data[:, obj_data_range[0]:obj_data_range[1], :]\n",
    "                # Mask out zero values\n",
    "                non_zero_mask = obj_data[:, 0, i] != 0\n",
    "                non_zero_data = obj_data[:, 0, i][non_zero_mask]\n",
    "                non_zero_weights = weights[non_zero_mask]\n",
    "                plt.hist(non_zero_data, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "            plt.title(f'HLT {obj_name} {var_name} Distribution (Leading Object)')\n",
    "            if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "            plt.xlabel(var_name)\n",
    "            plt.ylabel('Normalized Frequency')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_path, f'HLT_{obj_name}_{var_name}_leading.png'))\n",
    "            plt.clf()\n",
    "\n",
    "    # MET plots\n",
    "    for i, var_name in enumerate(['pt', 'eta']):\n",
    "        bins = bin_dict['MET'][var_name]\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        for tag in tags_to_plot:\n",
    "            data = datasets[tag][f'HLT_data']\n",
    "            weights = datasets[tag]['weights']\n",
    "            MET = data[:, -1, :]\n",
    "            # Mask out zero values\n",
    "            non_zero_mask = MET[:, i] != 0\n",
    "            non_zero_MET = MET[:, i][non_zero_mask]\n",
    "            non_zero_weights = weights[non_zero_mask]\n",
    "            plt.hist(non_zero_MET, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "        plt.title(f'HLT MET {var_name} Distribution')\n",
    "        if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "        plt.xlabel(var_name)\n",
    "        plt.ylabel('Normalized Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_path, f'HLT_MET_{var_name}.png'))\n",
    "        plt.clf()\n",
    "\n",
    "    # L1 data # ------------------------------------------------------------------------------------------------------------------------\n",
    "    for obj_name, obj_data_range in zip(['jets', 'EMs', 'muons', 'taus'], [(0, 6), (6, 9), (9, 12), (12, 15)]):\n",
    "        for i, var_name in enumerate(['pt', 'eta', 'phi']):\n",
    "            bins = bin_dict[obj_name][var_name]\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            for tag in tags_to_plot:\n",
    "                data = datasets[tag]['L1_data']\n",
    "                data[:, 9:12, 0] *= 1000 # Get the L1 muons into the right units\n",
    "                weights = datasets[tag]['weights']\n",
    "                obj_data = data[:, obj_data_range[0]:obj_data_range[1], :]\n",
    "                # Mask out zero values\n",
    "                non_zero_mask = obj_data[:, :, i].flatten() != 0\n",
    "                non_zero_data = obj_data[:, :, i].flatten()[non_zero_mask]\n",
    "                non_zero_weights = np.repeat(weights, obj_data.shape[1])[non_zero_mask]\n",
    "                plt.hist(non_zero_data, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "            plt.title(f'L1 {obj_name} {var_name} Distribution (All Objects)')\n",
    "            if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "            plt.xlabel(var_name)\n",
    "            plt.ylabel('Normalized Frequency')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_path, f'L1_{obj_name}_{var_name}_all.png'))\n",
    "            plt.clf()\n",
    "            \n",
    "            # For leading object\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            for tag in tags_to_plot:\n",
    "                data = datasets[tag]['L1_data']\n",
    "                weights = datasets[tag]['weights']\n",
    "                obj_data = data[:, obj_data_range[0]:obj_data_range[1], :]\n",
    "                # Mask out zero values\n",
    "                non_zero_mask = obj_data[:, 0, i] != 0\n",
    "                non_zero_data = obj_data[:, 0, i][non_zero_mask]\n",
    "                non_zero_weights = weights[non_zero_mask]\n",
    "                plt.hist(non_zero_data, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "            plt.title(f'L1 {obj_name} {var_name} Distribution (Leading Object)')\n",
    "            if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "            plt.xlabel(var_name)\n",
    "            plt.ylabel('Normalized Frequency')\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_path, f'L1_{obj_name}_{var_name}_leading.png'))\n",
    "            plt.clf()\n",
    "\n",
    "    # MET plots\n",
    "    for i, var_name in enumerate(['pt', 'eta']):\n",
    "        bins = bin_dict['MET'][var_name]\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        for tag in tags_to_plot:\n",
    "            data = datasets[tag]['L1_data']\n",
    "            weights = datasets[tag]['weights']\n",
    "            MET = data[:, -1, :]\n",
    "            # Mask out zero values\n",
    "            non_zero_mask = MET[:, i] != 0\n",
    "            non_zero_MET = MET[:, i][non_zero_mask]\n",
    "            non_zero_weights = weights[non_zero_mask]\n",
    "            plt.hist(non_zero_MET, bins=bins, label=tag, histtype='step', density=True, fill=False, linewidth=3, weights=non_zero_weights, alpha=0.5)\n",
    "        plt.title(f'L1 MET {var_name} Distribution')\n",
    "        if var_name == 'pt': \n",
    "                plt.yscale('log')\n",
    "        plt.xlabel(var_name)\n",
    "        plt.ylabel('Normalized Frequency')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_path, f'L1_MET_{var_name}.png'))\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed099eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_485/4191292515.py:51: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(14, 8))\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_105a_cuda/x86_64-el9-gcc11-opt/lib/python3.9/site-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "/tmp/ipykernel_485/4191292515.py:129: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.yscale('log')\n",
      "/tmp/ipykernel_485/4191292515.py:149: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.yscale('log')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_to_plot = [tag for tag in datasets.keys() if tag.startswith('EB')]\n",
    "plot_inputs(datasets, save_path = '/eos/home-m/mmcohen/ad_trigger_development/plots/feature_plots_11-11-2024', tags_to_plot=tags_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a7c35-8e7c-458f-94ae-08eac6e50218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
